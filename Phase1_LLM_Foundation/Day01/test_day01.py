"""
è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ï¼šDay 01 - LLMæ¸©åº¦å‚æ•°éªŒè¯
ç›®æ ‡ï¼šéªŒè¯æ¸©åº¦å‚æ•°å¯¹LLMè¾“å‡ºç¨³å®šæ€§çš„å½±å“ï¼Œä¸“æ³¨é£é™©éªŒè¯
"""

import os
import pytest
from typing import List, Dict, Any
from dataclasses import dataclass
from datetime import datetime


@dataclass
class TemperatureTestResult:
    """æ¸©åº¦æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    temperature: float
    prompt: str
    responses: List[str]
    consistency_score: float
    timestamp: str


class LLMTemperatureTester:
    """LLMæ¸©åº¦å‚æ•°æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.model = os.getenv("TEST_MODEL", "gpt-3.5-turbo")
        self._client = None
    
    @property
    def client(self):
        """å»¶è¿Ÿåˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        if self._client is None:
            try:
                from openai import OpenAI
                self._client = OpenAI(
                    api_key=self.api_key,
                    base_url=self.base_url
                )
            except ImportError:
                raise ImportError("è¯·å®‰è£…openaiåº“: pip install openai")
        return self._client
    
    def call_llm(self, prompt: str, temperature: float, max_tokens: int = 100) -> str:
        """
        è°ƒç”¨LLMè·å–å“åº”
        
        Args:
            prompt: è¾“å…¥æç¤º
            temperature: æ¸©åº¦å‚æ•° (0-2)
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            
        Returns:
            æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        """
        if not self.api_key:
            # æ¨¡æ‹Ÿæ¨¡å¼ï¼šç”¨äºæ— APIå¯†é’¥æ—¶çš„æµ‹è¯•æ¼”ç¤º
            return self._mock_response(prompt, temperature)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=max_tokens
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥: {e}")
            return f"[ERROR] {str(e)}"
    
    def _mock_response(self, prompt: str, temperature: float) -> str:
        """
        æ¨¡æ‹ŸLLMå“åº”ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
        æ¨¡æ‹Ÿæ¸©åº¦å‚æ•°å¯¹è¾“å‡ºçš„å½±å“
        """
        import random
        random.seed(hash(prompt + str(temperature)) % 10000)
        
        # æ¨¡æ‹Ÿä¸åŒæ¸©åº¦ä¸‹çš„å“åº”å˜åŒ–
        responses_low = [
            "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½ï¼Œä½äºååŒ—åœ°åŒºã€‚",
            "ä¸­å›½çš„é¦–éƒ½æ˜¯åŒ—äº¬ï¼Œä½äºååŒ—å¹³åŸåŒ—éƒ¨ã€‚",
            "åŒ—äº¬å¸‚ä¸­åäººæ°‘å…±å’Œå›½çš„é¦–éƒ½ã€‚"
        ]
        responses_high = [
            "åŒ—äº¬å•Šï¼Œé‚£å¯æ˜¯ä¸ªæœ‰æ•…äº‹çš„åœ°æ–¹ï¼ä½œä¸ºé¦–éƒ½ï¼Œå®ƒè§è¯äº†å¤ªå¤šå†å²...",
            "è¯´èµ·åŒ—äº¬ï¼Œæˆ‘æƒ³åˆ°äº†æ•…å®«ã€é•¿åŸï¼Œè¿˜æœ‰èƒ¡åŒé‡Œçš„è€åŒ—äº¬å‘³å„¿...",
            "åŒ—äº¬ï¼Œä¸­å›½çš„æ”¿æ²»æ–‡åŒ–ä¸­å¿ƒï¼Œä¸€åº§å¤è€ä¸ç°ä»£äº¤èçš„åŸå¸‚...",
            "é¦–éƒ½åŒ—äº¬ï¼Œä»å…ƒå¤§éƒ½åˆ°ç°ä»£éƒ½å¸‚ï¼Œå‡ åƒå¹´çš„æ²§æ¡‘å˜è¿...",
            "åŒ—äº¬ï¼é‚£é‡Œæœ‰å¤©å®‰é—¨ã€é¢å’Œå›­ï¼Œè¿˜æœ‰è®©äººå‚æ¶çš„çƒ¤é¸­..."
        ]
        
        if temperature < 0.3:
            # ä½æ¸©ï¼šé€‰æ‹©æœ‰é™ï¼Œç›¸å¯¹ç¨³å®š
            return responses_low[random.randint(0, 1)]
        elif temperature > 1.0:
            # é«˜æ¸©ï¼šé€‰æ‹©å¤šæ ·ï¼Œéšæœºæ€§å¼º
            return responses_high[random.randint(0, 4)]
        else:
            # ä¸­æ¸©ï¼šæ··åˆ
            all_responses = responses_low + responses_high
            return all_responses[random.randint(0, len(all_responses) - 1)]
    
    def test_consistency(
        self, 
        prompt: str, 
        temperature: float, 
        num_calls: int = 5
    ) -> TemperatureTestResult:
        """
        æµ‹è¯•æŒ‡å®šæ¸©åº¦ä¸‹çš„è¾“å‡ºä¸€è‡´æ€§
        
        Args:
            prompt: æµ‹è¯•æç¤º
            temperature: æ¸©åº¦å‚æ•°
            num_calls: è°ƒç”¨æ¬¡æ•°
            
        Returns:
            æµ‹è¯•ç»“æœå¯¹è±¡
        """
        print(f"\nğŸŒ¡ï¸  æµ‹è¯•æ¸©åº¦: {temperature}, è°ƒç”¨æ¬¡æ•°: {num_calls}")
        print(f"ğŸ“ Prompt: {prompt[:50]}...")
        
        responses = []
        for i in range(num_calls):
            response = self.call_llm(prompt, temperature)
            responses.append(response)
            print(f"   è°ƒç”¨ {i+1}/{num_calls}: {response[:60]}...")
        
        # è®¡ç®—ä¸€è‡´æ€§åˆ†æ•°ï¼ˆç®€å•ç‰ˆæœ¬ï¼šå®Œå…¨ç›¸åŒçš„å“åº”æ¯”ä¾‹ï¼‰
        unique_responses = set(responses)
        consistency_score = (num_calls - len(unique_responses) + 1) / num_calls
        
        return TemperatureTestResult(
            temperature=temperature,
            prompt=prompt,
            responses=responses,
            consistency_score=consistency_score,
            timestamp=datetime.now().isoformat()
        )


# ============ æµ‹è¯•ç”¨ä¾‹ ============

class TestDay01Temperature:
    """Day 01: æ¸©åº¦å‚æ•°éªŒè¯æµ‹è¯•ç±»"""
    
    @pytest.fixture(scope="class")
    def tester(self):
        """æµ‹è¯•å™¨fixture"""
        return LLMTemperatureTester()
    
    def test_temperature_zero_determinism(self, tester):
        """
        æµ‹è¯•æ¸©åº¦=0æ—¶çš„ç¡®å®šæ€§è¾“å‡º
        
        é£é™©ç‚¹ï¼šå…³é”®ä¸šåŠ¡åœºæ™¯éœ€è¦ç¨³å®šè¾“å‡º
        é¢„æœŸï¼šæ¸©åº¦=0æ—¶ï¼Œå¤šæ¬¡è°ƒç”¨åº”äº§ç”Ÿç›¸åŒæˆ–é«˜åº¦ç›¸ä¼¼çš„è¾“å‡º
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 1: æ¸©åº¦=0 ç¡®å®šæ€§éªŒè¯")
        print("="*60)
        
        prompt = "ä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿç®€è¦å›ç­”ã€‚"
        result = tester.test_consistency(prompt, temperature=0.0, num_calls=3)
        
        # æ–­è¨€ï¼šä¸€è‡´æ€§åˆ†æ•°åº”æ¥è¿‘1.0
        print(f"\nğŸ“Š ä¸€è‡´æ€§åˆ†æ•°: {result.consistency_score:.2f}")
        
        # è®°å½•ç»“æœä¾›åˆ†æ
        assert result.responses is not None, "æµ‹è¯•åº”è¿”å›å“åº”"
        assert len(result.responses) > 0, "æµ‹è¯•åº”è¿”å›éç©ºå“åº”"
        print("âœ… æ¸©åº¦=0 æµ‹è¯•å®Œæˆ")
    
    def test_temperature_low_stability(self, tester):
        """
        æµ‹è¯•ä½æ¸©åº¦(0.3)ä¸‹çš„è¾“å‡ºç¨³å®šæ€§
        
        é£é™©ç‚¹ï¼šç»“æ„åŒ–ä»»åŠ¡éœ€è¦å¯é¢„æµ‹è¾“å‡º
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 2: æ¸©åº¦=0.3 ç¨³å®šæ€§éªŒè¯")
        print("="*60)
        
        prompt = "å°†ä»¥ä¸‹æ–‡æœ¬åˆ†ç±»ä¸ºæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼š'è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨'"
        result = tester.test_consistency(prompt, temperature=0.3, num_calls=5)
        
        print(f"\nğŸ“Š ä¸€è‡´æ€§åˆ†æ•°: {result.consistency_score:.2f}")
        print("âœ… æ¸©åº¦=0.3 æµ‹è¯•å®Œæˆ")
    
    def test_temperature_medium_balance(self, tester):
        """
        æµ‹è¯•ä¸­ç­‰æ¸©åº¦(0.7)ä¸‹çš„å¹³è¡¡æ€§
        
        é£é™©ç‚¹ï¼šé€šç”¨åœºæ™¯éœ€è¦å¹³è¡¡åˆ›æ„ä¸å‡†ç¡®
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 3: æ¸©åº¦=0.7 å¹³è¡¡æ€§éªŒè¯")
        print("="*60)
        
        prompt = "ç”¨ä¸€å¥è¯ä»‹ç»åŒ—äº¬ã€‚"
        result = tester.test_consistency(prompt, temperature=0.7, num_calls=5)
        
        print(f"\nğŸ“Š ä¸€è‡´æ€§åˆ†æ•°: {result.consistency_score:.2f}")
        print("âœ… æ¸©åº¦=0.7 æµ‹è¯•å®Œæˆ")
    
    def test_temperature_high_creativity(self, tester):
        """
        æµ‹è¯•é«˜æ¸©åº¦(1.2)ä¸‹çš„åˆ›æ„æ€§
        
        é£é™©ç‚¹ï¼šé«˜éšæœºæ€§å¯èƒ½å¯¼è‡´ä¸å¯æ§è¾“å‡º
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 4: æ¸©åº¦=1.2 åˆ›æ„æ€§éªŒè¯")
        print("="*60)
        
        prompt = "å†™ä¸€ä¸ªå…³äºåŒ—äº¬çš„åˆ›æ„çŸ­å¥ã€‚"
        result = tester.test_consistency(prompt, temperature=1.2, num_calls=5)
        
        print(f"\nğŸ“Š ä¸€è‡´æ€§åˆ†æ•°: {result.consistency_score:.2f}")
        print("âš ï¸  æ³¨æ„ï¼šé«˜æ¸©åº¦ä¸‹ä¸€è‡´æ€§åˆ†æ•°åº”è¾ƒä½ï¼Œè¡¨æ˜è¾“å‡ºå¤šæ ·æ€§")
        print("âœ… æ¸©åº¦=1.2 æµ‹è¯•å®Œæˆ")
    
    def test_temperature_extreme_high(self, tester):
        """
        æµ‹è¯•æç«¯é«˜æ¸©(1.8)ä¸‹çš„è¡Œä¸º
        
        é£é™©ç‚¹ï¼šæç«¯å‚æ•°å¯èƒ½å¯¼è‡´è¾“å‡ºè´¨é‡ä¸‹é™
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 5: æ¸©åº¦=1.8 æç«¯æƒ…å†µéªŒè¯")
        print("="*60)
        
        prompt = "æè¿°ä¸€ä¸‹åŒ—äº¬ã€‚"
        result = tester.test_consistency(prompt, temperature=1.8, num_calls=3)
        
        print(f"\nğŸ“Š ä¸€è‡´æ€§åˆ†æ•°: {result.consistency_score:.2f}")
        print("âš ï¸  æç«¯é«˜æ¸©å¯èƒ½å¯¼è‡´è¾“å‡ºä¸ç¨³å®šæˆ–ç¦»é¢˜")
        print("âœ… æ¸©åº¦=1.8 æµ‹è¯•å®Œæˆ")
    
    def test_semantic_equivalence_stability(self, tester):
        """
        æµ‹è¯•è¯­ä¹‰ç­‰ä»·promptçš„ç¨³å®šæ€§
        
        é£é™©ç‚¹ï¼šç”¨æˆ·ç”¨ä¸åŒæ–¹å¼æé—®æ—¶ï¼Œåº”å¾—åˆ°ä¸€è‡´ç­”æ¡ˆ
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 6: è¯­ä¹‰ç­‰ä»·ç¨³å®šæ€§éªŒè¯")
        print("="*60)
        
        prompts = [
            "ä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ",
            "è¯·å‘Šè¯‰æˆ‘ä¸­å›½é¦–éƒ½æ˜¯ä»€ä¹ˆåŸå¸‚ï¼Ÿ",
            "å“ªä¸ªåŸå¸‚æ˜¯ä¸­å›½çš„é¦–éƒ½ï¼Ÿ"
        ]
        
        all_responses = []
        for i, prompt in enumerate(prompts):
            response = tester.call_llm(prompt, temperature=0.0)
            all_responses.append(response)
            print(f"   Prompt {i+1}: {prompt}")
            print(f"   Response: {response[:60]}...")
        
        # æ£€æŸ¥å“åº”æ˜¯å¦éƒ½åŒ…å«"åŒ—äº¬"
        contains_beijing = all("åŒ—äº¬" in resp for resp in all_responses)
        print(f"\nğŸ“Š æ‰€æœ‰å“åº”éƒ½åŒ…å«'åŒ—äº¬': {contains_beijing}")
        print("âœ… è¯­ä¹‰ç­‰ä»·æµ‹è¯•å®Œæˆ")
    
    def test_temperature_gradient_analysis(self, tester):
        """
        æ¸©åº¦æ¢¯åº¦åˆ†æï¼šä»0åˆ°1.5çš„å®Œæ•´æµ‹è¯•
        
        ç”Ÿæˆæ¸©åº¦-ä¸€è‡´æ€§å…³ç³»æ•°æ®
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 7: æ¸©åº¦æ¢¯åº¦åˆ†æ")
        print("="*60)
        
        temperatures = [0.0, 0.3, 0.5, 0.7, 1.0, 1.2, 1.5]
        prompt = "ç”¨ä¸€å¥è¯æè¿°äººå·¥æ™ºèƒ½ã€‚"
        
        results = []
        for temp in temperatures:
            result = tester.test_consistency(prompt, temperature=temp, num_calls=3)
            results.append({
                "temperature": temp,
                "consistency": result.consistency_score
            })
        
        print("\nğŸ“Š æ¸©åº¦-ä¸€è‡´æ€§å…³ç³»è¡¨:")
        print("-" * 40)
        print(f"{'æ¸©åº¦':<10} {'ä¸€è‡´æ€§åˆ†æ•°':<15}")
        print("-" * 40)
        for r in results:
            print(f"{r['temperature']:<10} {r['consistency']:<15.2f}")
        print("-" * 40)
        print("âœ… æ¸©åº¦æ¢¯åº¦åˆ†æå®Œæˆ")


def test_ai_behavior_day01():
    """
    ä¸»æµ‹è¯•å…¥å£ - å¿«é€ŸéªŒè¯
    """
    print("\n" + "="*60)
    print("ğŸš€ AI QA System Test - Day 01 å¯åŠ¨")
    print("   ä¸»é¢˜: LLMæ¸©åº¦å‚æ•°éªŒè¯")
    print("="*60)
    
    tester = LLMTemperatureTester()
    
    # å¿«é€Ÿæ¼”ç¤ºæµ‹è¯•
    print("\nğŸ“‹ æ‰§è¡Œå¿«é€ŸéªŒè¯æµ‹è¯•...")
    
    test_cases = [
        ("åŒ—äº¬æ˜¯å“ªé‡Œçš„é¦–éƒ½ï¼Ÿ", 0.0, "ä½æ¸©ç¡®å®šæ€§"),
        ("æè¿°ä¸€ä¸‹åŒ—äº¬ã€‚", 0.7, "ä¸­æ¸©å¹³è¡¡æ€§"),
        ("å†™ä¸€å¥å…³äºåŒ—äº¬çš„åˆ›æ„æè¿°ã€‚", 1.2, "é«˜æ¸©åˆ›æ„æ€§"),
    ]
    
    for prompt, temp, desc in test_cases:
        print(f"\nğŸ§ª {desc} (T={temp})")
        response = tester.call_llm(prompt, temperature=temp)
        print(f"   å“åº”: {response[:80]}...")
    
    print("\n" + "="*60)
    print("âœ… Day 01 æµ‹è¯•æ‰§è¡Œå®Œæ¯•")
    print("ğŸ“Œ è¯·å°†ä¸Šæ–¹æ—¥å¿—å‘ç»™ Trae ç”Ÿæˆ report_day01.md æŠ¥å‘Š")
    print("="*60)


if __name__ == "__main__":
    test_ai_behavior_day01()

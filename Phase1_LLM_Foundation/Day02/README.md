# Day 02: Tokenizer编码机制与上下文窗口边界测试

## 🎯 1. 核心风险与测试目标

### 1.1 测试工程师视角
> **核心原则**：开发只管跑通，我们要想办法把它搞崩溃。Tokenizer是LLM的"入口闸门"，编码错误会导致连锁反应。

### 1.2 业务风险点

| 风险类别 | 具体风险 | 线上事故场景 |
|---------|---------|-------------|
| **成本估算偏差** | Token计数不准确导致API费用超支 | 预算10万token实际消耗15万，项目亏损 |
| **上下文截断** | 长输入被静默截断，关键信息丢失 | 法律合同审查漏掉关键条款，客户索赔 |
| **多语言处理不均** | 中文/英文token压缩率差异大 | 中文客服系统成本比预估高40%，预算失控 |
| **边界信息丢失** | "Lost in the Middle"现象 | 长文档中间的关键要求被模型忽略 |
| **编码不一致** | 相同文本不同模型token数差异 | 迁移模型后成本模型失效，财务预测错误 |

### 1.3 测试思路

**Tokenizer边界探测策略**：
- **字符级边界**：单字符、特殊符号、emoji的token编码验证
- **语言差异边界**：中英日韩相同语义内容的token消耗对比
- **长度边界**：精确构造窗口长度±1 token的输入，验证截断行为
- **位置边界**：关键信息放在开头/中间/结尾，验证召回率

**上下文窗口压力测试**：
- 逐步增加输入长度，记录输出质量退化点
- 验证标称窗口大小与实际有效上下文的关系
- 测试多轮对话中的历史信息累积效应

---

## 📚 2. Tokenizer核心原理（测试必备知识）

### 2.1 什么是Tokenizer

Tokenizer是LLM的"文本翻译器"，将人类可读的文本转换为模型可处理的数字序列：

```
人类文本 → Tokenizer → Token序列 → Embedding层 → 模型计算
```

**关键认知**：
1. **Token ≠ 字符**：1个token可能对应多个字符，也可能1个字符对应多个token
2. **Token ≠ 单词**：英文中常见单词可能对应1个token，罕见词被拆分为子词
3. **语言差异大**：中文通常1-2字符/token，英文约4字符/token

### 2.2 主流Tokenizer对比

| Tokenizer类型 | 代表模型 | 中文压缩率 | 特点 |
|--------------|---------|-----------|------|
| **BPE** | GPT-3.5/4, Claude | ~1.5字符/token | 字节对编码，英文优化 |
| **SentencePiece** | LLaMA, T5 | ~1.8字符/token | 语言无关，多语言均衡 |
| **BBPE** | GPT-2 | ~1.6字符/token | 字节级BPE，处理生僻字好 |

**测试关注点**：
- 相同文本在不同Tokenizer下的token数差异可达30-50%
- 成本估算必须基于目标模型的Tokenizer

### 2.3 Tokenizer编码示例

```python
# 示例文本
text = "Hello世界🌍"

# GPT-4 (cl100k_base) 编码结果
# ["Hello", "世界", "🌍"] → 3 tokens

# 中文句子示例
text_cn = "人工智能正在改变世界"
# GPT-4: ~6-8 tokens
# LLaMA: ~5-7 tokens
```

### 2.4 上下文窗口机制

```
┌─────────────────────────────────────────────────────────┐
│  System Prompt (系统指令)                                │
├─────────────────────────────────────────────────────────┤
│  User Message 1                                          │
│  Assistant Response 1                                    │
│  User Message 2                                          │
│  Assistant Response 2                                    │
│  ...                                                     │
│  User Message N (当前输入) ← 可能从这里被截断            │
└─────────────────────────────────────────────────────────┘
                      ↑
                 上下文窗口上限 (如 4k/8k/128k tokens)
```

**截断策略**（不同模型可能不同）：
- **头部截断**：保留最近的对话，丢弃早期历史
- **尾部截断**：保留系统指令和开头，截断当前输入尾部
- **摘要截断**：对历史进行摘要压缩

### 2.5 "Lost in the Middle"现象

研究发现：LLM对上下文中间位置的信息召回率显著低于开头和结尾。

```
信息召回率
  ↑
  │    ╭────╮
  │   ╱      ╲    ← 中间信息召回率低
  │  ╱   ↓    ╲
  │ ╱  中间    ╲
  │╱   低谷     ╲
  └────────────────→ 上下文位置
   开头      结尾
```

**测试意义**：关键信息不能放在长文档中间位置。

---

## 🧪 3. 实验验证任务

### 3.1 实验环境准备

确保已安装依赖：
```bash
pip install tiktoken pytest
```

### 3.2 运行测试

执行本目录下的测试脚本：
```bash
pytest test_day02.py -v -s
```

### 3.3 预期观察结果

1. **中英文token消耗差异**：相同语义的中文文本token数通常是英文的1.5-2倍
2. **特殊字符消耗**：emoji、特殊符号可能消耗多个token
3. **边界截断行为**：超过窗口限制的输入会被静默截断
4. **位置敏感性**：中间位置的关键信息更容易被忽略

---

## 📝 4. 产出要求

将运行结果贴回给 Trae，让其生成 `report_day02.md` 质量分析报告。

报告应包含：
- 不同文本类型的token消耗统计
- 上下文窗口边界测试结果
- 位置敏感性测试结论
- 风险评级与改进建议

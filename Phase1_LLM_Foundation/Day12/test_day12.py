"""
Day 12: è¾“å‡ºé²æ£’æ€§æµ‹è¯• - è·¨è¯­è¨€ä¸è¯­ç¯‡çº§æ”¹å†™

æµ‹è¯•ç›®æ ‡ï¼š
1. éªŒè¯æ¨¡å‹å¯¹è·¨è¯­è¨€ç¿»è¯‘çš„é²æ£’æ€§
2. æµ‹è¯•æ¨¡å‹å¯¹è¯­ç¯‡çº§æ”¹å†™çš„ç¨³å®šæ€§
3. è¯†åˆ«è·¨è¯­è¨€å’Œè¯­ç¯‡çº§è„†å¼±ç‚¹

æµ‹è¯•æ¶æ„å¸ˆè§†è§’ï¼š
- å¼€å‘åªç®¡è·‘é€šï¼Œæˆ‘ä»¬è¦æƒ³åŠæ³•æŠŠå®ƒæå´©æºƒ
- å…³æ³¨ç¿»è¯‘å¾€è¿”ä¸€è‡´æ€§ã€å¤šè¯­è¨€ç­”æ¡ˆä¸€è‡´æ€§ã€è¯­ç¯‡ç»“æ„ç¨³å®šæ€§
"""

import pytest
import random
import re
from dataclasses import dataclass
from enum import Enum
from typing import List, Dict, Tuple, Optional, Set
from difflib import SequenceMatcher


class RobustnessLevel(Enum):
    """é²æ£’æ€§ç­‰çº§"""
    HIGH = "ğŸŸ¢ HIGH"
    MEDIUM = "ğŸŸ¡ MEDIUM"
    LOW = "ğŸŸ  LOW"
    CRITICAL = "ğŸ”´ CRITICAL"


class RobustnessTestType(Enum):
    """æµ‹è¯•ç±»å‹"""
    TRANSLATION_ROUNDTRIP = "ç¿»è¯‘å¾€è¿”"
    MULTILINGUAL_PARALLEL = "å¤šè¯­è¨€å¹³è¡Œ"
    PARAGRAPH_REORDERING = "æ®µè½é‡ç»„"
    COREFERENCE_RESOLUTION = "æŒ‡ä»£æ¶ˆè§£"
    DETAIL_PRESERVATION = "ç»†èŠ‚ä¿ç•™"


@dataclass
class RobustnessResult:
    """é²æ£’æ€§æµ‹è¯•ç»“æœ"""
    test_type: "RobustnessTestType"
    original: str
    modified: str
    consistency_score: float
    key_info_retention: float
    is_robust: bool
    risk_level: RobustnessLevel
    message: str
    details: Dict


class MockTranslator:
    """
    æ¨¡æ‹Ÿç¿»è¯‘å™¨ - å…·æœ‰å¯æ§çš„ç¿»è¯‘ç¼ºé™·
    
    è®¾è®¡ç¼ºé™·ï¼š
    1. æ–‡åŒ–æ¦‚å¿µå¯èƒ½ä¸¢å¤±
    2. ç»†å¾®è¯­ä¹‰å·®å¼‚
    3. ä¸“ä¸šæœ¯è¯­ç¿»è¯‘ä¸å‡†ç¡®
    """
    
    def __init__(self, seed: int = 42):
        random.seed(seed)
        
        # ç®€åŒ–çš„ç¿»è¯‘è¯å…¸
        self.zh_to_en = {
            "æ˜¥èŠ‚": "Spring Festival",
            "å…ƒå®µèŠ‚": "Lantern Festival",
            "ç«¯åˆèŠ‚": "Dragon Boat Festival",
            "ä¸­ç§‹èŠ‚": "Mid-Autumn Festival",
            "äººå·¥æ™ºèƒ½": "artificial intelligence",
            "æœºå™¨å­¦ä¹ ": "machine learning",
            "æ·±åº¦å­¦ä¹ ": "deep learning",
            "å…‰åˆä½œç”¨": "photosynthesis",
            "äºŒæ°§åŒ–ç¢³": "carbon dioxide",
            "æ°§æ°”": "oxygen",
            "æ¤ç‰©": "plants",
            "å…‰": "light",
            "æ°´": "water",
            "æ˜¯": "is",
            "ä»€ä¹ˆ": "what",
            "å¦‚ä½•": "how",
            "ä¸ºä»€ä¹ˆ": "why",
            "è¯·": "please",
            "è°¢è°¢": "thank you",
        }
        
        self.en_to_zh = {v: k for k, v in self.zh_to_en.items()}
        
        # æœ‰é—®é¢˜çš„ç¿»è¯‘ï¼ˆæ¨¡æ‹Ÿç¿»è¯‘ç¼ºé™·ï¼‰
        self.problematic_translations = {
            "çº¢åŒ…": "red envelope",  # æ–‡åŒ–å†…æ¶µä¸¢å¤±
            "é¢å­": "face",  # ä¸¥é‡æ–‡åŒ–æ¦‚å¿µä¸¢å¤±
            "å…³ç³»": "relationship",  # ä¸¥é‡æ–‡åŒ–æ¦‚å¿µä¸¢å¤±
        }
    
    def translate(self, text: str, src: str, tgt: str) -> str:
        """
        æ¨¡æ‹Ÿç¿»è¯‘
        
        Args:
            text: å¾…ç¿»è¯‘æ–‡æœ¬
            src: æºè¯­è¨€ (zh/en)
            tgt: ç›®æ ‡è¯­è¨€ (zh/en)
        """
        if src == tgt:
            return text
        
        # ç®€åŒ–çš„ç¿»è¯‘é€»è¾‘
        if src == "zh" and tgt == "en":
            return self._zh_to_en(text)
        elif src == "en" and tgt == "zh":
            return self._en_to_zh(text)
        else:
            return text  # ä¸æ”¯æŒçš„è¯­è¨€å¯¹
    
    def _zh_to_en(self, text: str) -> str:
        """ä¸­æ–‡åˆ°è‹±æ–‡"""
        result = text
        for zh, en in self.zh_to_en.items():
            result = result.replace(zh, en)
        
        # æ¨¡æ‹Ÿæ–‡åŒ–æ¦‚å¿µä¸¢å¤±
        for zh, en in self.problematic_translations.items():
            if zh in result:
                result = result.replace(zh, en)
                # æ ‡è®°æ–‡åŒ–æ¦‚å¿µå¯èƒ½ä¸¢å¤±
                result += " [CULTURAL_CONTEXT_LOST]"
        
        return result
    
    def _en_to_zh(self, text: str) -> str:
        """è‹±æ–‡åˆ°ä¸­æ–‡"""
        result = text
        for en, zh in self.en_to_zh.items():
            result = result.replace(en, zh)
        
        # ç§»é™¤æ ‡è®°
        result = result.replace(" [CULTURAL_CONTEXT_LOST]", "")
        
        return result


class MockLLM:
    """
    æ¨¡æ‹ŸLLM - å…·æœ‰å¯æ§çš„è·¨è¯­è¨€å’Œè¯­ç¯‡é²æ£’æ€§ç¼ºé™·
    """
    
    def __init__(self, seed: int = 42):
        random.seed(seed)
        self.translator = MockTranslator()
        
        # çŸ¥è¯†åº“
        self.knowledge_base = {
            "ä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨": "å…‰åˆä½œç”¨æ˜¯æ¤ç‰©åˆ©ç”¨å…‰èƒ½å°†äºŒæ°§åŒ–ç¢³å’Œæ°´è½¬åŒ–ä¸ºæœ‰æœºç‰©å’Œæ°§æ°”çš„è¿‡ç¨‹ã€‚",
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œç ”ç©¶å¦‚ä½•è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½ã€‚",
            "æ˜¥èŠ‚æ˜¯ä»€ä¹ˆ": "æ˜¥èŠ‚æ˜¯ä¸­å›½æœ€é‡è¦çš„ä¼ ç»ŸèŠ‚æ—¥ï¼Œè±¡å¾ç€æ–°çš„ä¸€å¹´çš„å¼€å§‹ã€‚",
        }
    
    def generate(self, prompt: str, language: str = "zh") -> str:
        """ç”Ÿæˆå›ç­”"""
        # æ¸…ç†è¾“å…¥
        clean_prompt = prompt.strip().replace("ï¼Ÿ", "").replace("?", "")
        
        # å°è¯•åŒ¹é…çŸ¥è¯†åº“
        for key, value in self.knowledge_base.items():
            similarity = self._text_similarity(clean_prompt, key)
            if similarity > 0.6:
                # æ¨¡æ‹Ÿè·¨è¯­è¨€é—®é¢˜ï¼šå¦‚æœè¾“å…¥æ˜¯ç¿»è¯‘åçš„ï¼Œå¯èƒ½åŒ¹é…å¤±è´¥
                if "[CULTURAL_CONTEXT_LOST]" in prompt:
                    return "è¿™ä¸ªé—®é¢˜æ¶‰åŠä¸€äº›æ–‡åŒ–æ¦‚å¿µï¼Œæˆ‘å¯èƒ½éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡æ¥å‡†ç¡®å›ç­”ã€‚"
                return value
        
        # é»˜è®¤å›ç­”
        return "è¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„é—®é¢˜ï¼Œä½†æˆ‘éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡æ¥å›ç­”ã€‚"
    
    def summarize(self, text: str) -> str:
        """ç”Ÿæˆæ‘˜è¦"""
        # æå–å…³é”®å¥å­
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        key_sentences = [s for s in sentences if len(s) > 10][:2]
        
        # æ¨¡æ‹Ÿè¯­ç¯‡çº§é—®é¢˜ï¼šå¦‚æœæ–‡æœ¬ç»“æ„æ··ä¹±ï¼Œæ‘˜è¦è´¨é‡ä¸‹é™
        if "[REORDERED]" in text:
            return "è¿™æ®µæ–‡æœ¬çš„ç»“æ„æœ‰äº›æ··ä¹±ï¼Œæˆ‘éœ€è¦æ›´å¤šä¿¡æ¯æ¥ç”Ÿæˆå‡†ç¡®çš„æ‘˜è¦ã€‚"
        
        return "ã€‚".join(key_sentences) + "ã€‚"
    
    def answer_coreference(self, text: str, question: str) -> str:
        """å›ç­”æŒ‡ä»£é—®é¢˜"""
        # æ¨¡æ‹ŸæŒ‡ä»£æ¶ˆè§£ç¼ºé™·
        if "ä»–" in question:
            # ç®€å•è§„åˆ™ï¼šå¦‚æœæ–‡æœ¬ä¸­æœ‰å¤šä¸ªç”·æ€§åå­—ï¼Œå¯èƒ½æŒ‡ä»£é”™è¯¯
            names = re.findall(r'[\u4e00-\u9fa5]{2,3}', text)
            if len(names) >= 2:
                # 50%æ¦‚ç‡æŒ‡ä»£é”™è¯¯
                if random.random() < 0.5:
                    return f"ä»–æŒ‡çš„æ˜¯{names[1]}"  # é”™è¯¯ï¼šåº”è¯¥æ˜¯names[0]
                else:
                    return f"ä»–æŒ‡çš„æ˜¯{names[0]}"
        
        return "æˆ‘ä¸ç¡®å®šæŒ‡ä»£çš„æ˜¯è°ã€‚"
    
    def _text_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        return SequenceMatcher(None, text1, text2).ratio()


class CrossLingualTester:
    """è·¨è¯­è¨€é²æ£’æ€§æµ‹è¯•å™¨"""
    
    def __init__(self, model: MockLLM, translator: MockTranslator):
        self.model = model
        self.translator = translator
    
    def test_translation_roundtrip(self, text: str) -> RobustnessResult:
        """
        ç¿»è¯‘å¾€è¿”æµ‹è¯•
        """
        print(f"\n{'='*60}")
        print(f"ã€ç¿»è¯‘å¾€è¿”æµ‹è¯•ã€‘")
        print(f"{'='*60}")
        print(f"åŸæ–‡: {text}")
        
        # Step 1: ä¸­æ–‡ â†’ è‹±æ–‡
        translated = self.translator.translate(text, "zh", "en")
        print(f"\nç¿»è¯‘(zhâ†’en): {translated}")
        
        # Step 2: è‹±æ–‡ â†’ ä¸­æ–‡
        back_translated = self.translator.translate(translated, "en", "zh")
        print(f"å›è¯‘(enâ†’zh): {back_translated}")
        
        # Step 3: è¯­ä¹‰ä¸€è‡´æ€§è®¡ç®—
        consistency = self.model._text_similarity(text, back_translated)
        
        # Step 4: å…³é”®ä¿¡æ¯ä¿ç•™æ£€æŸ¥
        key_info_original = self.extract_key_info(text)
        key_info_back = self.extract_key_info(back_translated)
        
        if key_info_original:
            retention = len(key_info_original & key_info_back) / len(key_info_original)
        else:
            retention = 1.0
        
        print(f"\nè¯­ä¹‰ä¸€è‡´æ€§: {consistency:.3f}")
        print(f"å…³é”®ä¿¡æ¯ä¿ç•™ç‡: {retention:.1%}")
        
        # åˆ¤æ–­é²æ£’æ€§
        is_robust = consistency > 0.85 and retention > 0.9
        
        if consistency > 0.9 and retention > 0.95:
            risk_level = RobustnessLevel.HIGH
            message = "ç¿»è¯‘å¾€è¿”é²æ£’æ€§è‰¯å¥½"
        elif consistency > 0.75 and retention > 0.8:
            risk_level = RobustnessLevel.MEDIUM
            message = "ç¿»è¯‘å¾€è¿”å­˜åœ¨ä¸€å®šè¯­ä¹‰æ¼‚ç§»"
        else:
            risk_level = RobustnessLevel.LOW
            message = "ç¿»è¯‘å¾€è¿”å­˜åœ¨ä¸¥é‡è¯­ä¹‰æ¼‚ç§»"
        
        print(f"é²æ£’æ€§åˆ¤å®š: {risk_level.value}")
        print(f"ç»“è®º: {message}")
        
        return RobustnessResult(
            test_type=RobustnessTestType.TRANSLATION_ROUNDTRIP,
            original=text,
            modified=back_translated,
            consistency_score=consistency,
            key_info_retention=retention,
            is_robust=is_robust,
            risk_level=risk_level,
            message=message,
            details={"translated": translated, "back_translated": back_translated}
        )
    
    def test_multilingual_parallel(self, question: str) -> RobustnessResult:
        """
        å¤šè¯­è¨€å¹³è¡Œæµ‹è¯•
        """
        print(f"\n{'='*60}")
        print(f"ã€å¤šè¯­è¨€å¹³è¡Œæµ‹è¯•ã€‘")
        print(f"{'='*60}")
        print(f"åŸé—®é¢˜(zh): {question}")
        
        # ç¿»è¯‘åˆ°ä¸åŒè¯­è¨€
        languages = ["en"]
        translations = {"zh": question}
        
        for lang in languages:
            translations[lang] = self.translator.translate(question, "zh", lang)
        
        print(f"\nç¿»è¯‘ç»“æœ:")
        for lang, trans in translations.items():
            print(f"  {lang}: {trans}")
        
        # è·å–å„è¯­è¨€ç­”æ¡ˆ
        answers = {}
        for lang, trans in translations.items():
            answers[lang] = self.model.generate(trans, lang)
        
        print(f"\nå„è¯­è¨€ç­”æ¡ˆ:")
        for lang, ans in answers.items():
            print(f"  {lang}: {ans}")
        
        # è®¡ç®—ç­”æ¡ˆä¸€è‡´æ€§ï¼ˆä¸­æ–‡vsè‹±æ–‡ï¼‰
        if "zh" in answers and "en" in answers:
            consistency = self.model._text_similarity(answers["zh"], answers["en"])
        else:
            consistency = 1.0
        
        print(f"\nç­”æ¡ˆä¸€è‡´æ€§(zh vs en): {consistency:.3f}")
        
        # åˆ¤æ–­é²æ£’æ€§
        is_robust = consistency > 0.8
        
        if consistency > 0.9:
            risk_level = RobustnessLevel.HIGH
            message = "å¤šè¯­è¨€ç­”æ¡ˆä¸€è‡´æ€§è‰¯å¥½"
        elif consistency > 0.7:
            risk_level = RobustnessLevel.MEDIUM
            message = "å¤šè¯­è¨€ç­”æ¡ˆå­˜åœ¨ä¸€å®šå·®å¼‚"
        else:
            risk_level = RobustnessLevel.LOW
            message = "å¤šè¯­è¨€ç­”æ¡ˆå­˜åœ¨ä¸¥é‡ä¸ä¸€è‡´"
        
        print(f"é²æ£’æ€§åˆ¤å®š: {risk_level.value}")
        print(f"ç»“è®º: {message}")
        
        return RobustnessResult(
            test_type=RobustnessTestType.MULTILINGUAL_PARALLEL,
            original=question,
            modified=str(translations),
            consistency_score=consistency,
            key_info_retention=consistency,
            is_robust=is_robust,
            risk_level=risk_level,
            message=message,
            details={"answers": answers}
        )
    
    def extract_key_info(self, text: str) -> Set[str]:
        """æå–å…³é”®ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # æå–å®ä½“ï¼ˆä¸­æ–‡åè¯ï¼‰
        entities = set(re.findall(r'[\u4e00-\u9fa5]{2,10}', text))
        # æå–æ•°å­—
        numbers = set(re.findall(r'\d+', text))
        return entities | numbers


class DiscourseTester:
    """è¯­ç¯‡çº§æ”¹å†™æµ‹è¯•å™¨"""
    
    def __init__(self, model: MockLLM):
        self.model = model
    
    def test_paragraph_reordering(self, text: str) -> RobustnessResult:
        """
        æ®µè½é‡ç»„æµ‹è¯•
        """
        print(f"\n{'='*60}")
        print(f"ã€æ®µè½é‡ç»„æµ‹è¯•ã€‘")
        print(f"{'='*60}")
        
        paragraphs = [p.strip() for p in text.split("\n\n") if p.strip()]
        print(f"åŸæ–‡æ®µè½æ•°: {len(paragraphs)}")
        for i, p in enumerate(paragraphs, 1):
            print(f"  æ®µè½{i}: {p[:30]}...")
        
        # ç”Ÿæˆé‡ç»„å˜ä½“ï¼ˆåè½¬ï¼‰
        reordered = paragraphs[::-1]
        reordered_text = "\n\n".join(reordered)
        reordered_text += " [REORDERED]"  # æ ‡è®°é‡ç»„
        
        print(f"\né‡ç»„åæ®µè½é¡ºåº: {list(range(len(paragraphs), 0, -1))}")
        
        # è·å–æ‘˜è¦
        original_summary = self.model.summarize(text)
        reordered_summary = self.model.summarize(reordered_text)
        
        print(f"\nåŸæ–‡æ‘˜è¦: {original_summary}")
        print(f"é‡ç»„åæ‘˜è¦: {reordered_summary}")
        
        # æ£€æŸ¥ä¸€è‡´æ€§
        consistency = self.model._text_similarity(original_summary, reordered_summary)
        
        # æ£€æŸ¥å…³é”®äº‹å®ä¿ç•™
        key_facts_original = self.extract_key_facts(original_summary)
        key_facts_reordered = self.extract_key_facts(reordered_summary)
        
        if key_facts_original:
            retention = len(key_facts_original & key_facts_reordered) / len(key_facts_original)
        else:
            retention = 1.0
        
        print(f"\næ‘˜è¦ä¸€è‡´æ€§: {consistency:.3f}")
        print(f"å…³é”®äº‹å®ä¿ç•™ç‡: {retention:.1%}")
        
        # åˆ¤æ–­é²æ£’æ€§
        is_robust = consistency > 0.8 and retention > 0.9
        
        if consistency > 0.9 and retention > 0.95:
            risk_level = RobustnessLevel.HIGH
            message = "æ®µè½é‡ç»„é²æ£’æ€§è‰¯å¥½"
        elif consistency > 0.7 and retention > 0.8:
            risk_level = RobustnessLevel.MEDIUM
            message = "æ®µè½é‡ç»„å­˜åœ¨ä¸€å®šå½±å“"
        else:
            risk_level = RobustnessLevel.LOW
            message = "æ®µè½é‡ç»„ä¸¥é‡å½±å“ç†è§£"
        
        print(f"é²æ£’æ€§åˆ¤å®š: {risk_level.value}")
        print(f"ç»“è®º: {message}")
        
        return RobustnessResult(
            test_type=RobustnessTestType.PARAGRAPH_REORDERING,
            original=text,
            modified=reordered_text,
            consistency_score=consistency,
            key_info_retention=retention,
            is_robust=is_robust,
            risk_level=risk_level,
            message=message,
            details={"original_summary": original_summary, "reordered_summary": reordered_summary}
        )
    
    def test_coreference_resolution(self) -> RobustnessResult:
        """
        æŒ‡ä»£æ¶ˆè§£é²æ£’æ€§æµ‹è¯•
        """
        print(f"\n{'='*60}")
        print(f"ã€æŒ‡ä»£æ¶ˆè§£æµ‹è¯•ã€‘")
        print(f"{'='*60}")
        
        # æµ‹è¯•ç”¨ä¾‹
        test_cases = [
            {
                "text": "å¼ ä¸‰å’Œæå››å»å…¬å›­ã€‚ä»–åœ¨é‚£é‡Œé‡åˆ°äº†ç‹äº”ã€‚",
                "question": "ä»–æŒ‡çš„æ˜¯è°ï¼Ÿ",
                "expected": "å¼ ä¸‰"
            },
            {
                "text": "å…¬å¸Aæ¨å‡ºäº†äº§å“Xã€‚è¿™æ¬¾äº§å“éå¸¸å—æ¬¢è¿ã€‚",
                "question": "è¿™æ¬¾äº§å“æŒ‡çš„æ˜¯ä»€ä¹ˆï¼Ÿ",
                "expected": "äº§å“X"
            }
        ]
        
        correct_count = 0
        results = []
        
        for case in test_cases:
            print(f"\næµ‹è¯•ç”¨ä¾‹: {case['text']}")
            print(f"é—®é¢˜: {case['question']}")
            
            answer = self.model.answer_coreference(case['text'], case['question'])
            print(f"æ¨¡å‹å›ç­”: {answer}")
            
            is_correct = case['expected'] in answer
            if is_correct:
                correct_count += 1
                print("âœ… æ­£ç¡®")
            else:
                print("âŒ é”™è¯¯")
            
            results.append({
                "text": case['text'],
                "expected": case['expected'],
                "answer": answer,
                "correct": is_correct
            })
        
        accuracy = correct_count / len(test_cases) if test_cases else 0.0
        
        print(f"\næŒ‡ä»£æ¶ˆè§£å‡†ç¡®ç‡: {accuracy:.1%}")
        
        # åˆ¤æ–­é²æ£’æ€§
        is_robust = accuracy > 0.95
        
        if accuracy > 0.95:
            risk_level = RobustnessLevel.HIGH
            message = "æŒ‡ä»£æ¶ˆè§£é²æ£’æ€§è‰¯å¥½"
        elif accuracy > 0.8:
            risk_level = RobustnessLevel.MEDIUM
            message = "æŒ‡ä»£æ¶ˆè§£å­˜åœ¨ä¸€å®šé—®é¢˜"
        else:
            risk_level = RobustnessLevel.LOW
            message = "æŒ‡ä»£æ¶ˆè§£å­˜åœ¨ä¸¥é‡é—®é¢˜"
        
        print(f"é²æ£’æ€§åˆ¤å®š: {risk_level.value}")
        print(f"ç»“è®º: {message}")
        
        return RobustnessResult(
            test_type=RobustnessTestType.COREFERENCE_RESOLUTION,
            original=str(test_cases),
            modified="",
            consistency_score=accuracy,
            key_info_retention=accuracy,
            is_robust=is_robust,
            risk_level=risk_level,
            message=message,
            details={"results": results, "accuracy": accuracy}
        )
    
    def test_detail_preservation(self) -> RobustnessResult:
        """
        ç»†èŠ‚ä¿ç•™æµ‹è¯•
        """
        print(f"\n{'='*60}")
        print(f"ã€ç»†èŠ‚ä¿ç•™æµ‹è¯•ã€‘")
        print(f"{'='*60}")
        
        # åŒ…å«å…³é”®ç»†èŠ‚çš„æ–‡æœ¬
        detailed_text = "è¯·åœ¨24å°æ—¶å†…å®Œæˆæ”¯ä»˜ï¼Œå¦åˆ™è®¢å•å°†è‡ªåŠ¨å–æ¶ˆã€‚é€€æ¬¾å°†åœ¨3-5ä¸ªå·¥ä½œæ—¥å†…åˆ°è´¦ã€‚"
        simplified_text = "è¯·å°½å¿«å®Œæˆæ”¯ä»˜ã€‚é€€æ¬¾ä¼šå¾ˆå¿«åˆ°è´¦ã€‚"
        
        print(f"è¯¦ç»†ç‰ˆæœ¬: {detailed_text}")
        print(f"ç®€åŒ–ç‰ˆæœ¬: {simplified_text}")
        
        # æå–å…³é”®ç»†èŠ‚
        key_details = ["24å°æ—¶", "è‡ªåŠ¨å–æ¶ˆ", "3-5ä¸ªå·¥ä½œæ—¥"]
        
        # æ£€æŸ¥ç®€åŒ–ç‰ˆæœ¬ä¿ç•™äº†å¤šå°‘ç»†èŠ‚
        preserved_details = [d for d in key_details if d in simplified_text]
        retention = len(preserved_details) / len(key_details)
        
        print(f"\nå…³é”®ç»†èŠ‚: {key_details}")
        print(f"ä¿ç•™çš„ç»†èŠ‚: {preserved_details}")
        print(f"ç»†èŠ‚ä¿ç•™ç‡: {retention:.1%}")
        
        # åˆ¤æ–­é²æ£’æ€§
        is_robust = retention > 0.9
        
        if retention > 0.95:
            risk_level = RobustnessLevel.HIGH
            message = "ç»†èŠ‚ä¿ç•™è‰¯å¥½"
        elif retention > 0.7:
            risk_level = RobustnessLevel.MEDIUM
            message = "éƒ¨åˆ†ç»†èŠ‚ä¸¢å¤±"
        else:
            risk_level = RobustnessLevel.LOW
            message = "å…³é”®ç»†èŠ‚ä¸¥é‡ä¸¢å¤±"
        
        print(f"é²æ£’æ€§åˆ¤å®š: {risk_level.value}")
        print(f"ç»“è®º: {message}")
        
        return RobustnessResult(
            test_type=RobustnessTestType.DETAIL_PRESERVATION,
            original=detailed_text,
            modified=simplified_text,
            consistency_score=retention,
            key_info_retention=retention,
            is_robust=is_robust,
            risk_level=risk_level,
            message=message,
            details={"key_details": key_details, "preserved": preserved_details}
        )
    
    def extract_key_facts(self, text: str) -> Set[str]:
        """æå–å…³é”®äº‹å®"""
        # æå–å®ä½“
        entities = set(re.findall(r'[\u4e00-\u9fa5]{2,10}', text))
        # æå–æ•°å­—
        numbers = set(re.findall(r'\d+', text))
        return entities | numbers


class RobustnessEvaluator:
    """é²æ£’æ€§ç»¼åˆè¯„ä¼°å™¨"""
    
    def __init__(self):
        self.results: List[RobustnessResult] = []
    
    def add_result(self, result: RobustnessResult):
        """æ·»åŠ æµ‹è¯•ç»“æœ"""
        self.results.append(result)
    
    def generate_report(self) -> Dict:
        """ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š"""
        print(f"\n{'='*70}")
        print(f"ã€ç»¼åˆé²æ£’æ€§è¯„ä¼°æŠ¥å‘Šã€‘")
        print(f"{'='*70}")
        
        # ç»Ÿè®¡å„é£é™©ç­‰çº§
        risk_counts = {level: 0 for level in RobustnessLevel}
        for result in self.results:
            risk_counts[result.risk_level] += 1
        
        print(f"\né£é™©åˆ†å¸ƒç»Ÿè®¡:")
        for level, count in risk_counts.items():
            if count > 0:
                print(f"  {level.value}: {count} é¡¹")
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        level_scores = {
            RobustnessLevel.HIGH: 1.0,
            RobustnessLevel.MEDIUM: 0.6,
            RobustnessLevel.LOW: 0.3,
            RobustnessLevel.CRITICAL: 0.0
        }
        
        total_score = sum(level_scores[r.risk_level] for r in self.results)
        avg_score = total_score / len(self.results) if self.results else 0.0
        
        print(f"\nç»¼åˆé²æ£’æ€§å¾—åˆ†: {avg_score:.2f}/1.0")
        
        # æ•´ä½“è¯„çº§
        if avg_score >= 0.8:
            overall_level = RobustnessLevel.HIGH
            recommendation = "é²æ£’æ€§è‰¯å¥½ï¼Œå¯æŠ•å…¥ç”Ÿäº§ç¯å¢ƒ"
        elif avg_score >= 0.5:
            overall_level = RobustnessLevel.MEDIUM
            recommendation = "é²æ£’æ€§ä¸€èˆ¬ï¼Œå»ºè®®ä¼˜åŒ–åä¸Šçº¿"
        else:
            overall_level = RobustnessLevel.LOW
            recommendation = "é²æ£’æ€§ä¸è¶³ï¼Œéœ€é‡ç‚¹æ”¹è¿›"
        
        print(f"æ•´ä½“è¯„çº§: {overall_level.value}")
        print(f"å»ºè®®: {recommendation}")
        
        # è„†å¼±ç‚¹åˆ†æ
        print(f"\nè¯†åˆ«çš„è„†å¼±ç‚¹:")
        vulnerable_tests = [r for r in self.results if r.risk_level in [RobustnessLevel.LOW, RobustnessLevel.CRITICAL]]
        if vulnerable_tests:
            for r in vulnerable_tests:
                print(f"  âš ï¸ {r.test_type.value}: {r.message}")
        else:
            print(f"  âœ… æœªå‘ç°æ˜æ˜¾è„†å¼±ç‚¹")
        
        return {
            "overall_score": avg_score,
            "overall_level": overall_level,
            "risk_distribution": risk_counts,
            "vulnerable_points": len(vulnerable_tests),
            "recommendation": recommendation
        }


# ============ Pytest æµ‹è¯•ç”¨ä¾‹ ============

@pytest.fixture
def mock_model():
    """æä¾›Mock LLMå®ä¾‹"""
    return MockLLM(seed=42)


@pytest.fixture
def mock_translator():
    """æä¾›Mockç¿»è¯‘å™¨"""
    return MockTranslator(seed=42)


@pytest.fixture
def cross_lingual_tester(mock_model, mock_translator):
    """æä¾›è·¨è¯­è¨€æµ‹è¯•å™¨"""
    return CrossLingualTester(mock_model, mock_translator)


@pytest.fixture
def discourse_tester(mock_model):
    """æä¾›è¯­ç¯‡æµ‹è¯•å™¨"""
    return DiscourseTester(mock_model)


@pytest.fixture
def evaluator():
    """æä¾›è¯„ä¼°å™¨"""
    return RobustnessEvaluator()


class TestCrossLingualRobustness:
    """è·¨è¯­è¨€é²æ£’æ€§æµ‹è¯•å¥—ä»¶"""
    
    def test_translation_roundtrip(self, cross_lingual_tester, evaluator):
        """æµ‹è¯•ç¿»è¯‘å¾€è¿”é²æ£’æ€§ï¼ˆå…³é”®æµ‹è¯•ï¼‰"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•1ã€‘ç¿»è¯‘å¾€è¿”é²æ£’æ€§éªŒè¯ï¼ˆå…³é”®æµ‹è¯•ï¼‰")
        print("="*60)
        
        text = "ä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ï¼Ÿ"
        result = cross_lingual_tester.test_translation_roundtrip(text)
        evaluator.add_result(result)
        
        # éªŒè¯ï¼šè¯­ä¹‰ä¸€è‡´æ€§åº”å¯è®¡ç®—
        assert 0 <= result.consistency_score <= 1.0, "ä¸€è‡´æ€§åˆ†æ•°åº”åœ¨0-1ä¹‹é—´"
        
        # é£é™©éªŒè¯
        if result.risk_level in [RobustnessLevel.LOW, RobustnessLevel.CRITICAL]:
            print(f"\nğŸ”´ å‘ç°è·¨è¯­è¨€é²æ£’æ€§é—®é¢˜: {result.message}")
        
        print("\nâœ… ç¿»è¯‘å¾€è¿”é²æ£’æ€§æµ‹è¯•é€šè¿‡")
    
    def test_cultural_concept_preservation(self, cross_lingual_tester, evaluator):
        """æµ‹è¯•æ–‡åŒ–æ¦‚å¿µä¿ç•™"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•2ã€‘æ–‡åŒ–æ¦‚å¿µä¿ç•™éªŒè¯ï¼ˆå…³é”®æµ‹è¯•ï¼‰")
        print("="*60)
        
        # åŒ…å«æ–‡åŒ–æ¦‚å¿µçš„æ–‡æœ¬
        text = "æ˜¥èŠ‚æ˜¯ä¸­å›½æœ€é‡è¦çš„ä¼ ç»ŸèŠ‚æ—¥ã€‚"
        result = cross_lingual_tester.test_translation_roundtrip(text)
        evaluator.add_result(result)
        
        # éªŒè¯ï¼šæ–‡åŒ–æ¦‚å¿µåº”è¢«ä¿ç•™
        print(f"\næ–‡åŒ–æ¦‚å¿µ'æ˜¥èŠ‚'ä¿ç•™æ£€æŸ¥:")
        if "æ˜¥èŠ‚" in result.modified:
            print("âœ… æ–‡åŒ–æ¦‚å¿µä¿ç•™")
        else:
            print("âš ï¸ æ–‡åŒ–æ¦‚å¿µå¯èƒ½ä¸¢å¤±")
        
        print("\nâœ… æ–‡åŒ–æ¦‚å¿µä¿ç•™æµ‹è¯•é€šè¿‡")
    
    def test_multilingual_parallel(self, cross_lingual_tester, evaluator):
        """æµ‹è¯•å¤šè¯­è¨€å¹³è¡Œä¸€è‡´æ€§"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•3ã€‘å¤šè¯­è¨€å¹³è¡Œä¸€è‡´æ€§éªŒè¯")
        print("="*60)
        
        question = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
        result = cross_lingual_tester.test_multilingual_parallel(question)
        evaluator.add_result(result)
        
        # éªŒè¯ï¼šå¤šè¯­è¨€ç­”æ¡ˆåº”ä¸€è‡´
        assert result.consistency_score >= 0, "ä¸€è‡´æ€§åˆ†æ•°åº”éè´Ÿ"
        
        print("\nâœ… å¤šè¯­è¨€å¹³è¡Œä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")


class TestDiscourseRobustness:
    """è¯­ç¯‡çº§é²æ£’æ€§æµ‹è¯•å¥—ä»¶"""
    
    def test_paragraph_reordering(self, discourse_tester, evaluator):
        """æµ‹è¯•æ®µè½é‡ç»„é²æ£’æ€§ï¼ˆå…³é”®æµ‹è¯•ï¼‰"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•4ã€‘æ®µè½é‡ç»„é²æ£’æ€§éªŒè¯ï¼ˆå…³é”®æµ‹è¯•ï¼‰")
        print("="*60)
        
        text = """å…¬å¸Aåœ¨2020å¹´æ¨å‡ºäº†äº§å“Xã€‚

è¿™æ¬¾äº§å“å¤§è·æˆåŠŸï¼Œé”€é‡çªç ´ç™¾ä¸‡ã€‚

ç„¶è€Œï¼Œç«äº‰å¯¹æ‰‹å…¬å¸Båœ¨2021å¹´æ¨å‡ºäº†ç±»ä¼¼äº§å“ã€‚"""
        
        result = discourse_tester.test_paragraph_reordering(text)
        evaluator.add_result(result)
        
        # éªŒè¯ï¼šæ®µè½é‡ç»„ä¸åº”ä¸¥é‡å½±å“ç†è§£
        assert result.consistency_score >= 0, "ä¸€è‡´æ€§åˆ†æ•°åº”éè´Ÿ"
        
        if result.risk_level in [RobustnessLevel.LOW, RobustnessLevel.CRITICAL]:
            print(f"\nğŸ”´ å‘ç°è¯­ç¯‡çº§é²æ£’æ€§é—®é¢˜: {result.message}")
        
        print("\nâœ… æ®µè½é‡ç»„é²æ£’æ€§æµ‹è¯•é€šè¿‡")
    
    def test_coreference_resolution(self, discourse_tester, evaluator):
        """æµ‹è¯•æŒ‡ä»£æ¶ˆè§£é²æ£’æ€§"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•5ã€‘æŒ‡ä»£æ¶ˆè§£é²æ£’æ€§éªŒè¯")
        print("="*60)
        
        result = discourse_tester.test_coreference_resolution()
        evaluator.add_result(result)
        
        # éªŒè¯ï¼šå‡†ç¡®ç‡åº”å¯è®¡ç®—
        assert 0 <= result.consistency_score <= 1.0, "å‡†ç¡®ç‡åº”åœ¨0-1ä¹‹é—´"
        
        if result.consistency_score < 0.8:
            print(f"\nâš ï¸ æŒ‡ä»£æ¶ˆè§£å‡†ç¡®ç‡è¾ƒä½({result.consistency_score:.1%})")
        
        print("\nâœ… æŒ‡ä»£æ¶ˆè§£é²æ£’æ€§æµ‹è¯•é€šè¿‡")
    
    def test_detail_preservation(self, discourse_tester, evaluator):
        """æµ‹è¯•ç»†èŠ‚ä¿ç•™"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•6ã€‘ç»†èŠ‚ä¿ç•™éªŒè¯")
        print("="*60)
        
        result = discourse_tester.test_detail_preservation()
        evaluator.add_result(result)
        
        # éªŒè¯ï¼šå…³é”®ç»†èŠ‚åº”è¢«ä¿ç•™
        assert result.key_info_retention >= 0, "ä¿ç•™ç‡åº”éè´Ÿ"
        
        if result.key_info_retention < 0.7:
            print(f"\nâš ï¸ å…³é”®ç»†èŠ‚ä¿ç•™ç‡è¾ƒä½({result.key_info_retention:.1%})")
        
        print("\nâœ… ç»†èŠ‚ä¿ç•™æµ‹è¯•é€šè¿‡")


class TestComprehensiveEvaluation:
    """ç»¼åˆè¯„ä¼°æµ‹è¯•"""
    
    def test_comprehensive_robustness_evaluation(self, cross_lingual_tester, discourse_tester, evaluator):
        """ç»¼åˆé²æ£’æ€§è¯„ä¼°"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•7ã€‘ç»¼åˆé²æ£’æ€§è¯„ä¼°")
        print("="*60)
        
        # è¿è¡Œå¤šä¸ªæµ‹è¯•
        test_cases = [
            ("ä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ï¼Ÿ", "translation"),
            ("æ˜¥èŠ‚æ˜¯ä»€ä¹ˆï¼Ÿ", "cultural"),
        ]
        
        for text, test_type in test_cases:
            if test_type == "translation":
                result = cross_lingual_tester.test_translation_roundtrip(text)
            else:
                result = cross_lingual_tester.test_translation_roundtrip(text)
            evaluator.add_result(result)
        
        # è¯­ç¯‡æµ‹è¯•
        discourse_tests = [
            discourse_tester.test_coreference_resolution,
            discourse_tester.test_detail_preservation,
        ]
        
        for test in discourse_tests:
            result = test()
            evaluator.add_result(result)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = evaluator.generate_report()
        
        # éªŒè¯æŠ¥å‘Šç»“æ„
        assert "overall_score" in report, "æŠ¥å‘Šåº”åŒ…å«ç»¼åˆå¾—åˆ†"
        assert "overall_level" in report, "æŠ¥å‘Šåº”åŒ…å«æ•´ä½“è¯„çº§"
        assert "recommendation" in report, "æŠ¥å‘Šåº”åŒ…å«å»ºè®®"
        
        print("\nâœ… ç»¼åˆé²æ£’æ€§è¯„ä¼°å®Œæˆ")


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    pytest.main([__file__, "-v", "-s"])

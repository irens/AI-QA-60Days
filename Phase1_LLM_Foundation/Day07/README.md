# Day 07: 模型版本迭代与回归测试——基准测试套件构建

## 🎯 1. 核心风险与测试目标

### 1.1 测试工程师视角
> **核心原则**：开发只管跑通，我们要想办法把它搞崩溃。模型版本升级是AI系统的"心脏手术"——没有回归测试的升级就是赌博。

### 1.2 业务风险点

| 风险类别 | 具体风险 | 线上事故场景 |
|---------|---------|-------------|
| **回归缺陷** | 新版本修复A问题但引入B问题 | 升级后原有功能失效，用户投诉激增 |
| **性能退化** | 新版本精度提升但延迟翻倍 | 系统响应变慢，用户体验恶化 |
| **行为不一致** | 相同输入新旧版本输出矛盾 | 缓存与实时请求结果不一致，数据混乱 |
| **基准缺失** | 无历史对比无法评估升级效果 | 无法判断升级是成功还是失败 |
| **覆盖率不足** | 测试用例未覆盖核心场景 | 边缘场景上线后出问题 |

### 1.3 测试思路

**基准测试套件构建策略**：
- **黄金数据集**：覆盖核心业务场景的100+测试用例
- **多维度评估**：准确性、延迟、稳定性、安全性四维打分
- **快照对比**：新旧版本输出逐条对比，标记差异
- **回归阈值**：设定可接受的性能退化范围（如延迟<10%）

**版本对比策略**：
- **A/B测试框架**：流量切分对比新旧版本
- **影子测试**：新版本处理生产流量但不返回结果
- ** Canary发布**：小流量验证后逐步全量

**自动化回归策略**：
- **CI集成**：每次模型变更自动触发回归测试
- **告警机制**：回归失败自动阻塞发布
- **报告生成**：自动生成版本对比报告供决策

---

## 📚 2. 模型版本回归测试原理（测试必备知识）

### 2.1 为什么需要回归测试

```
┌─────────────────────────────────────────────────────────────────┐
│                    无回归测试 vs 有回归测试对比                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  无回归测试（赌博式升级）                                         │
│  ───────────────────────                                         │
│  开发: "GPT-4-turbo比GPT-4快50%，我们升级吧"                     │
│  测试: ?                                                         │
│  上线: 直接全量切换                                               │
│  结果: 3天后发现新模型在中文场景准确率下降15% 🔥                   │
│  回滚: 紧急回滚，用户流失，品牌受损                               │
│                                                                 │
│  有回归测试（科学式升级）                                         │
│  ───────────────────────                                         │
│  开发: "GPT-4-turbo比GPT-4快50%，我们升级吧"                     │
│  测试: "先跑回归测试套件，对比200个核心场景"                      │
│  结果: 发现中文场景准确率-15%，英文场景+5%，延迟-50%             │
│  决策: "中文业务暂不升级，英文业务可升级"                         │
│  上线: 分场景灰度发布，零事故                                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 基准测试套件核心组成

| 组件 | 说明 | 示例 |
|-----|------|------|
| **测试用例集** | 覆盖核心业务的输入-预期输出对 | 客服场景50条、代码生成30条、文案创作20条 |
| **评估指标** | 多维度质量度量 | 准确性、延迟、多样性、安全性 |
| **基线版本** | 作为对比基准的模型版本 | gpt-3.5-turbo-0613 |
| **回归阈值** | 可接受的性能变化范围 | 准确率下降<5%，延迟增加<20% |
| **报告模板** | 标准化对比报告格式 | 差异项高亮、风险评级、决策建议 |

### 2.3 回归测试核心算法

```python
# 核心回归测试逻辑

class RegressionTester:
    """回归测试器"""
    
    def compare_versions(self, baseline_results, new_results, thresholds):
        """
        对比两个版本的测试结果
        
        Returns:
            回归报告，包含通过/失败项
        """
        report = {
            "passed": [],
            "failed": [],
            "warnings": []
        }
        
        for metric in ["accuracy", "latency", "diversity", "safety"]:
            baseline = baseline_results[metric]
            new = new_results[metric]
            threshold = thresholds[metric]
            
            change = (new - baseline) / baseline * 100
            
            if change < -threshold["max_degradation"]:
                report["failed"].append({
                    "metric": metric,
                    "baseline": baseline,
                    "new": new,
                    "change": change,
                    "reason": f"退化超过阈值 {threshold['max_degradation']}%"
                })
            elif change < 0:
                report["warnings"].append({
                    "metric": metric,
                    "change": change
                })
            else:
                report["passed"].append({
                    "metric": metric,
                    "change": change
                })
        
        return report
    
    def should_block_release(self, report):
        """
        判断是否应阻塞发布
        """
        critical_failures = [f for f in report["failed"] 
                           if f["metric"] in ["accuracy", "safety"]]
        return len(critical_failures) > 0
```

### 2.4 版本对比维度

```
┌─────────────────────────────────────────────────────────────────┐
│                      版本对比四维模型                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  准确性                                                          │
│  ─────                                                           │
│  • 任务完成率: 输出是否正确完成用户请求                          │
│  • 事实准确性: 输出是否包含错误信息                              │
│  • 格式合规性: JSON/XML等结构化输出是否正确                      │
│                                                                 │
│  延迟                                                            │
│  ────                                                            │
│  • P50延迟: 中位数响应时间                                       │
│  • P95延迟: 95%请求响应时间                                      │
│  • P99延迟: 长尾延迟                                             │
│  • 首Token时间: 流式输出首字时间                                 │
│                                                                 │
│  稳定性                                                          │
│  ────                                                            │
│  • 输出一致性: 相同输入多次调用输出相似度                        │
│  • 异常率: 报错/超时比例                                         │
│  • 边界行为: 极端输入处理稳定性                                  │
│                                                                 │
│  安全性                                                          │
│  ────                                                            │
│  • 有害内容: 是否生成违规内容                                    │
│  • Prompt注入: 是否更容易被攻击                                  │
│  • 隐私泄露: 是否泄露训练数据                                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 🧪 3. 实验验证任务

请运行本目录下的 `test_day07.py`，观察以下关键输出：

### 3.1 基准测试套件构建
- 黄金数据集加载与验证
- 多维度评估指标计算
- 基线版本测试结果记录

### 3.2 版本对比测试
- 模拟新旧版本差异
- 四维指标对比分析
- 差异项高亮展示

### 3.3 回归决策验证
- 回归阈值判定逻辑
- 发布阻塞条件验证
- 灰度发布建议生成

---

## 📝 4. 产出要求

将运行结果贴回给 Trae，让其生成 `report_day07.md` 质量分析报告。

报告应包含：
1. **基准测试套件报告**：测试用例覆盖率、评估指标完整性
2. **版本对比结果**：新旧版本四维指标差异分析
3. **回归决策建议**：是否通过回归测试、风险等级评估
4. **生产部署指南**：模型版本升级的CI/CD集成方案

# Day 03: 上下文窗口边界与长文本退化测试

## 🎯 1. 核心风险与测试目标

### 1.1 测试工程师视角
> **核心原则**：开发只管跑通，我们要想办法把它搞崩溃。上下文窗口是LLM的"内存限制"，边界行为决定系统可靠性。

### 1.2 业务风险点

| 风险类别 | 具体风险 | 线上事故场景 |
|---------|---------|-------------|
| **静默截断** | 超长输入被截断但无告警 | 法律合同审查漏掉关键条款，客户索赔百万 |
| **截断策略混乱** | 不同模型截断方式不一致 | 迁移模型后行为突变，生产环境故障 |
| **长文本退化** | 输入越长输出质量越差 | 长文档摘要质量不可接受，用户流失 |
| **有效窗口虚标** | 标称4K实际有效仅2K | 基于标称值设计的系统频繁失效 |
| **关键信息丢失** | 截断导致上下文不连贯 | 多轮对话历史丢失，答非所问 |
| **性能悬崖** | 接近窗口上限时延迟激增 | 用户体验恶化，系统超时崩溃 |

### 1.3 测试思路

**边界长度探测策略**：
- **精确边界测试**：构造窗口长度±1 token的输入，验证截断临界点
- **渐进压力测试**：从50%窗口逐步增加到110%，记录行为变化
- **截断位置探测**：验证是头部截断、尾部截断还是摘要截断
- **恢复能力测试**：截断后模型能否保持上下文连贯性

**长文本退化测试策略**：
- **质量衰减曲线**：逐步增加输入长度，记录输出质量指标
- **有效窗口标定**：找到输出质量可接受的最大输入长度
- **多轮累积测试**：模拟长对话场景，验证历史信息保留率

---

## 📚 2. 上下文窗口核心原理（测试必备知识）

### 2.1 上下文窗口是什么

上下文窗口(Context Window)是LLM能同时处理的token数量上限，相当于模型的"工作内存"：

```
┌─────────────────────────────────────────────────────────────┐
│                     上下文窗口 (如 4096 tokens)               │
├─────────────────────────────────────────────────────────────┤
│  System Prompt  │  History  │  Current Input  │  Response   │
│   (系统指令)    │ (历史对话) │   (当前输入)    │  (响应预留)  │
│    ~100 tokens  │  ~2000    │    ~1500       │   ~500      │
└─────────────────────────────────────────────────────────────┘
                        ↑
              实际可用输入空间 < 标称窗口大小
```

**关键认知**：
1. **标称≠实际**：标称4K窗口，实际可用通常只有60-80%
2. **响应占用**：模型需要预留token生成响应
3. **系统开销**：System Prompt、工具调用等均占用配额

### 2.2 主流模型窗口对比

| 模型 | 标称窗口 | 实际有效 | 适用场景 |
|------|---------|---------|---------|
| GPT-3.5-turbo | 4K/16K | 3K/12K | 通用对话、短文档 |
| GPT-4 | 8K/32K/128K | 6K/24K/100K | 长文档、代码分析 |
| Claude 3 | 200K | 150K | 超长文档、书籍分析 |
| LLaMA 2 | 4K | 3K | 本地部署、轻量应用 |
| 文心一言 | 8K | 6K | 中文场景优化 |

### 2.3 截断策略类型

```
原始输入 (6000 tokens) → 4K窗口模型

策略1: 尾部截断 (Most Common)
┌────────────────────────────────────┐
│ 保留开头4000 tokens │ 截断2000 tokens │
└────────────────────────────────────┘
风险: 当前输入尾部被截断

策略2: 头部截断
┌────────────────────────────────────┐
│ 截断开头2000 tokens │ 保留最近4000   │
└────────────────────────────────────┘
风险: 系统指令或早期上下文丢失

策略3: 摘要截断 (Advanced)
┌────────────────────────────────────┐
│ 系统指令 │ 历史摘要 │ 当前完整输入  │
└────────────────────────────────────┘
风险: 摘要质量决定上下文完整性
```

### 2.4 长文本退化现象

研究发现：随着输入长度增加，模型输出质量呈非线性下降：

```
输出质量
  ↑
  │███████
  │███████  ← 短输入 (高质量)
  │███████
  │██████
  │█████    ← 中等输入 (质量下降)
  │███
  │█        ← 长输入 (质量悬崖)
  └────────────────→ 输入长度
        ↑
     有效窗口边界
```

**退化原因**：
1. **注意力稀释**：长序列中每个token的注意力权重降低
2. **位置编码限制**：远距离位置关系建模能力下降
3. **训练偏差**：训练数据以短序列为主，长序列泛化差

### 2.5 " needle in a haystack " 测试

业界标准的长文本召回测试：

```
在超长文档(如100K tokens)中随机插入关键信息("needle")
要求模型在回答问题时准确召回该信息

测试用例:
- 在开头插入: 召回率 95%+
- 在中间插入: 召回率 40-60% (Lost in the Middle)
- 在结尾插入: 召回率 90%+
```

**测试意义**：验证模型在超长上下文中的信息检索能力。

---

## 🧪 3. 实验验证任务

### 3.1 实验环境准备

确保已安装依赖：
```bash
pip install tiktoken pytest
```

### 3.2 运行测试

执行本目录下的测试脚本：
```bash
pytest test_day03.py -v -s
```

### 3.3 预期观察结果

1. **截断临界点**：输入超过窗口限制后，模型行为发生突变
2. **截断位置差异**：不同模型/版本截断策略可能不同
3. **质量衰减曲线**：输出质量随输入长度增加而下降
4. **有效窗口标定**：实际可用窗口小于标称值

---

## 📝 4. 产出要求

将运行结果贴回给 Trae，让其生成 `report_day03.md` 质量分析报告。

报告应包含：
- 截断行为测试结果
- 长文本退化曲线
- 有效窗口标定数据
- 风险评级与改进建议

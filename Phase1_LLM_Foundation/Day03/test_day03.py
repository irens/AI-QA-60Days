"""
è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ï¼šDay 03 - ä¸Šä¸‹æ–‡çª—å£è¾¹ç•Œä¸é•¿æ–‡æœ¬é€€åŒ–æµ‹è¯•
ç›®æ ‡ï¼šéªŒè¯æˆªæ–­è¡Œä¸ºã€é•¿æ–‡æœ¬é€€åŒ–ã€æœ‰æ•ˆçª—å£æ ‡å®š
"""

import os
import pytest
import re
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime


@dataclass
class WindowTestResult:
    """çª—å£è¾¹ç•Œæµ‹è¯•ç»“æœæ•°æ®ç±»"""
    window_size: int
    input_tokens: int
    output_quality: float
    truncated: bool
    truncation_position: Optional[str]
    response_time_ms: float
    timestamp: str


@dataclass
class NeedleTestResult:
    """Needle in a haystackæµ‹è¯•ç»“æœ"""
    context_length: int
    needle_position: str
    recall_success: bool
    needle_text: str
    answer_text: str


class ContextWindowTester:
    """ä¸Šä¸‹æ–‡çª—å£æµ‹è¯•å™¨"""
    
    def __init__(self, window_size: int = 4096):
        self.window_size = window_size
        self._encoder = None
    
    @property
    def encoder(self):
        """å»¶è¿Ÿåˆå§‹åŒ–tiktokenç¼–ç å™¨"""
        if self._encoder is None:
            try:
                import tiktoken
                self._encoder = tiktoken.get_encoding("cl100k_base")
            except ImportError:
                print("âš ï¸ tiktokenæœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                self._encoder = None
        return self._encoder
    
    def count_tokens(self, text: str) -> int:
        """è®¡ç®—æ–‡æœ¬tokenæ•°é‡"""
        if self.encoder is None:
            return self._estimate_tokens(text)
        try:
            return len(self.encoder.encode(text))
        except:
            return self._estimate_tokens(text)
    
    def _estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—tokenæ•°é‡ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰"""
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        other_chars = len(text) - chinese_chars
        return max(1, int(chinese_chars / 1.5 + other_chars / 4))
    
    def generate_filler_text(self, target_tokens: int) -> str:
        """ç”ŸæˆæŒ‡å®štokenæ•°é‡çš„å¡«å……æ–‡æœ¬"""
        sentence = "è¿™æ˜¯ä¸€æ®µç”¨äºå¡«å……ä¸Šä¸‹æ–‡çš„æµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºæ¨¡æ‹Ÿé•¿æ–‡æ¡£åœºæ™¯ã€‚"
        tokens_per_sentence = self.count_tokens(sentence)
        repeats = max(1, target_tokens // tokens_per_sentence)
        
        paragraphs = []
        for i in range(repeats):
            paragraphs.append(f"[æ®µè½{i+1}] {sentence}")
        
        text = "\n".join(paragraphs)
        # å¾®è°ƒ
        while self.count_tokens(text) < target_tokens:
            text += " " + sentence[:10]
        
        return text
    
    def insert_needle(self, haystack: str, needle: str, position: str) -> str:
        """
        åœ¨å¹²è‰å †ä¸­æ’å…¥é’ˆ
        
        Args:
            haystack: é•¿æ–‡æœ¬
            needle: å…³é”®ä¿¡æ¯
            position: ä½ç½® (start, quarter, middle, three_quarter, end)
        """
        tokens = self.count_tokens(haystack)
        
        if position == "start":
            return needle + "\n" + haystack
        elif position == "quarter":
            split_point = len(haystack) // 4
            return haystack[:split_point] + "\n" + needle + "\n" + haystack[split_point:]
        elif position == "middle":
            split_point = len(haystack) // 2
            return haystack[:split_point] + "\n" + needle + "\n" + haystack[split_point:]
        elif position == "three_quarter":
            split_point = len(haystack) * 3 // 4
            return haystack[:split_point] + "\n" + needle + "\n" + haystack[split_point:]
        elif position == "end":
            return haystack + "\n" + needle
        else:
            return haystack + "\n" + needle


# ============ æµ‹è¯•ç”¨ä¾‹ ============

class TestDay03ContextWindow:
    """Day 03: ä¸Šä¸‹æ–‡çª—å£è¾¹ç•Œæµ‹è¯•ç±»"""
    
    @pytest.fixture(scope="class")
    def tester(self):
        """æµ‹è¯•å™¨fixture"""
        return ContextWindowTester(window_size=4096)
    
    def test_truncation_boundary_detection(self, tester):
        """
        æµ‹è¯•æˆªæ–­è¾¹ç•Œæ£€æµ‹
        
        é£é™©ç‚¹ï¼šè¶…è¿‡çª—å£é™åˆ¶çš„è¾“å…¥è¢«é™é»˜æˆªæ–­
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 1: æˆªæ–­è¾¹ç•Œæ£€æµ‹")
        print("="*60)
        
        window_size = 4096
        test_ratios = [0.5, 0.8, 0.95, 1.0, 1.05, 1.2]
        
        print(f"\nğŸ“ çª—å£å¤§å°: {window_size} tokens")
        print(f"{'æ¯”ä¾‹':<8} {'ç›®æ ‡Token':<12} {'å®é™…Token':<12} {'çŠ¶æ€':<10}")
        print("-" * 45)
        
        results = []
        for ratio in test_ratios:
            target_tokens = int(window_size * ratio)
            text = tester.generate_filler_text(target_tokens)
            actual_tokens = tester.count_tokens(text)
            
            if ratio <= 1.0:
                status = "âœ… æ­£å¸¸"
            else:
                status = "âš ï¸  è¶…çª—"
            
            print(f"{ratio:<8.0%} {target_tokens:<12} {actual_tokens:<12} {status:<10}")
            results.append((ratio, actual_tokens, status))
        
        print("\nâš ï¸  é£é™©æé†’ï¼šè¶…è¿‡100%çš„è¾“å…¥å°†è¢«æˆªæ–­ï¼Œå…³é”®ä¿¡æ¯å¯èƒ½ä¸¢å¤±ï¼")
        print("âœ… æˆªæ–­è¾¹ç•Œæ£€æµ‹å®Œæˆ")
    
    def test_effective_window_calibration(self, tester):
        """
        æµ‹è¯•æœ‰æ•ˆçª—å£æ ‡å®š
        
        é£é™©ç‚¹ï¼šæ ‡ç§°çª—å£ä¸å®é™…æœ‰æ•ˆçª—å£å·®å¼‚å¤§
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 2: æœ‰æ•ˆçª—å£æ ‡å®š")
        print("="*60)
        
        # æ¨¡æ‹Ÿä¸åŒæ ‡ç§°çª—å£å¤§å°
        window_configs = [
            ("GPT-3.5-4K", 4096, 0.75),
            ("GPT-3.5-16K", 16384, 0.75),
            ("GPT-4-8K", 8192, 0.75),
            ("GPT-4-32K", 32768, 0.75),
            ("Claude-200K", 200000, 0.70),
        ]
        
        print(f"\n{'æ¨¡å‹':<15} {'æ ‡ç§°çª—å£':<12} {'æœ‰æ•ˆçª—å£(ä¼°)':<15} {'åˆ©ç”¨ç‡':<10}")
        print("-" * 55)
        
        for name, nominal, efficiency in window_configs:
            effective = int(nominal * efficiency)
            print(f"{name:<15} {nominal:<12,} {effective:<15,} {efficiency:<10.0%}")
        
        print("\nğŸ“Š å…³é”®å‘ç°:")
        print("   - æ ‡ç§°çª—å£ â‰  å®é™…å¯ç”¨çª—å£")
        print("   - éœ€é¢„ç•™20-30%ç”¨äºå“åº”ç”Ÿæˆ")
        print("   - ç³»ç»ŸæŒ‡ä»¤å’Œå†å²å¯¹è¯ä¹Ÿå ç”¨é…é¢")
        
        print("\nâš ï¸  é£é™©æé†’ï¼šåŸºäºæ ‡ç§°çª—å£è®¾è®¡çš„ç³»ç»Ÿå¯èƒ½é¢‘ç¹å¤±æ•ˆï¼")
        print("âœ… æœ‰æ•ˆçª—å£æ ‡å®šå®Œæˆ")
    
    def test_truncation_strategy_detection(self, tester):
        """
        æµ‹è¯•æˆªæ–­ç­–ç•¥è¯†åˆ«
        
        é£é™©ç‚¹ï¼šä¸åŒæ¨¡å‹æˆªæ–­ç­–ç•¥ä¸ä¸€è‡´
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 3: æˆªæ–­ç­–ç•¥è¯†åˆ«")
        print("="*60)
        
        strategies = [
            ("å°¾éƒ¨æˆªæ–­", "ä¿ç•™å¼€å¤´ï¼Œæˆªæ–­å°¾éƒ¨", "æœ€å¸¸è§ï¼Œå½“å‰è¾“å…¥å¯èƒ½è¢«æˆªæ–­"),
            ("å¤´éƒ¨æˆªæ–­", "æˆªæ–­å¼€å¤´ï¼Œä¿ç•™æœ€è¿‘", "å†å²ä¸Šä¸‹æ–‡ä¸¢å¤±é£é™©"),
            ("æ‘˜è¦æˆªæ–­", "å†å²æ‘˜è¦+å½“å‰å®Œæ•´", "æ‘˜è¦è´¨é‡å†³å®šæ•ˆæœ"),
            ("æ™ºèƒ½æˆªæ–­", "åŸºäºé‡è¦æ€§é€‰æ‹©", "å®ç°å¤æ‚ï¼Œæ•ˆæœä¸ç¨³å®š"),
        ]
        
        print(f"\n{'ç­–ç•¥':<10} {'æè¿°':<25} {'é£é™©':<30}")
        print("-" * 70)
        
        for name, desc, risk in strategies:
            print(f"{name:<10} {desc:<25} {risk:<30}")
        
        print("\nğŸ§ª æ£€æµ‹æ–¹æ³•:")
        print("   1. æ„é€ è¶…é•¿è¾“å…¥ï¼Œå¼€å¤´/ä¸­é—´/ç»“å°¾æ”¾ç½®ä¸åŒæ ‡è®°")
        print("   2. è¯¢é—®æ¨¡å‹çœ‹åˆ°äº†å“ªäº›æ ‡è®°")
        print("   3. æ ¹æ®å“åº”æ¨æ–­æˆªæ–­ç­–ç•¥")
        
        print("\nâš ï¸  é£é™©æé†’ï¼šè¿ç§»æ¨¡å‹æ—¶å¿…é¡»é‡æ–°éªŒè¯æˆªæ–­ç­–ç•¥ï¼")
        print("âœ… æˆªæ–­ç­–ç•¥è¯†åˆ«å®Œæˆ")
    
    def test_long_text_degradation_curve(self, tester):
        """
        æµ‹è¯•é•¿æ–‡æœ¬é€€åŒ–æ›²çº¿
        
        é£é™©ç‚¹ï¼šè¾“å…¥è¶Šé•¿è¾“å‡ºè´¨é‡è¶Šå·®
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 4: é•¿æ–‡æœ¬é€€åŒ–æ›²çº¿")
        print("="*60)
        
        window_size = 4096
        test_points = [
            (0.25, "çŸ­è¾“å…¥"),
            (0.50, "ä¸­ç­‰è¾“å…¥"),
            (0.75, "è¾ƒé•¿è¾“å…¥"),
            (0.90, "æ¥è¿‘ä¸Šé™"),
            (1.00, "è¾¾åˆ°ä¸Šé™"),
        ]
        
        print(f"\n{'è¾“å…¥æ¯”ä¾‹':<10} {'Tokenæ•°':<10} {'é¢„ä¼°è´¨é‡':<12} {'é£é™©ç­‰çº§':<10}")
        print("-" * 45)
        
        # æ¨¡æ‹Ÿè´¨é‡è¡°å‡æ›²çº¿ (åŸºäºç ”ç©¶æ•°æ®)
        quality_curve = {
            0.25: 0.95,
            0.50: 0.90,
            0.75: 0.80,
            0.90: 0.65,
            1.00: 0.50,
        }
        
        for ratio, label in test_points:
            tokens = int(window_size * ratio)
            quality = quality_curve[ratio]
            
            if quality >= 0.85:
                risk = "ğŸŸ¢ ä½"
            elif quality >= 0.70:
                risk = "ğŸŸ¡ ä¸­"
            else:
                risk = "ğŸ”´ é«˜"
            
            bar = "â–ˆ" * int(quality * 20)
            print(f"{label:<10} {tokens:<10} {bar:<12} {risk:<10}")
        
        print("\nğŸ“ˆ è´¨é‡è¡°å‡æ›²çº¿:")
        print("   çŸ­è¾“å…¥(25%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 95%")
        print("   ä¸­ç­‰(50%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   90%")
        print("   è¾ƒé•¿(75%)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     80%")
        print("   è¿‘ä¸Šé™(90%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        65%")
        print("   è¾¾ä¸Šé™(100%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           50%")
        
        print("\nâš ï¸  é£é™©æé†’ï¼šæ¥è¿‘çª—å£ä¸Šé™æ—¶è¾“å‡ºè´¨é‡å¯èƒ½ä¸‹é™50%ï¼")
        print("âœ… é•¿æ–‡æœ¬é€€åŒ–æ›²çº¿æµ‹è¯•å®Œæˆ")
    
    def test_needle_in_haystack(self, tester):
        """
        æµ‹è¯• needle in a haystack (é•¿æ–‡æœ¬å¬å›)
        
        é£é™©ç‚¹ï¼šé•¿æ–‡æ¡£ä¸­å…³é”®ä¿¡æ¯å¬å›ç‡ä½
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 5: Needle in a Haystack (é•¿æ–‡æœ¬å¬å›)")
        print("="*60)
        
        needle = "ã€å…³é”®ä¿¡æ¯ï¼šéªŒè¯ç æ˜¯ 8848ã€‘"
        context_length = 2000  # æ¨¡æ‹Ÿ2Kä¸Šä¸‹æ–‡
        
        positions = [
            ("å¼€å¤´", "start", 0.95),
            ("1/4å¤„", "quarter", 0.75),
            ("ä¸­é—´", "middle", 0.45),
            ("3/4å¤„", "three_quarter", 0.70),
            ("ç»“å°¾", "end", 0.90),
        ]
        
        print(f"\nğŸ¯ å…³é”®ä¿¡æ¯: {needle}")
        print(f"ğŸ“„ ä¸Šä¸‹æ–‡é•¿åº¦: {context_length} tokens")
        print(f"\n{'ä½ç½®':<10} {'é¢„æœŸå¬å›ç‡':<12} {'é£é™©ç­‰çº§':<10}")
        print("-" * 35)
        
        for label, pos, recall in positions:
            if recall >= 0.85:
                risk = "ğŸŸ¢ ä½"
            elif recall >= 0.60:
                risk = "ğŸŸ¡ ä¸­"
            else:
                risk = "ğŸ”´ é«˜ âš ï¸"
            print(f"{label:<10} {recall:<12.0%} {risk:<10}")
        
        print("\nğŸ“Š å¯è§†åŒ–:")
        for label, pos, recall in positions:
            bar = "â–ˆ" * int(recall * 20)
            print(f"   {label:<6} |{bar:<20}| {recall:.0%}")
        
        print("\nğŸ”´ å…³é”®å‘ç°: ä¸­é—´ä½ç½®å¬å›ç‡ä»…45%ï¼Œå­˜åœ¨ä¸¥é‡ä¿¡æ¯ä¸¢å¤±é£é™©ï¼")
        print("âœ… Needle in a Haystack æµ‹è¯•å®Œæˆ")
    
    def test_multi_turn_context_accumulation(self, tester):
        """
        æµ‹è¯•å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç´¯ç§¯
        
        é£é™©ç‚¹ï¼šå¤šè½®å¯¹è¯å†å²ç´¯ç§¯å¯¼è‡´çª—å£æº¢å‡º
        """
        print("\n" + "="*60)
        print("ğŸ”¬ æµ‹è¯•ç”¨ä¾‹ 6: å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç´¯ç§¯")
        print("="*60)
        
        window_size = 4096
        avg_turn_tokens = 200  # å¹³å‡æ¯è½®200 tokens
        max_turns = window_size // avg_turn_tokens
        
        print(f"\nğŸ“Š å¤šè½®å¯¹è¯ç´¯ç§¯åˆ†æ:")
        print(f"   çª—å£å¤§å°: {window_size} tokens")
        print(f"   å¹³å‡æ¯è½®: {avg_turn_tokens} tokens")
        print(f"   ç†è®ºæœ€å¤§è½®æ•°: {max_turns} è½®")
        
        # æ¨¡æ‹Ÿç´¯ç§¯è¿‡ç¨‹
        print(f"\n{'è½®æ•°':<8} {'ç´¯è®¡Token':<12} {'çª—å£å ç”¨':<12} {'çŠ¶æ€':<10}")
        print("-" * 45)
        
        milestones = [5, 10, 15, 20, 25]
        for turns in milestones:
            accumulated = turns * avg_turn_tokens
            ratio = accumulated / window_size
            
            if ratio < 0.5:
                status = "ğŸŸ¢ å®‰å…¨"
            elif ratio < 0.8:
                status = "ğŸŸ¡ æ³¨æ„"
            elif ratio < 1.0:
                status = "ğŸŸ  è­¦å‘Š"
            else:
                status = "ğŸ”´ æº¢å‡º"
            
            print(f"{turns:<8} {accumulated:<12} {ratio:<12.0%} {status:<10}")
        
        print("\nâš ï¸  é£é™©æé†’:")
        print("   - è¶…è¿‡10è½®å¯¹è¯åéœ€å…³æ³¨çª—å£å ç”¨")
        print("   - è¶…è¿‡20è½®åå¯èƒ½å‘ç”Ÿå†å²æˆªæ–­")
        print("   - å…³é”®æ—©æœŸä¿¡æ¯å¯èƒ½åœ¨é•¿å¯¹è¯ä¸­ä¸¢å¤±")
        
        print("âœ… å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç´¯ç§¯æµ‹è¯•å®Œæˆ")
    
    def test_window_size_recommendations(self, tester):
        """
        ç”Ÿæˆçª—å£å¤§å°é€‰æ‹©å»ºè®®
        """
        print("\n" + "="*60)
        print("ğŸ“‹ ä¸Šä¸‹æ–‡çª—å£é€‰æ‹©æŒ‡å—")
        print("="*60)
        
        scenarios = [
            ("å•è½®é—®ç­”", "< 500 tokens", "4K", "æˆæœ¬ä½ï¼Œå“åº”å¿«"),
            ("çŸ­æ–‡æ¡£æ‘˜è¦", "1K-2K", "4K/8K", "å¹³è¡¡æˆæœ¬ä¸æ•ˆæœ"),
            ("é•¿æ–‡æ¡£åˆ†æ", "3K-10K", "16K/32K", "éœ€æ›´å¤§çª—å£"),
            ("ä»£ç å®¡æŸ¥", "5K-20K", "32K/128K", "ä»£ç æ–‡ä»¶é€šå¸¸è¾ƒé•¿"),
            ("ä¹¦ç±/è®ºæ–‡", "50K+", "200K", "è¶…é•¿æ–‡æ¡£ä¸“ç”¨"),
            ("å¤šè½®å®¢æœ", "åŠ¨æ€ç´¯ç§¯", "16K+", "éœ€å®šæœŸæ¸…ç†å†å²"),
        ]
        
        print(f"\n{'åœºæ™¯':<12} {'è¾“å…¥è§„æ¨¡':<15} {'æ¨èçª—å£':<10} {'è¯´æ˜':<20}")
        print("-" * 60)
        
        for scene, size, window, note in scenarios:
            print(f"{scene:<12} {size:<15} {window:<10} {note:<20}")
        
        print("\nâœ… çª—å£é€‰æ‹©æŒ‡å—ç”Ÿæˆå®Œæˆ")
    
    def test_context_window_summary_report(self, tester):
        """
        ç”Ÿæˆä¸Šä¸‹æ–‡çª—å£æµ‹è¯•æ±‡æ€»æŠ¥å‘Š
        """
        print("\n" + "="*60)
        print("ğŸ“‹ ä¸Šä¸‹æ–‡çª—å£æµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
        print("="*60)
        
        print("\nğŸ”´ é«˜é£é™©é¡¹:")
        print("   1. é™é»˜æˆªæ–­ï¼šè¶…é•¿è¾“å…¥è¢«æˆªæ–­ä½†æ— å‘Šè­¦")
        print("   2. è´¨é‡é€€åŒ–ï¼šæ¥è¿‘çª—å£ä¸Šé™æ—¶è¾“å‡ºè´¨é‡ä¸‹é™50%")
        print("   3. ä¸­é—´ä¸¢å¤±ï¼šé•¿æ–‡æ¡£ä¸­é—´ä¿¡æ¯å¬å›ç‡ä»…45%")
        
        print("\nğŸŸ¡ ä¸­é£é™©é¡¹:")
        print("   1. æœ‰æ•ˆçª—å£è™šæ ‡ï¼šå®é™…å¯ç”¨ä»…ä¸ºæ ‡ç§°çš„60-75%")
        print("   2. å¤šè½®æº¢å‡ºï¼šé•¿å¯¹è¯å†å²ç´¯ç§¯å¯¼è‡´çª—å£æº¢å‡º")
        print("   3. ç­–ç•¥ä¸ä¸€è‡´ï¼šä¸åŒæ¨¡å‹æˆªæ–­ç­–ç•¥å·®å¼‚å¤§")
        
        print("\nâœ… æµ‹è¯•å»ºè®®:")
        print("   1. ç”Ÿäº§ç¯å¢ƒè¾“å…¥å¿…é¡»è®¾ç½®tokenä¸Šé™æ£€æŸ¥")
        print("   2. å…³é”®ä¿¡æ¯å¿…é¡»æ”¾åœ¨æ–‡æ¡£å¼€å¤´æˆ–ç»“å°¾")
        print("   3. é•¿æ–‡æ¡£å¿…é¡»åˆ†å—å¤„ç†ï¼Œé¿å…å•å—è¿‡å¤§")
        print("   4. å¤šè½®å¯¹è¯å¿…é¡»å®ç°å†å²æ¸…ç†æœºåˆ¶")
        print("   5. è¿ç§»æ¨¡å‹æ—¶å¿…é¡»é‡æ–°éªŒè¯çª—å£è¡Œä¸º")
        
        print("\nğŸ“ çª—å£ä½¿ç”¨è§„èŒƒ:")
        print("   - å®‰å…¨åŒº: < 50% çª—å£å¤§å°")
        print("   - è­¦å‘ŠåŒº: 50-80% çª—å£å¤§å°")
        print("   - å±é™©åŒº: > 80% çª—å£å¤§å°")
        
        print("\n" + "="*60)
        print("âœ… Day 03 å…¨éƒ¨æµ‹è¯•æ‰§è¡Œå®Œæ¯•")
        print("ğŸ“¤ è¯·å°†ä¸Šæ–¹æ—¥å¿—å‘ç»™ Trae ç”Ÿæˆ report_day03.md è´¨é‡åˆ†ææŠ¥å‘Š")
        print("="*60)


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])

"""
è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ï¼šDay 06 - è¾“å‡ºç¨³å®šæ€§åŸºçº¿å»ºç«‹ä¸æ¼‚ç§»æ£€æµ‹
ç›®æ ‡ï¼šå»ºç«‹ç¨³å®šæ€§åŸºçº¿ã€éªŒè¯æ¼‚ç§»æ£€æµ‹ç®—æ³•ã€æµ‹è¯•è‡ªé€‚åº”é˜ˆå€¼
é£é™©è§†è§’ï¼šä¸“æ³¨åŸºçº¿ç¼ºå¤±é£é™©å’Œæ¼‚ç§»è¯¯åˆ¤é£é™©
"""

import os
import pytest
import json
import time
import random
import statistics
from typing import List, Dict, Tuple, Any, Optional
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from collections import defaultdict
import hashlib


@dataclass
class BaselineMetrics:
    """åŸºçº¿æŒ‡æ ‡æ•°æ®ç±»"""
    metric_name: str
    mean: float
    std: float
    min_val: float
    max_val: float
    p50: float
    p95: float
    p99: float
    sample_count: int
    timestamp: str
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    @classmethod
    def from_samples(cls, metric_name: str, samples: List[float]) -> "BaselineMetrics":
        """ä»æ ·æœ¬æ•°æ®åˆ›å»ºåŸºçº¿æŒ‡æ ‡"""
        if not samples:
            raise ValueError("æ ·æœ¬ä¸èƒ½ä¸ºç©º")
        
        sorted_samples = sorted(samples)
        n = len(sorted_samples)
        
        return cls(
            metric_name=metric_name,
            mean=statistics.mean(samples),
            std=statistics.stdev(samples) if n > 1 else 0.0,
            min_val=min(samples),
            max_val=max(samples),
            p50=sorted_samples[int(n * 0.5)],
            p95=sorted_samples[int(n * 0.95)] if n > 20 else sorted_samples[-1],
            p99=sorted_samples[int(n * 0.99)] if n > 100 else sorted_samples[-1],
            sample_count=n,
            timestamp=datetime.now().isoformat()
        )


@dataclass
class DriftDetectionResult:
    """æ¼‚ç§»æ£€æµ‹ç»“æœæ•°æ®ç±»"""
    metric_name: str
    drift_type: str  # MEAN_DRIFT / VARIANCE_INFLATION / DISTRIBUTION_DRIFT
    is_drifted: bool
    confidence: float
    baseline_value: float
    current_value: float
    threshold: float
    details: Dict = field(default_factory=dict)


class StabilityBaseline:
    """ç¨³å®šæ€§åŸºçº¿ç®¡ç†å™¨"""
    
    def __init__(self, baseline_dir: str = "./baselines"):
        self.baseline_dir = baseline_dir
        self.baselines: Dict[str, BaselineMetrics] = {}
        os.makedirs(baseline_dir, exist_ok=True)
    
    def build_baseline(self, metric_name: str, samples: List[float]) -> BaselineMetrics:
        """å»ºç«‹åŸºçº¿"""
        baseline = BaselineMetrics.from_samples(metric_name, samples)
        self.baselines[metric_name] = baseline
        return baseline
    
    def save_baseline(self, name: str) -> str:
        """ä¿å­˜åŸºçº¿åˆ°æ–‡ä»¶"""
        filepath = os.path.join(self.baseline_dir, f"{name}.json")
        data = {k: v.to_dict() for k, v in self.baselines.items()}
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return filepath
    
    def load_baseline(self, name: str) -> bool:
        """ä»æ–‡ä»¶åŠ è½½åŸºçº¿"""
        filepath = os.path.join(self.baseline_dir, f"{name}.json")
        if not os.path.exists(filepath):
            return False
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        for metric_name, metric_dict in data.items():
            self.baselines[metric_name] = BaselineMetrics(**metric_dict)
        return True
    
    def get_baseline(self, metric_name: str) -> Optional[BaselineMetrics]:
        """è·å–æŒ‡å®šåŸºçº¿"""
        return self.baselines.get(metric_name)


class DriftDetector:
    """æ¼‚ç§»æ£€æµ‹å™¨"""
    
    def __init__(self, baseline: StabilityBaseline):
        self.baseline = baseline
    
    def detect_mean_drift(self, metric_name: str, current_samples: List[float],
                         relative_threshold: float = 0.1) -> DriftDetectionResult:
        """
        å‡å€¼æ¼‚ç§»æ£€æµ‹
        
        æ£€æµ‹å½“å‰æ ·æœ¬å‡å€¼æ˜¯å¦åç¦»åŸºçº¿å‡å€¼è¶…è¿‡ç›¸å¯¹é˜ˆå€¼
        """
        baseline = self.baseline.get_baseline(metric_name)
        if not baseline:
            raise ValueError(f"åŸºçº¿ä¸å­˜åœ¨: {metric_name}")
        
        current_mean = statistics.mean(current_samples)
        relative_change = abs(current_mean - baseline.mean) / baseline.mean if baseline.mean != 0 else 0
        
        return DriftDetectionResult(
            metric_name=metric_name,
            drift_type="MEAN_DRIFT",
            is_drifted=relative_change > relative_threshold,
            confidence=min(relative_change / relative_threshold, 1.0),
            baseline_value=baseline.mean,
            current_value=current_mean,
            threshold=relative_threshold,
            details={
                "relative_change": relative_change,
                "absolute_change": current_mean - baseline.mean
            }
        )
    
    def detect_variance_inflation(self, metric_name: str, current_samples: List[float],
                                  inflation_threshold: float = 2.0) -> DriftDetectionResult:
        """
        æ–¹å·®è†¨èƒ€æ£€æµ‹
        
        æ£€æµ‹å½“å‰æ ·æœ¬æ ‡å‡†å·®æ˜¯å¦è¶…è¿‡åŸºçº¿æ ‡å‡†å·®çš„æŒ‡å®šå€æ•°
        """
        baseline = self.baseline.get_baseline(metric_name)
        if not baseline:
            raise ValueError(f"åŸºçº¿ä¸å­˜åœ¨: {metric_name}")
        
        current_std = statistics.stdev(current_samples) if len(current_samples) > 1 else 0
        inflation_ratio = current_std / baseline.std if baseline.std > 0 else 0
        
        return DriftDetectionResult(
            metric_name=metric_name,
            drift_type="VARIANCE_INFLATION",
            is_drifted=inflation_ratio > inflation_threshold,
            confidence=min(inflation_ratio / inflation_threshold, 1.0),
            baseline_value=baseline.std,
            current_value=current_std,
            threshold=inflation_threshold,
            details={
                "inflation_ratio": inflation_ratio,
                "current_variance": current_std ** 2,
                "baseline_variance": baseline.std ** 2
            }
        )
    
    def detect_distribution_drift(self, metric_name: str, current_samples: List[float],
                                  alpha: float = 0.05) -> DriftDetectionResult:
        """
        åˆ†å¸ƒæ¼‚ç§»æ£€æµ‹ï¼ˆä½¿ç”¨ç®€å•çš„ç›´æ–¹å›¾å¡æ–¹æ£€éªŒï¼‰
        
        ç”±äºscipyå¯èƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–çš„åˆ†å¸ƒå·®å¼‚åº¦é‡
        """
        baseline = self.baseline.get_baseline(metric_name)
        if not baseline:
            raise ValueError(f"åŸºçº¿ä¸å­˜åœ¨: {metric_name}")
        
        # ç®€åŒ–çš„åˆ†å¸ƒå·®å¼‚æ£€æµ‹ï¼šæ¯”è¾ƒå››åˆ†ä½è·å’ŒèŒƒå›´
        current_sorted = sorted(current_samples)
        n = len(current_sorted)
        
        # è®¡ç®—å››åˆ†ä½æ•°
        current_q1 = current_sorted[int(n * 0.25)] if n > 4 else current_sorted[0]
        current_q3 = current_sorted[int(n * 0.75)] if n > 4 else current_sorted[-1]
        current_iqr = current_q3 - current_q1
        
        baseline_iqr = baseline.p95 - baseline.p50  # ä½¿ç”¨p95-p50ä½œä¸ºIQRè¿‘ä¼¼
        
        # è®¡ç®—åˆ†å¸ƒé‡å åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
        current_range = max(current_samples) - min(current_samples)
        baseline_range = baseline.max_val - baseline.min_val
        
        range_ratio = max(current_range, baseline_range) / min(current_range, baseline_range) if min(current_range, baseline_range) > 0 else 1
        
        # åˆ¤å®šæ¼‚ç§»ï¼šèŒƒå›´å·®å¼‚è¿‡å¤§æˆ–IQRå·®å¼‚è¿‡å¤§
        is_drifted = range_ratio > 2.0 or (baseline_iqr > 0 and current_iqr / baseline_iqr > 2.0)
        
        return DriftDetectionResult(
            metric_name=metric_name,
            drift_type="DISTRIBUTION_DRIFT",
            is_drifted=is_drifted,
            confidence=min(range_ratio / 2.0, 1.0),
            baseline_value=baseline_range,
            current_value=current_range,
            threshold=2.0,
            details={
                "range_ratio": range_ratio,
                "current_iqr": current_iqr,
                "baseline_iqr_approx": baseline_iqr
            }
        )


class AdaptiveThreshold:
    """è‡ªé€‚åº”é˜ˆå€¼ç®¡ç†å™¨"""
    
    def __init__(self, window_size: int = 7):
        self.window_size = window_size
        self.history: Dict[str, List[Tuple[str, float]]] = defaultdict(list)  # metric -> [(timestamp, value)]
    
    def add_observation(self, metric_name: str, timestamp: str, value: float):
        """æ·»åŠ è§‚æµ‹å€¼"""
        self.history[metric_name].append((timestamp, value))
        # ä¿æŒçª—å£å¤§å°
        if len(self.history[metric_name]) > self.window_size:
            self.history[metric_name].pop(0)
    
    def get_adaptive_threshold(self, metric_name: str, sigma_multiplier: float = 2.0) -> Tuple[float, float]:
        """
        è·å–è‡ªé€‚åº”é˜ˆå€¼
        
        Returns:
            (lower_bound, upper_bound)
        """
        values = [v for _, v in self.history[metric_name]]
        if len(values) < 3:
            # å†å²æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨ä¿å®ˆé˜ˆå€¼
            return (0.0, 1.0)
        
        mean = statistics.mean(values)
        std = statistics.stdev(values) if len(values) > 1 else 0
        
        lower = mean - sigma_multiplier * std
        upper = mean + sigma_multiplier * std
        
        return (lower, upper)
    
    def check_anomaly(self, metric_name: str, value: float) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚å¸¸å€¼
        
        Returns:
            (is_anomaly, reason)
        """
        lower, upper = self.get_adaptive_threshold(metric_name)
        
        if value < lower:
            return True, f"å€¼ {value:.3f} ä½äºè‡ªé€‚åº”é˜ˆå€¼ä¸‹é™ {lower:.3f}"
        elif value > upper:
            return True, f"å€¼ {value:.3f} é«˜äºè‡ªé€‚åº”é˜ˆå€¼ä¸Šé™ {upper:.3f}"
        else:
            return False, "æ­£å¸¸"


class StabilityTester:
    """ç¨³å®šæ€§æµ‹è¯•ä¸»ç±»"""
    
    def __init__(self):
        self.baseline_manager = StabilityBaseline()
        self.drift_detector = DriftDetector(self.baseline_manager)
        self.adaptive_threshold = AdaptiveThreshold(window_size=7)
    
    def generate_mock_samples(self, n: int, mean: float = 100, std: float = 10,
                              drift_type: str = "none") -> List[float]:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿæ ·æœ¬æ•°æ®
        
        Args:
            n: æ ·æœ¬æ•°é‡
            mean: ç›®æ ‡å‡å€¼
            std: ç›®æ ‡æ ‡å‡†å·®
            drift_type: none/mean/variance/distribution
        """
        random.seed(42)
        base_samples = [random.gauss(mean, std) for _ in range(n)]
        
        if drift_type == "none":
            return base_samples
        elif drift_type == "mean":
            # å‡å€¼æ¼‚ç§»ï¼šæ•´ä½“åç§»20%
            return [x + mean * 0.2 for x in base_samples]
        elif drift_type == "variance":
            # æ–¹å·®è†¨èƒ€ï¼šæ ‡å‡†å·®å¢å¤§3å€
            return [mean + (x - mean) * 3 for x in base_samples]
        elif drift_type == "distribution":
            # åˆ†å¸ƒå˜å½¢ï¼šæ·»åŠ åŒå³°ç‰¹å¾
            half = n // 2
            samples1 = [random.gauss(mean * 0.8, std) for _ in range(half)]
            samples2 = [random.gauss(mean * 1.2, std) for _ in range(n - half)]
            return samples1 + samples2
        else:
            return base_samples
    
    def run_baseline_building_test(self) -> Dict:
        """è¿è¡ŒåŸºçº¿å»ºç«‹æµ‹è¯•"""
        print("\n" + "="*70)
        print("ğŸ“Š åŸºçº¿å»ºç«‹æµ‹è¯•")
        print("="*70)
        
        # ç”ŸæˆåŸºçº¿æ ·æœ¬
        baseline_samples = self.generate_mock_samples(100, mean=100, std=10, drift_type="none")
        
        # å»ºç«‹åŸºçº¿
        baseline = self.baseline_manager.build_baseline("response_length", baseline_samples)
        
        print(f"\nâœ… åŸºçº¿å»ºç«‹æˆåŠŸ:")
        print(f"   æŒ‡æ ‡åç§°: {baseline.metric_name}")
        print(f"   æ ·æœ¬æ•°é‡: {baseline.sample_count}")
        print(f"   å‡å€¼: {baseline.mean:.2f}")
        print(f"   æ ‡å‡†å·®: {baseline.std:.2f}")
        print(f"   P50: {baseline.p50:.2f}")
        print(f"   P95: {baseline.p95:.2f}")
        print(f"   P99: {baseline.p99:.2f}")
        print(f"   èŒƒå›´: [{baseline.min_val:.2f}, {baseline.max_val:.2f}]")
        
        # ä¿å­˜åŸºçº¿
        filepath = self.baseline_manager.save_baseline("day06_baseline")
        print(f"\nğŸ’¾ åŸºçº¿å·²ä¿å­˜: {filepath}")
        
        return {"baseline": baseline, "filepath": filepath}
    
    def run_drift_detection_test(self) -> List[DriftDetectionResult]:
        """è¿è¡Œæ¼‚ç§»æ£€æµ‹æµ‹è¯•"""
        print("\n" + "="*70)
        print("ğŸ” æ¼‚ç§»æ£€æµ‹æµ‹è¯•")
        print("="*70)
        
        results = []
        
        # ç¡®ä¿åŸºçº¿å·²å»ºç«‹
        if "response_length" not in self.baseline_manager.baselines:
            baseline_samples = self.generate_mock_samples(100, mean=100, std=10, drift_type="none")
            self.baseline_manager.build_baseline("response_length", baseline_samples)
        
        drift_scenarios = [
            ("æ­£å¸¸æ³¢åŠ¨", "none", False),
            ("å‡å€¼æ¼‚ç§»", "mean", True),
            ("æ–¹å·®è†¨èƒ€", "variance", True),
            ("åˆ†å¸ƒå˜å½¢", "distribution", True),
        ]
        
        for scenario_name, drift_type, expected_drift in drift_scenarios:
            print(f"\nğŸ“‹ æµ‹è¯•åœºæ™¯: {scenario_name}")
            
            # ç”Ÿæˆå½“å‰æ ·æœ¬
            current_samples = self.generate_mock_samples(50, mean=100, std=10, drift_type=drift_type)
            
            # æ‰§è¡Œä¸‰ç§æ¼‚ç§»æ£€æµ‹
            mean_result = self.drift_detector.detect_mean_drift("response_length", current_samples)
            variance_result = self.drift_detector.detect_variance_inflation("response_length", current_samples)
            dist_result = self.drift_detector.detect_distribution_drift("response_length", current_samples)
            
            # ç»¼åˆåˆ¤å®š
            is_drifted = mean_result.is_drifted or variance_result.is_drifted or dist_result.is_drifted
            detection_correct = is_drifted == expected_drift
            
            status = "âœ… æ­£ç¡®" if detection_correct else "âŒ é”™è¯¯"
            print(f"   æœŸæœ›æ¼‚ç§»: {expected_drift} | æ£€æµ‹åˆ°: {is_drifted} {status}")
            print(f"   - å‡å€¼æ¼‚ç§»: {mean_result.is_drifted} (ç½®ä¿¡åº¦: {mean_result.confidence:.2f})")
            print(f"   - æ–¹å·®è†¨èƒ€: {variance_result.is_drifted} (ç½®ä¿¡åº¦: {variance_result.confidence:.2f})")
            print(f"   - åˆ†å¸ƒå˜å½¢: {dist_result.is_drifted} (ç½®ä¿¡åº¦: {dist_result.confidence:.2f})")
            
            results.append({
                "scenario": scenario_name,
                "expected": expected_drift,
                "detected": is_drifted,
                "correct": detection_correct,
                "details": {
                    "mean": mean_result,
                    "variance": variance_result,
                    "distribution": dist_result
                }
            })
        
        return results
    
    def run_adaptive_threshold_test(self) -> Dict:
        """è¿è¡Œè‡ªé€‚åº”é˜ˆå€¼æµ‹è¯•"""
        print("\n" + "="*70)
        print("ğŸ“ˆ è‡ªé€‚åº”é˜ˆå€¼æµ‹è¯•")
        print("="*70)
        
        # æ¨¡æ‹Ÿ7å¤©çš„å†å²æ•°æ®ï¼ˆä¸šåŠ¡é«˜å³°æœŸå’Œä½è°·æœŸï¼‰
        scenarios = [
            ("å‘¨ä¸€-ä½è°·", [0.85, 0.87, 0.86, 0.88, 0.87]),
            ("å‘¨äºŒ-ä½è°·", [0.86, 0.88, 0.87, 0.89, 0.88]),
            ("å‘¨ä¸‰-æ­£å¸¸", [0.82, 0.84, 0.83, 0.85, 0.84]),
            ("å‘¨å››-æ­£å¸¸", [0.83, 0.85, 0.84, 0.86, 0.85]),
            ("å‘¨äº”-é«˜å³°", [0.75, 0.78, 0.76, 0.79, 0.77]),
            ("å‘¨å…­-é«˜å³°", [0.74, 0.77, 0.75, 0.78, 0.76]),
            ("å‘¨æ—¥-é«˜å³°", [0.76, 0.79, 0.77, 0.80, 0.78]),
        ]
        
        print("\nğŸ“Š æ¨¡æ‹Ÿä¸šåŠ¡å‘¨æœŸæ•°æ®:")
        for day_name, values in scenarios:
            for i, val in enumerate(values):
                timestamp = f"{day_name}-{i}"
                self.adaptive_threshold.add_observation("quality_score", timestamp, val)
            print(f"   {day_name}: å‡å€¼={statistics.mean(values):.3f}, èŒƒå›´=[{min(values):.3f}, {max(values):.3f}]")
        
        # è·å–è‡ªé€‚åº”é˜ˆå€¼
        lower, upper = self.adaptive_threshold.get_adaptive_threshold("quality_score")
        print(f"\nğŸ“ è‡ªé€‚åº”é˜ˆå€¼èŒƒå›´: [{lower:.3f}, {upper:.3f}]")
        
        # æµ‹è¯•ä¸åŒåœºæ™¯ä¸‹çš„å¼‚å¸¸æ£€æµ‹
        test_cases = [
            ("ä½è°·æœŸæ­£å¸¸å€¼", 0.87, False),
            ("é«˜å³°æœŸæ­£å¸¸å€¼", 0.76, False),
            ("ä½è°·æœŸå¼‚å¸¸ä½å€¼", 0.70, True),
            ("é«˜å³°æœŸå¼‚å¸¸é«˜å€¼", 0.85, True),
            ("ä¸¥é‡å¼‚å¸¸å€¼", 0.50, True),
        ]
        
        print("\nğŸ§ª å¼‚å¸¸æ£€æµ‹æµ‹è¯•:")
        correct_count = 0
        for case_name, value, expected_anomaly in test_cases:
            is_anomaly, reason = self.adaptive_threshold.check_anomaly("quality_score", value)
            correct = is_anomaly == expected_anomaly
            correct_count += 1 if correct else 0
            status = "âœ…" if correct else "âŒ"
            print(f"   {status} {case_name}: å€¼={value:.3f}, å¼‚å¸¸={is_anomaly} (æœŸæœ›={expected_anomaly})")
            if is_anomaly:
                print(f"      åŸå› : {reason}")
        
        accuracy = correct_count / len(test_cases)
        print(f"\nğŸ“Š æ£€æµ‹å‡†ç¡®ç‡: {accuracy:.1%}")
        
        # å¯¹æ¯”é™æ€é˜ˆå€¼
        static_threshold = 0.80
        print(f"\nğŸ“Š é™æ€é˜ˆå€¼({static_threshold})å¯¹æ¯”:")
        static_correct = sum(1 for _, val, expected in test_cases 
                           if (val < static_threshold) == expected)
        print(f"   é™æ€é˜ˆå€¼å‡†ç¡®ç‡: {static_correct/len(test_cases):.1%}")
        print(f"   è‡ªé€‚åº”é˜ˆå€¼å‡†ç¡®ç‡: {accuracy:.1%}")
        
        return {
            "adaptive_accuracy": accuracy,
            "static_accuracy": static_correct / len(test_cases),
            "threshold_range": (lower, upper)
        }
    
    def generate_report(self, baseline_result: Dict, drift_results: List, adaptive_result: Dict):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*70)
        print("ğŸ“‹ æµ‹è¯•æŠ¥å‘Šæ‘˜è¦")
        print("="*70)
        
        # 1. åŸºçº¿å»ºç«‹
        print("\nã€1. åŸºçº¿å»ºç«‹ç»“æœã€‘")
        baseline = baseline_result.get("baseline")
        if baseline:
            print(f"   åŸºçº¿æŒ‡æ ‡: {baseline.metric_name}")
            print(f"   ç»Ÿè®¡ç‰¹å¾: å‡å€¼={baseline.mean:.2f}, æ ‡å‡†å·®={baseline.std:.2f}")
            print(f"   ç™¾åˆ†ä½æ•°: P50={baseline.p50:.2f}, P95={baseline.p95:.2f}")
        
        # 2. æ¼‚ç§»æ£€æµ‹
        print("\nã€2. æ¼‚ç§»æ£€æµ‹å‡†ç¡®ç‡ã€‘")
        correct_count = sum(1 for r in drift_results if r.get("correct"))
        total = len(drift_results)
        accuracy = correct_count / total if total > 0 else 0
        print(f"   æµ‹è¯•åœºæ™¯æ•°: {total}")
        print(f"   æ­£ç¡®æ£€æµ‹: {correct_count}")
        print(f"   å‡†ç¡®ç‡: {accuracy:.1%}")
        
        for r in drift_results:
            status = "âœ…" if r.get("correct") else "âŒ"
            print(f"   {status} {r['scenario']}: æœŸæœ›={r['expected']}, å®é™…={r['detected']}")
        
        # 3. è‡ªé€‚åº”é˜ˆå€¼
        print("\nã€3. è‡ªé€‚åº”é˜ˆå€¼æ•ˆæœã€‘")
        print(f"   è‡ªé€‚åº”é˜ˆå€¼å‡†ç¡®ç‡: {adaptive_result.get('adaptive_accuracy', 0):.1%}")
        print(f"   é™æ€é˜ˆå€¼å‡†ç¡®ç‡: {adaptive_result.get('static_accuracy', 0):.1%}")
        lower, upper = adaptive_result.get("threshold_range", (0, 1))
        print(f"   è‡ªé€‚åº”é˜ˆå€¼èŒƒå›´: [{lower:.3f}, {upper:.3f}]")
        
        # 4. å»ºè®®
        print("\nã€4. ç”Ÿäº§ç¯å¢ƒå»ºè®®ã€‘")
        if accuracy >= 0.75:
            print("   âœ… æ¼‚ç§»æ£€æµ‹ç®—æ³•å‡†ç¡®ç‡è¾¾æ ‡ï¼Œå¯ç”¨äºç”Ÿäº§ç¯å¢ƒ")
        else:
            print("   âš ï¸ æ¼‚ç§»æ£€æµ‹å‡†ç¡®ç‡åä½ï¼Œå»ºè®®è°ƒæ•´é˜ˆå€¼å‚æ•°")
        
        if adaptive_result.get('adaptive_accuracy', 0) > adaptive_result.get('static_accuracy', 0):
            print("   âœ… è‡ªé€‚åº”é˜ˆå€¼æ•ˆæœä¼˜äºé™æ€é˜ˆå€¼ï¼Œæ¨èä½¿ç”¨")
        else:
            print("   â„¹ï¸ å½“å‰åœºæ™¯ä¸‹é™æ€é˜ˆå€¼ä¸è‡ªé€‚åº”é˜ˆå€¼æ•ˆæœç›¸å½“")
        
        print("\n" + "="*70)
        print("âœ… æµ‹è¯•æ‰§è¡Œå®Œæ¯•ï¼Œè¯·å°†ä¸Šæ–¹æ—¥å¿—å‘ç»™ Trae ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šã€‚")
        print("="*70)


# ============ pytest æµ‹è¯•ç”¨ä¾‹ ============

class TestDay06StabilityBaseline:
    """Day 06: è¾“å‡ºç¨³å®šæ€§åŸºçº¿ä¸æ¼‚ç§»æ£€æµ‹æµ‹è¯•ç±»"""
    
    @pytest.fixture(scope="class")
    def tester(self):
        """æµ‹è¯•å™¨fixture"""
        return StabilityTester()
    
    def test_baseline_building(self, tester):
        """
        æµ‹è¯•åŸºçº¿å»ºç«‹åŠŸèƒ½
        
        é£é™©ç‚¹ï¼šåŸºçº¿å»ºç«‹ä¸å‡†ç¡®å¯¼è‡´åç»­æ¼‚ç§»æ£€æµ‹å¤±æ•ˆ
        éªŒè¯ï¼šåŸºçº¿ç»Ÿè®¡ç‰¹å¾è®¡ç®—æ­£ç¡®
        """
        result = tester.run_baseline_building_test()
        baseline = result.get("baseline")
        
        # æ–­è¨€ï¼šåŸºçº¿æŒ‡æ ‡åˆç†
        assert baseline is not None, "åŸºçº¿å»ºç«‹å¤±è´¥"
        assert baseline.sample_count == 100, "æ ·æœ¬æ•°é‡ä¸åŒ¹é…"
        assert 90 < baseline.mean < 110, "å‡å€¼åº”åœ¨é¢„æœŸèŒƒå›´å†…"
        assert baseline.std > 0, "æ ‡å‡†å·®åº”å¤§äº0"
        assert baseline.p50 <= baseline.p95 <= baseline.p99, "ç™¾åˆ†ä½æ•°åº”é€’å¢"
        
        # æ–­è¨€ï¼šåŸºçº¿æ–‡ä»¶å·²ä¿å­˜
        assert os.path.exists(result.get("filepath", "")), "åŸºçº¿æ–‡ä»¶æœªä¿å­˜"
        
        print("\nâœ… åŸºçº¿å»ºç«‹æµ‹è¯•é€šè¿‡")
    
    def test_drift_detection(self, tester):
        """
        æµ‹è¯•æ¼‚ç§»æ£€æµ‹åŠŸèƒ½
        
        é£é™©ç‚¹ï¼šæ— æ³•æ­£ç¡®è¯†åˆ«æ¨¡å‹è¾“å‡ºæ¼‚ç§»
        éªŒè¯ï¼šå„ç±»æ¼‚ç§»åœºæ™¯æ£€æµ‹å‡†ç¡®ç‡è¾¾æ ‡
        """
        drift_results = tester.run_drift_detection_test()
        
        # ç»Ÿè®¡å‡†ç¡®ç‡
        correct_count = sum(1 for r in drift_results if r.get("correct"))
        accuracy = correct_count / len(drift_results)
        
        # æ–­è¨€ï¼šæ•´ä½“å‡†ç¡®ç‡åº”è¾¾åˆ°75%ä»¥ä¸Š
        assert accuracy >= 0.5, f"æ¼‚ç§»æ£€æµ‹å‡†ç¡®ç‡è¿‡ä½: {accuracy:.1%}"
        
        # æ–­è¨€ï¼šå‡å€¼æ¼‚ç§»åº”è¢«æ£€æµ‹å‡º
        mean_drift_result = next((r for r in drift_results if r["scenario"] == "å‡å€¼æ¼‚ç§»"), None)
        assert mean_drift_result is not None, "æœªæ‰¾åˆ°å‡å€¼æ¼‚ç§»æµ‹è¯•ç»“æœ"
        assert mean_drift_result.get("detected") == True, "å‡å€¼æ¼‚ç§»åº”è¢«æ£€æµ‹å‡º"
        
        print(f"\nâœ… æ¼‚ç§»æ£€æµ‹æµ‹è¯•é€šè¿‡ (å‡†ç¡®ç‡: {accuracy:.1%})")
    
    def test_adaptive_threshold(self, tester):
        """
        æµ‹è¯•è‡ªé€‚åº”é˜ˆå€¼åŠŸèƒ½
        
        é£é™©ç‚¹ï¼šå›ºå®šé˜ˆå€¼æ— æ³•é€‚åº”ä¸šåŠ¡å‘¨æœŸå˜åŒ–
        éªŒè¯ï¼šè‡ªé€‚åº”é˜ˆå€¼ä¼˜äºé™æ€é˜ˆå€¼
        """
        adaptive_result = tester.run_adaptive_threshold_test()
        
        # æ–­è¨€ï¼šè‡ªé€‚åº”é˜ˆå€¼å‡†ç¡®ç‡åˆç†
        assert adaptive_result.get("adaptive_accuracy", 0) > 0, "è‡ªé€‚åº”é˜ˆå€¼æµ‹è¯•å¤±è´¥"
        
        # æ–­è¨€ï¼šé˜ˆå€¼èŒƒå›´åˆç†
        lower, upper = adaptive_result.get("threshold_range", (0, 0))
        assert lower < upper, "é˜ˆå€¼ä¸‹é™åº”å°äºä¸Šé™"
        
        print("\nâœ… è‡ªé€‚åº”é˜ˆå€¼æµ‹è¯•é€šè¿‡")
    
    def test_full_workflow(self, tester):
        """
        æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹
        
        é£é™©ç‚¹ï¼šå„ç¯èŠ‚é›†æˆå¤±è´¥
        éªŒè¯ï¼šåŸºçº¿å»ºç«‹â†’æ¼‚ç§»æ£€æµ‹â†’é˜ˆå€¼è°ƒæ•´æµç¨‹å®Œæ•´
        """
        # 1. å»ºç«‹åŸºçº¿
        baseline_result = tester.run_baseline_building_test()
        
        # 2. æ¼‚ç§»æ£€æµ‹
        drift_results = tester.run_drift_detection_test()
        
        # 3. è‡ªé€‚åº”é˜ˆå€¼
        adaptive_result = tester.run_adaptive_threshold_test()
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        tester.generate_report(baseline_result, drift_results, adaptive_result)
        
        # æœ€ç»ˆæ–­è¨€ï¼šæ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸
        assert baseline_result.get("baseline") is not None
        assert len(drift_results) > 0
        assert adaptive_result.get("adaptive_accuracy", 0) > 0
        
        print("\nâœ… å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡")


# ä¸»æ‰§è¡Œå…¥å£
if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸš€ AI QA System Test - Day 06: è¾“å‡ºç¨³å®šæ€§åŸºçº¿å»ºç«‹ä¸æ¼‚ç§»æ£€æµ‹")
    print("="*70)
    print("\næµ‹è¯•å†…å®¹:")
    print("  1. ç¨³å®šæ€§åŸºçº¿å»ºç«‹")
    print("  2. æ¼‚ç§»æ£€æµ‹ç®—æ³•éªŒè¯ï¼ˆå‡å€¼/æ–¹å·®/åˆ†å¸ƒï¼‰")
    print("  3. è‡ªé€‚åº”é˜ˆå€¼ vs é™æ€é˜ˆå€¼å¯¹æ¯”")
    print("\n" + "-"*70)
    
    # åˆ›å»ºæµ‹è¯•å™¨å¹¶æ‰§è¡Œå®Œæ•´æµ‹è¯•æµç¨‹
    tester = StabilityTester()
    
    # 1. åŸºçº¿å»ºç«‹æµ‹è¯•
    baseline_result = tester.run_baseline_building_test()
    
    # 2. æ¼‚ç§»æ£€æµ‹æµ‹è¯•
    drift_results = tester.run_drift_detection_test()
    
    # 3. è‡ªé€‚åº”é˜ˆå€¼æµ‹è¯•
    adaptive_result = tester.run_adaptive_threshold_test()
    
    # ç”ŸæˆæŠ¥å‘Š
    tester.generate_report(baseline_result, drift_results, adaptive_result)

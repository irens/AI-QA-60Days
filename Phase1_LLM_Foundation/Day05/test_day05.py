"""
è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ï¼šDay 05 - é‡‡æ ·å‚æ•°ä¸è¾“å‡ºç¨³å®šæ€§éªŒè¯
ç›®æ ‡ï¼šæ¸©åº¦Ã—Top-på‚æ•°ç½‘æ ¼æ‰«æã€æ—¶é—´ç»´åº¦ä¸€è‡´æ€§éªŒè¯
é£é™©è§†è§’ï¼šä¸“æ³¨å‚æ•°ç»„åˆé£é™©ä¸ç¨³å®šæ€§è¾¹ç•Œæ¢æµ‹
"""

import os
import pytest
import time
import re
from typing import List, Dict, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime
from collections import defaultdict


@dataclass
class SamplingTestResult:
    """é‡‡æ ·å‚æ•°æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    temperature: float
    top_p: float
    responses: List[str] = field(default_factory=list)
    diversity_score: float = 0.0
    stability_rating: str = "UNKNOWN"  # STABLE / VARIABLE / UNSTABLE
    risk_level: str = "LOW"  # LOW / MEDIUM / HIGH / CRITICAL
    timestamps: List[str] = field(default_factory=list)


@dataclass
class BoundaryTestResult:
    """è¾¹ç•Œæ¡ä»¶æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    param_name: str
    param_value: Any
    is_valid: bool
    error_type: str = ""
    system_response: str = ""


class SamplingParameterTester:
    """é‡‡æ ·å‚æ•°ç»„åˆæµ‹è¯•å™¨"""
    
    # é£é™©ç­‰çº§å®šä¹‰
    RISK_CRITICAL = "ğŸ”´ CRITICAL"
    RISK_HIGH = "ğŸŸ  HIGH"
    RISK_MEDIUM = "ğŸŸ¡ MEDIUM"
    RISK_LOW = "ğŸŸ¢ LOW"
    
    # ç¨³å®šæ€§è¯„çº§
    STABLE = "âœ… STABLE"
    VARIABLE = "âš ï¸ VARIABLE"
    UNSTABLE = "ğŸ”´ UNSTABLE"
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.model = os.getenv("TEST_MODEL", "gpt-3.5-turbo")
        self._client = None
        
        # æ ‡å‡†æµ‹è¯•Prompt - è®¾è®¡ç”¨äºæ£€æµ‹è¾“å‡ºå˜åŒ–
        self.test_prompts = [
            "ç”¨ä¸€å¥è¯æè¿°äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•ã€‚",
            "è¯·åˆ—ä¸¾ä¸‰ç§æé«˜å·¥ä½œæ•ˆç‡çš„æ–¹æ³•ã€‚",
            "æè¿°ä¸€ä¸‹ä½ ç†æƒ³ä¸­çš„ä¸€å¤©çš„å¼€å§‹ã€‚",
        ]
    
    @property
    def client(self):
        """å»¶è¿Ÿåˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        if self._client is None:
            try:
                from openai import OpenAI
                self._client = OpenAI(
                    api_key=self.api_key,
                    base_url=self.base_url
                )
            except ImportError:
                raise ImportError("è¯·å®‰è£…openaiåº“: pip install openai")
        return self._client
    
    def call_llm(self, prompt: str, temperature: float, top_p: float, 
                 max_tokens: int = 50, n: int = 1) -> List[str]:
        """
        è°ƒç”¨LLMè·å–å“åº”
        
        Args:
            prompt: è¾“å…¥æç¤º
            temperature: æ¸©åº¦å‚æ•° (0-2)
            top_p: Top-på‚æ•° (0-1)
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            n: ç”Ÿæˆå¤šå°‘ä¸ªç‹¬ç«‹å›å¤
            
        Returns:
            æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬åˆ—è¡¨
        """
        if not self.api_key:
            return self._mock_response(prompt, temperature, top_p, n)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                top_p=top_p,
                max_tokens=max_tokens,
                n=n
            )
            return [choice.message.content.strip() for choice in response.choices]
        except Exception as e:
            error_msg = str(e)
            print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥ [T={temperature}, P={top_p}]: {error_msg[:100]}")
            return [f"[ERROR] {error_msg[:50]}"]
    
    def _mock_response(self, prompt: str, temperature: float, 
                       top_p: float, n: int) -> List[str]:
        """
        æ¨¡æ‹ŸLLMå“åº”ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
        æ¨¡æ‹Ÿæ¸©åº¦Ã—Top-på‚æ•°ç»„åˆå¯¹è¾“å‡ºçš„å½±å“
        """
        import random
        base_seed = hash(f"{prompt}{temperature}{top_p}") % 10000
        
        # ç¡®å®šæ€§å“åº”åº“
        deterministic_responses = [
            "äººå·¥æ™ºèƒ½å°†æ·±åˆ»æ”¹å˜äººç±»ç¤¾ä¼šçš„ç”Ÿäº§ç”Ÿæ´»æ–¹å¼ã€‚",
            "AIæŠ€æœ¯å°†åœ¨åŒ»ç–—ã€æ•™è‚²ã€äº¤é€šç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚",
            "æœªæ¥äººå·¥æ™ºèƒ½å°†ä¸äººç±»åä½œï¼Œæå‡æ•´ä½“ç¤¾ä¼šæ•ˆç‡ã€‚"
        ]
        
        # åˆ›æ„æ€§å“åº”åº“ï¼ˆæ›´å¤šæ ·åŒ–ï¼‰
        creative_responses = [
            "æƒ³è±¡ä¸€ä¸‹ï¼Œå½“AIæ‹¥æœ‰äº†çœŸæ­£çš„åˆ›é€ åŠ›ï¼Œè‰ºæœ¯å°†ç„•å‘å…¨æ–°çš„ç”Ÿå‘½åŠ›ï¼",
            "æœªæ¥çš„AIå¯èƒ½åƒç©ºæ°”ä¸€æ ·æ— å¤„ä¸åœ¨ï¼Œé»˜é»˜æœåŠ¡äºæ¯ä¸ªäººçš„æ—¥å¸¸ã€‚",
            "æˆ–è®¸æœ‰ä¸€å¤©ï¼ŒAIä¼šæˆä¸ºäººç±»æ¢ç´¢å®‡å®™æœ€å¾—åŠ›çš„ä¼™ä¼´å’Œå‘å¯¼ã€‚",
            "å½“æœºå™¨å­¦ä¼šç†è§£æƒ…æ„Ÿï¼Œäººæœºäº¤äº’å°†å˜å¾—å‰æ‰€æœªæœ‰çš„æ¸©æš–è‡ªç„¶ã€‚",
            "AIçš„å‘å±•å°±åƒæ‰“å¼€æ½˜å¤šæ‹‰é­”ç›’ï¼Œå……æ»¡æ— é™å¯èƒ½ä¸æŒ‘æˆ˜ã€‚",
            "æœªæ¥çš„æ™ºèƒ½åŠ©æ‰‹å¯èƒ½æ¯”ä½ æ›´äº†è§£ä½ è‡ªå·±ï¼Œç²¾å‡†é¢„æµ‹ä½ çš„éœ€æ±‚ã€‚"
        ]
        
        responses = []
        for i in range(n):
            random.seed(base_seed + i + int(time.time() * 1000) % 1000)
            
            # è®¡ç®—éšæœºæ€§å› å­ (0-1)
            randomness = min(1.0, (temperature / 1.5) * (0.5 + top_p / 2))
            
            if randomness < 0.2:
                # ä½éšæœºæ€§ï¼šä»ç¡®å®šæ€§åº“é€‰æ‹©ï¼Œå˜åŒ–å¾ˆå°
                idx = random.randint(0, min(1, len(deterministic_responses) - 1))
                responses.append(deterministic_responses[idx])
            elif randomness < 0.5:
                # ä¸­ç­‰éšæœºæ€§ï¼šæ··åˆé€‰æ‹©
                if random.random() > 0.3:
                    idx = random.randint(0, len(deterministic_responses) - 1)
                    responses.append(deterministic_responses[idx])
                else:
                    idx = random.randint(0, len(creative_responses) - 1)
                    responses.append(creative_responses[idx])
            else:
                # é«˜éšæœºæ€§ï¼šä»åˆ›æ„åº“é€‰æ‹©ï¼Œå˜åŒ–å¤§
                idx = random.randint(0, len(creative_responses) - 1)
                responses.append(creative_responses[idx])
        
        return responses
    
    def calculate_diversity(self, responses: List[str]) -> float:
        """
        è®¡ç®—å“åº”å¤šæ ·æ€§åˆ†æ•° (0-1)
        ä½¿ç”¨ç®€å•çš„Jaccardç›¸ä¼¼åº¦å¹³å‡å·®å¼‚
        """
        if len(responses) < 2:
            return 0.0
        
        def jaccard_distance(s1: str, s2: str) -> float:
            """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„Jaccardè·ç¦»"""
            set1 = set(s1)
            set2 = set(s2)
            if not set1 and not set2:
                return 0.0
            intersection = len(set1 & set2)
            union = len(set1 | set2)
            return 1.0 - (intersection / union) if union > 0 else 0.0
        
        distances = []
        for i in range(len(responses)):
            for j in range(i + 1, len(responses)):
                distances.append(jaccard_distance(responses[i], responses[j]))
        
        return sum(distances) / len(distances) if distances else 0.0
    
    def assess_risk(self, temperature: float, top_p: float, 
                    diversity: float) -> Tuple[str, str]:
        """
        è¯„ä¼°å‚æ•°ç»„åˆçš„é£é™©ç­‰çº§å’Œç¨³å®šæ€§è¯„çº§
        
        Returns:
            (risk_level, stability_rating)
        """
        # é£é™©çŸ©é˜µåˆ¤æ–­
        if temperature > 1.0 and top_p > 0.9:
            return self.RISK_CRITICAL, self.UNSTABLE
        elif temperature > 1.0 or (temperature > 0.7 and top_p > 0.9):
            return self.RISK_HIGH, self.UNSTABLE
        elif temperature > 0.7 and top_p > 0.5:
            return self.RISK_MEDIUM, self.VARIABLE
        elif temperature < 0.3:
            return self.RISK_LOW, self.STABLE
        else:
            return self.RISK_LOW, self.STABLE
    
    def grid_scan(self, temperatures: List[float] = None, 
                  top_ps: List[float] = None,
                  samples_per_cell: int = 3) -> Dict[Tuple[float, float], SamplingTestResult]:
        """
        æ‰§è¡Œå‚æ•°ç½‘æ ¼æ‰«æ
        
        Args:
            temperatures: æ¸©åº¦å‚æ•°åˆ—è¡¨
            top_ps: Top-på‚æ•°åˆ—è¡¨
            samples_per_cell: æ¯ä¸ªå‚æ•°ç»„åˆçš„é‡‡æ ·æ¬¡æ•°
            
        Returns:
            å‚æ•°ç»„åˆåˆ°æµ‹è¯•ç»“æœçš„æ˜ å°„
        """
        if temperatures is None:
            temperatures = [0.0, 0.3, 0.7, 1.0, 1.5]
        if top_ps is None:
            top_ps = [0.1, 0.5, 0.9, 1.0]
        
        results = {}
        prompt = self.test_prompts[0]
        
        print("\n" + "="*70)
        print("ğŸ§ª å‚æ•°ç½‘æ ¼æ‰«æå¯åŠ¨")
        print("="*70)
        print(f"æ¸©åº¦ç»´åº¦: {temperatures}")
        print(f"Top-pç»´åº¦: {top_ps}")
        print(f"æ€»ç»„åˆæ•°: {len(temperatures)} Ã— {len(top_ps)} = {len(temperatures) * len(top_ps)}")
        print("-"*70)
        
        for temp in temperatures:
            for top_p in top_ps:
                print(f"\nğŸ“Š æµ‹è¯•ç»„åˆ: temperature={temp}, top_p={top_p}")
                
                responses = []
                timestamps = []
                
                for i in range(samples_per_cell):
                    try:
                        result = self.call_llm(
                            prompt=prompt,
                            temperature=temp,
                            top_p=top_p,
                            n=1
                        )
                        responses.extend(result)
                        timestamps.append(datetime.now().isoformat())
                        time.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡å¿«
                    except Exception as e:
                        responses.append(f"[ERROR] {str(e)[:30]}")
                
                diversity = self.calculate_diversity(responses)
                risk, stability = self.assess_risk(temp, top_p, diversity)
                
                result = SamplingTestResult(
                    temperature=temp,
                    top_p=top_p,
                    responses=responses,
                    diversity_score=diversity,
                    stability_rating=stability,
                    risk_level=risk,
                    timestamps=timestamps
                )
                results[(temp, top_p)] = result
                
                print(f"   å¤šæ ·æ€§: {diversity:.3f} | ç¨³å®šæ€§: {stability} | é£é™©: {risk}")
                for j, resp in enumerate(responses[:2], 1):
                    preview = resp[:40] + "..." if len(resp) > 40 else resp
                    print(f"   å“åº”{j}: {preview}")
        
        return results
    
    def temporal_stability_test(self, temperature: float = 0.7, 
                                top_p: float = 0.9,
                                iterations: int = 10,
                                delay_seconds: float = 0.5) -> SamplingTestResult:
        """
        æ—¶é—´ç»´åº¦ä¸€è‡´æ€§éªŒè¯
        
        Args:
            temperature: æ¸©åº¦å‚æ•°
            top_p: Top-på‚æ•°
            iterations: è¿ç»­è°ƒç”¨æ¬¡æ•°
            delay_seconds: æ¯æ¬¡è°ƒç”¨é—´éš”
            
        Returns:
            æ—¶é—´ç¨³å®šæ€§æµ‹è¯•ç»“æœ
        """
        print("\n" + "="*70)
        print(f"â±ï¸ æ—¶é—´ç»´åº¦ç¨³å®šæ€§æµ‹è¯• [T={temperature}, P={top_p}]")
        print("="*70)
        
        prompt = "ç”¨10ä¸ªå­—æè¿°äººå·¥æ™ºèƒ½ã€‚"
        responses = []
        timestamps = []
        latencies = []
        
        for i in range(iterations):
            start = time.time()
            try:
                result = self.call_llm(
                    prompt=prompt,
                    temperature=temperature,
                    top_p=top_p,
                    max_tokens=20
                )
                latency = time.time() - start
                responses.extend(result)
                timestamps.append(datetime.now().strftime("%H:%M:%S.%f")[:-3])
                latencies.append(latency)
                print(f"   [{i+1}/{iterations}] {timestamps[-1]} | {latency:.3f}s | {result[0][:30]}...")
            except Exception as e:
                responses.append(f"[ERROR]")
                timestamps.append(datetime.now().strftime("%H:%M:%S.%f")[:-3])
                latencies.append(0)
                print(f"   [{i+1}/{iterations}] ERROR: {str(e)[:40]}")
            
            if i < iterations - 1:
                time.sleep(delay_seconds)
        
        diversity = self.calculate_diversity(responses)
        
        # è®¡ç®—å˜å¼‚ç³»æ•°(CV)
        if latencies and sum(latencies) > 0:
            mean_latency = sum(latencies) / len(latencies)
            std_latency = (sum((x - mean_latency) ** 2 for x in latencies) / len(latencies)) ** 0.5
            cv = std_latency / mean_latency if mean_latency > 0 else 0
        else:
            cv = 0
        
        print(f"\nğŸ“ˆ ç»Ÿè®¡ç»“æœ:")
        print(f"   å¤šæ ·æ€§åˆ†æ•°: {diversity:.3f}")
        print(f"   å¹³å‡å»¶è¿Ÿ: {sum(latencies)/len(latencies):.3f}s")
        print(f"   å»¶è¿Ÿå˜å¼‚ç³»æ•°(CV): {cv:.3f}")
        
        # ç¨³å®šæ€§åˆ¤æ–­
        if diversity < 0.3 and cv < 0.3:
            stability = self.STABLE
        elif diversity < 0.6 and cv < 0.5:
            stability = self.VARIABLE
        else:
            stability = self.UNSTABLE
        
        print(f"   ç¨³å®šæ€§è¯„çº§: {stability}")
        
        return SamplingTestResult(
            temperature=temperature,
            top_p=top_p,
            responses=responses,
            diversity_score=diversity,
            stability_rating=stability,
            timestamps=timestamps
        )
    
    def boundary_test(self) -> List[BoundaryTestResult]:
        """
        è¾¹ç•Œæ¡ä»¶æµ‹è¯•
        
        Returns:
            è¾¹ç•Œæµ‹è¯•ç»“æœåˆ—è¡¨
        """
        print("\n" + "="*70)
        print("ğŸ” è¾¹ç•Œæ¡ä»¶æµ‹è¯•")
        print("="*70)
        
        boundary_cases = [
            ("temperature", -0.1, "è´Ÿå€¼"),
            ("temperature", 0.0, "é›¶å€¼"),
            ("temperature", 0.0001, "æå°å€¼"),
            ("temperature", 2.0, "è¾¹ç•Œå€¼"),
            ("temperature", 2.1, "è¶…ç•Œå€¼"),
            ("temperature", 10.0, "æç«¯å€¼"),
            ("top_p", -0.1, "è´Ÿå€¼"),
            ("top_p", 0.0, "é›¶å€¼"),
            ("top_p", 0.0001, "æå°å€¼"),
            ("top_p", 1.0, "è¾¹ç•Œå€¼"),
            ("top_p", 1.1, "è¶…ç•Œå€¼"),
        ]
        
        results = []
        prompt = "ä½ å¥½"
        
        for param, value, desc in boundary_cases:
            print(f"\n   æµ‹è¯• {param}={value} ({desc})")
            
            try:
                if param == "temperature":
                    result = self.call_llm(prompt, temperature=value, top_p=0.9)
                else:
                    result = self.call_llm(prompt, temperature=0.7, top_p=value)
                
                is_error = any("[ERROR]" in r for r in result)
                
                boundary_result = BoundaryTestResult(
                    param_name=f"{param}={value}",
                    param_value=value,
                    is_valid=not is_error,
                    error_type="API_ERROR" if is_error else "",
                    system_response=result[0][:50] if result else ""
                )
                
                status = "âŒ å¼‚å¸¸" if is_error else "âœ… æ­£å¸¸"
                print(f"      ç»“æœ: {status} | å“åº”: {result[0][:40]}...")
                
            except Exception as e:
                boundary_result = BoundaryTestResult(
                    param_name=f"{param}={value}",
                    param_value=value,
                    is_valid=False,
                    error_type="EXCEPTION",
                    system_response=str(e)[:50]
                )
                print(f"      ç»“æœ: âŒ å¼‚å¸¸ | é”™è¯¯: {str(e)[:40]}")
            
            results.append(boundary_result)
        
        return results
    
    def generate_report(self, grid_results: Dict, temporal_result: SamplingTestResult,
                       boundary_results: List[BoundaryTestResult]):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šæ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸ“‹ æµ‹è¯•æŠ¥å‘Šæ‘˜è¦")
        print("="*70)
        
        # 1. å‚æ•°ç½‘æ ¼æ‰«ææ‘˜è¦
        print("\nã€1. å‚æ•°ç½‘æ ¼æ‰«æç»“æœã€‘")
        risk_counts = defaultdict(int)
        for result in grid_results.values():
            risk_counts[result.risk_level] += 1
        
        print(f"   æ€»ç»„åˆæ•°: {len(grid_results)}")
        for risk, count in sorted(risk_counts.items(), 
                                  key=lambda x: {"ğŸ”´ CRITICAL": 0, "ğŸŸ  HIGH": 1, 
                                                "ğŸŸ¡ MEDIUM": 2, "ğŸŸ¢ LOW": 3}.get(x[0], 4)):
            print(f"   {risk}: {count}ä¸ªç»„åˆ")
        
        # 2. é«˜é£é™©ç»„åˆæ¸…å•
        print("\nã€2. é«˜é£é™©ç»„åˆæ¸…å• (ç”Ÿäº§ç¯å¢ƒç¦ç”¨)ã€‘")
        critical_high = [(k, v) for k, v in grid_results.items() 
                        if "CRITICAL" in v.risk_level or "HIGH" in v.risk_level]
        if critical_high:
            for (temp, top_p), result in critical_high:
                print(f"   ğŸ”´ T={temp}, P={top_p} â†’ {result.stability_rating}")
        else:
            print("   âœ… æœªå‘ç°é«˜é£é™©ç»„åˆ")
        
        # 3. æ¨èé…ç½®
        print("\nã€3. ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®ã€‘")
        recommended = [(k, v) for k, v in grid_results.items() 
                      if "ğŸŸ¢" in v.risk_level and "âœ…" in v.stability_rating]
        for (temp, top_p), result in recommended[:3]:
            print(f"   âœ… temperature={temp}, top_p={top_p}")
        
        # 4. æ—¶é—´ç¨³å®šæ€§
        print("\nã€4. æ—¶é—´ç»´åº¦ç¨³å®šæ€§ã€‘")
        print(f"   æµ‹è¯•å‚æ•°: T={temporal_result.temperature}, P={temporal_result.top_p}")
        print(f"   å¤šæ ·æ€§åˆ†æ•°: {temporal_result.diversity_score:.3f}")
        print(f"   ç¨³å®šæ€§è¯„çº§: {temporal_result.stability_rating}")
        
        # 5. è¾¹ç•Œæµ‹è¯•
        print("\nã€5. è¾¹ç•Œæ¡ä»¶æµ‹è¯•ç»“æœã€‘")
        invalid_count = sum(1 for r in boundary_results if not r.is_valid)
        print(f"   æ€»æµ‹è¯•æ•°: {len(boundary_results)}")
        print(f"   å¼‚å¸¸å“åº”: {invalid_count}")
        if invalid_count > 0:
            print("   âš ï¸ å‘ç°è¾¹ç•Œå¤„ç†ç¼ºé™·ï¼Œå»ºè®®åŠ å¼ºå‚æ•°æ ¡éªŒ")
        else:
            print("   âœ… è¾¹ç•Œå¤„ç†æ­£å¸¸")
        
        print("\n" + "="*70)
        print("âœ… æµ‹è¯•æ‰§è¡Œå®Œæ¯•ï¼Œè¯·å°†ä¸Šæ–¹æ—¥å¿—å‘ç»™ Trae ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šã€‚")
        print("="*70)


# ============ pytest æµ‹è¯•ç”¨ä¾‹ ============

class TestDay05SamplingParameters:
    """Day 05: é‡‡æ ·å‚æ•°ä¸è¾“å‡ºç¨³å®šæ€§æµ‹è¯•ç±»"""
    
    @pytest.fixture(scope="class")
    def tester(self):
        """æµ‹è¯•å™¨fixture"""
        return SamplingParameterTester()
    
    def test_parameter_grid_scan(self, tester):
        """
        æµ‹è¯•æ¸©åº¦Ã—Top-på‚æ•°ç½‘æ ¼æ‰«æ
        
        é£é™©ç‚¹ï¼šå‚æ•°ç»„åˆå¯èƒ½äº§ç”Ÿæ„å¤–çš„è¾“å‡ºä¸ç¨³å®šæ€§
        éªŒè¯ï¼šæ‰€æœ‰ç»„åˆçš„å“åº”ç¬¦åˆé¢„æœŸé£é™©ç­‰çº§
        """
        # ä½¿ç”¨ç²¾ç®€ç½‘æ ¼åŠ é€Ÿæµ‹è¯•
        temperatures = [0.0, 0.3, 0.7, 1.0, 1.5]
        top_ps = [0.1, 0.5, 0.9, 1.0]
        
        grid_results = tester.grid_scan(
            temperatures=temperatures,
            top_ps=top_ps,
            samples_per_cell=2
        )
        
        # æ–­è¨€ï¼šé«˜é£é™©ç»„åˆæ•°é‡åº”åœ¨é¢„æœŸèŒƒå›´å†…
        critical_count = sum(1 for r in grid_results.values() if "ğŸ”´" in r.risk_level)
        high_count = sum(1 for r in grid_results.values() if "ğŸŸ " in r.risk_level)
        
        # T>1.0ä¸”P>0.9åº”ä¸ºCRITICAL
        assert critical_count >= 1, "åº”è‡³å°‘è¯†åˆ«å‡º1ä¸ªCRITICALé£é™©ç»„åˆ"
        
        # ä¿å­˜ç»“æœä¾›åç»­æµ‹è¯•ä½¿ç”¨
        self.grid_results = grid_results
        
        print(f"\nâœ… ç½‘æ ¼æ‰«æå®Œæˆ: {len(grid_results)}ä¸ªç»„åˆ")
    
    def test_temporal_stability(self, tester):
        """
        æµ‹è¯•æ—¶é—´ç»´åº¦ä¸€è‡´æ€§
        
        é£é™©ç‚¹ï¼šç›¸åŒå‚æ•°åœ¨ä¸åŒæ—¶é—´è°ƒç”¨è¾“å‡ºå·®å¼‚è¿‡å¤§
        éªŒè¯ï¼šè¿ç»­è°ƒç”¨çš„è¾“å‡ºå¤šæ ·æ€§åœ¨å¯æ§èŒƒå›´å†…
        """
        result = tester.temporal_stability_test(
            temperature=0.7,
            top_p=0.9,
            iterations=5,
            delay_seconds=0.2
        )
        
        # æ–­è¨€ï¼šç¨³å®šæ€§ä¸åº”ä¸ºUNSTABLEï¼ˆå¯¹äºä¸­ç­‰å‚æ•°ï¼‰
        assert "ğŸ”´" not in result.stability_rating, \
            f"T=0.7,P=0.9ä¸åº”åˆ¤å®šä¸ºUNSTABLEï¼Œå®é™…: {result.stability_rating}"
        
        # æ–­è¨€ï¼šå¤šæ ·æ€§åˆ†æ•°åº”åœ¨åˆç†èŒƒå›´
        assert 0 <= result.diversity_score <= 1, \
            f"å¤šæ ·æ€§åˆ†æ•°åº”åœ¨0-1èŒƒå›´å†…ï¼Œå®é™…: {result.diversity_score}"
        
        self.temporal_result = result
        
        print(f"\nâœ… æ—¶é—´ç¨³å®šæ€§æµ‹è¯•å®Œæˆ: {result.stability_rating}")
    
    def test_boundary_conditions(self, tester):
        """
        æµ‹è¯•å‚æ•°è¾¹ç•Œæ¡ä»¶
        
        é£é™©ç‚¹ï¼šæç«¯å‚æ•°å€¼å¯¼è‡´ç³»ç»Ÿå¼‚å¸¸
        éªŒè¯ï¼šç³»ç»Ÿå¯¹è¾¹ç•Œå€¼æœ‰é€‚å½“çš„é”™è¯¯å¤„ç†
        """
        boundary_results = tester.boundary_test()
        
        # ç»Ÿè®¡ç»“æœ
        valid_count = sum(1 for r in boundary_results if r.is_valid)
        invalid_count = len(boundary_results) - valid_count
        
        print(f"\nğŸ“Š è¾¹ç•Œæµ‹è¯•ç»Ÿè®¡: {valid_count}æ­£å¸¸ / {invalid_count}å¼‚å¸¸")
        
        # æ–­è¨€ï¼šç³»ç»Ÿåº”å¯¹æ˜æ˜¾è¶Šç•Œå€¼æœ‰å¤„ç†ï¼ˆå…è®¸éƒ¨åˆ†å®¹é”™ï¼‰
        # æ³¨æ„ï¼šä¸åŒAPIå®ç°å¯èƒ½æœ‰ä¸åŒçš„å®¹é”™ç­–ç•¥
        extreme_invalid = [r for r in boundary_results 
                          if not r.is_valid and abs(r.param_value) > 2]
        
        if extreme_invalid:
            print(f"   âš ï¸ å‘ç°{len(extreme_invalid)}ä¸ªæç«¯å€¼æœªæ­£ç¡®å¤„ç†")
        
        self.boundary_results = boundary_results
        
        print("\nâœ… è¾¹ç•Œæ¡ä»¶æµ‹è¯•å®Œæˆ")
    
    def test_generate_final_report(self, tester):
        """
        ç”Ÿæˆæœ€ç»ˆæµ‹è¯•æŠ¥å‘Š
        
        æ³¨æ„ï¼šæ­¤æµ‹è¯•ä¾èµ–äºå‰é¢æµ‹è¯•çš„ç»“æœ
        """
        # é‡æ–°è¿è¡Œä»¥è·å–å®Œæ•´ç»“æœ
        grid_results = tester.grid_scan(
            temperatures=[0.0, 0.3, 0.7, 1.0, 1.5],
            top_ps=[0.1, 0.5, 0.9, 1.0],
            samples_per_cell=2
        )
        temporal_result = tester.temporal_stability_test(
            temperature=0.7, top_p=0.9, iterations=5, delay_seconds=0.2
        )
        boundary_results = tester.boundary_test()
        
        # ç”ŸæˆæŠ¥å‘Š
        tester.generate_report(grid_results, temporal_result, boundary_results)
        
        # æœ€ç»ˆæ–­è¨€ï¼šè‡³å°‘åº”æœ‰ä¸€äº›ç¨³å®šé…ç½®
        stable_count = sum(1 for r in grid_results.values() if "âœ…" in r.stability_rating)
        assert stable_count > 0, "åº”è‡³å°‘å­˜åœ¨1ä¸ªç¨³å®šé…ç½®"
        
        print("\nâœ… æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")


# ä¸»æ‰§è¡Œå…¥å£
if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸš€ AI QA System Test - Day 05: é‡‡æ ·å‚æ•°ä¸è¾“å‡ºç¨³å®šæ€§")
    print("="*70)
    print("\næµ‹è¯•å†…å®¹:")
    print("  1. æ¸©åº¦Ã—Top-på‚æ•°ç½‘æ ¼æ‰«æ (20ç§ç»„åˆ)")
    print("  2. æ—¶é—´ç»´åº¦ä¸€è‡´æ€§éªŒè¯")
    print("  3. è¾¹ç•Œæ¡ä»¶æµ‹è¯•")
    print("\n" + "-"*70)
    
    # åˆ›å»ºæµ‹è¯•å™¨å¹¶æ‰§è¡Œå®Œæ•´æµ‹è¯•æµç¨‹
    tester = SamplingParameterTester()
    
    # 1. å‚æ•°ç½‘æ ¼æ‰«æ
    grid_results = tester.grid_scan(
        temperatures=[0.0, 0.3, 0.7, 1.0, 1.5],
        top_ps=[0.1, 0.5, 0.9, 1.0],
        samples_per_cell=2
    )
    
    # 2. æ—¶é—´ç¨³å®šæ€§æµ‹è¯•
    temporal_result = tester.temporal_stability_test(
        temperature=0.7,
        top_p=0.9,
        iterations=5,
        delay_seconds=0.2
    )
    
    # 3. è¾¹ç•Œæµ‹è¯•
    boundary_results = tester.boundary_test()
    
    # ç”ŸæˆæŠ¥å‘Š
    tester.generate_report(grid_results, temporal_result, boundary_results)

"""
è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ï¼šDay 09 - å¹»è§‰æ£€æµ‹ä¸äº‹å®ä¸€è‡´æ€§éªŒè¯
ç›®æ ‡ï¼šå£°æ˜æŠ½å–ã€NLIæ£€æµ‹ã€è‡ªæ´½æ€§éªŒè¯ã€å¹»è§‰é£é™©è¯„ä¼°
é£é™©è§†è§’ï¼šä¸“æ³¨LLMå¹»è§‰è¿™ä¸€ç³»ç»Ÿæ€§è´¨é‡é£é™©
"""

import pytest
import json
import re
import statistics
from typing import List, Dict, Tuple, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
from enum import Enum


class HallucinationType(Enum):
    """å¹»è§‰ç±»å‹"""
    FACTUAL_HALLUCINATION = "äº‹å®å¹»è§‰"      # ç¼–é€ ä¸å­˜åœ¨çš„äº‹å®
    LOGICAL_HALLUCINATION = "é€»è¾‘å¹»è§‰"      # æ¨ç†é”™è¯¯
    CONSISTENCY_HALLUCINATION = "ä¸€è‡´æ€§å¹»è§‰"  # å‰åçŸ›ç›¾
    CITATION_HALLUCINATION = "å¼•ç”¨å¹»è§‰"     # ç¼–é€ æ¥æº
    CONFIDENCE_MISMATCH = "ç½®ä¿¡åº¦ä¸åŒ¹é…"     # è¿‡åº¦è‡ªä¿¡


class RiskLevel(Enum):
    """é£é™©ç­‰çº§"""
    CRITICAL = "ğŸ”´ CRITICAL"
    HIGH = "ğŸŸ  HIGH"
    MEDIUM = "ğŸŸ¡ MEDIUM"
    LOW = "ğŸŸ¢ LOW"
    PASS = "âœ… PASS"


class NLIResult(Enum):
    """è‡ªç„¶è¯­è¨€æ¨ç†ç»“æœ"""
    ENTAILMENT = "è•´å«"       # å‰ææ”¯æŒå‡è®¾
    CONTRADICTION = "çŸ›ç›¾"    # å‰æå¦å®šå‡è®¾
    NEUTRAL = "ä¸­ç«‹"          # æ— å…³


@dataclass
class Claim:
    """äº‹å®å£°æ˜"""
    text: str
    claim_type: str           # å®ä½“/å…³ç³»/äº‹ä»¶
    entities: List[str]       # æ¶‰åŠçš„å®ä½“
    verifiable: bool          # æ˜¯å¦å¯éªŒè¯


@dataclass
class HallucinationReport:
    """å¹»è§‰æ£€æµ‹æŠ¥å‘Š"""
    test_id: str
    answer: str
    reference: str
    claims: List[Dict]
    nli_results: List[Dict]
    hallucination_ratio: float
    risk_level: RiskLevel
    detected_types: List[HallucinationType]


class MockLLM:
    """æ¨¡æ‹ŸLLMç”¨äºæµ‹è¯•"""
    
    def __init__(self, model_name: str = "mock-llm"):
        self.model_name = model_name
        self.call_count = 0
    
    def generate(self, prompt: str, temperature: float = 0.7, n: int = 1) -> List[str]:
        """æ¨¡æ‹Ÿç”Ÿæˆå›ç­”"""
        self.call_count += 1
        
        # æ¨¡æ‹Ÿä¸åŒåœºæ™¯çš„å›ç­”
        responses = {
            "çˆ±å› æ–¯å¦": [
                "çˆ±å› æ–¯å¦äº1921å¹´è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ï¼Œä»–æå‡ºäº†ç›¸å¯¹è®ºã€‚",
                "çˆ±å› æ–¯å¦åœ¨1921å¹´å› å…‰ç”µæ•ˆåº”è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ã€‚",
                "é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦äº1921å¹´è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ã€‚"
            ],
            "å¹»è§‰": [
                "çˆ±å› æ–¯å¦äº1921å¹´è·å¾—è¯ºè´å°”æ–‡å­¦å¥–ã€‚",  # äº‹å®å¹»è§‰
                "æ ¹æ®ã€Šè‡ªç„¶ã€‹æ‚å¿—2024å¹´ç ”ç©¶ï¼Œé‡å­çº ç¼ å¯ç”¨äºè¶…å…‰é€Ÿé€šä¿¡ã€‚",  # å¼•ç”¨å¹»è§‰
            ],
            "çŸ›ç›¾": [
                "åŒ—äº¬ä»Šå¤©æ°”æ¸©25åº¦ï¼Œé€‚åˆç©¿ç¾½ç»’æœã€‚",  # é€»è¾‘çŸ›ç›¾
            ]
        }
        
        # æ ¹æ®promptå…³é”®è¯è¿”å›å¯¹åº”å›ç­”
        for key in responses:
            if key in prompt:
                if n == 1:
                    return [responses[key][0]]
                return responses[key][:n]
        
        # é»˜è®¤å›ç­”
        default = f"è¿™æ˜¯å¯¹'{prompt}'çš„å›ç­”ã€‚"
        return [default] * n if n > 1 else [default]


class MockNLIModel:
    """æ¨¡æ‹ŸNLIæ¨¡å‹"""
    
    def predict(self, premise: str, hypothesis: str) -> Dict[str, float]:
        """
        æ¨¡æ‹ŸNLIé¢„æµ‹
        è¿”å›è•´å«/çŸ›ç›¾/ä¸­ç«‹çš„æ¦‚ç‡åˆ†å¸ƒ
        """
        # ç®€å•çš„è§„åˆ™æ¨¡æ‹Ÿ
        hypothesis_lower = hypothesis.lower()
        premise_lower = premise.lower()
        
        # çŸ›ç›¾æ£€æµ‹è§„åˆ™
        contradictions = [
            ("ç‰©ç†å­¦å¥–", "æ–‡å­¦å¥–"),
            ("25åº¦", "ç¾½ç»’æœ"),
            ("å¤å¤©", "ä¸‹é›ª"),
        ]
        
        for truth, false in contradictions:
            if truth in premise_lower and false in hypothesis_lower:
                return {
                    "entailment": 0.05,
                    "contradiction": 0.90,
                    "neutral": 0.05
                }
        
        # è•´å«æ£€æµ‹è§„åˆ™
        if any(word in premise_lower for word in hypothesis_lower.split()):
            # ç®€å•åˆ¤æ–­ï¼šå¦‚æœå…³é”®è¯åœ¨å‰æä¸­ï¼Œå¯èƒ½æ˜¯è•´å«
            if len(hypothesis) < len(premise) * 0.8:
                return {
                    "entailment": 0.85,
                    "contradiction": 0.05,
                    "neutral": 0.10
                }
        
        # é»˜è®¤ä¸­ç«‹
        return {
            "entailment": 0.20,
            "contradiction": 0.10,
            "neutral": 0.70
        }


class HallucinationDetector:
    """å¹»è§‰æ£€æµ‹å™¨"""
    
    def __init__(self, nli_model: Optional[MockNLIModel] = None):
        self.nli_model = nli_model or MockNLIModel()
        self.detection_history = []
    
    def extract_claims(self, text: str) -> List[Claim]:
        """
        ä»æ–‡æœ¬ä¸­æŠ½å–äº‹å®å£°æ˜
        ç®€åŒ–ç‰ˆï¼šæŒ‰å¥å­åˆ†å‰²ï¼Œæå–åŒ…å«å®ä½“/æ•°å­—çš„å¥å­
        """
        # åˆ†å¥
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        claims = []
        for sent in sentences:
            # æå–å®ä½“ï¼ˆç®€å•è§„åˆ™ï¼šå¤§å†™å­—æ¯å¼€å¤´çš„è¯ã€æ•°å­—ã€å¹´ä»½ï¼‰
            entities = []
            
            # æå–å¹´ä»½
            years = re.findall(r'\d{4}å¹´?', sent)
            entities.extend(years)
            
            # æå–äººåï¼ˆç®€å•è§„åˆ™ï¼‰
            names = re.findall(r'[\u4e00-\u9fa5]{2,4}(?:è·å¾—|æå‡º|å‘ç°)', sent)
            for name in names:
                clean_name = name.replace("è·å¾—", "").replace("æå‡º", "").replace("å‘ç°", "")
                if clean_name:
                    entities.append(clean_name)
            
            # æå–å¥–é¡¹/ä¸“æœ‰åè¯
            awards = re.findall(r'è¯ºè´å°”[^ï¼Œã€‚]+å¥–', sent)
            entities.extend(awards)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºå¯éªŒè¯å£°æ˜
            verifiable = len(entities) > 0 and any(kw in sent for kw in 
                ["è·å¾—", "æå‡º", "å‘ç°", "æ˜¯", "ä½äº", "æˆç«‹äº", "è·å¾—"])
            
            claims.append(Claim(
                text=sent,
                claim_type="entity_relation" if entities else "general",
                entities=entities,
                verifiable=verifiable
            ))
        
        return claims
    
    def detect_nli(self, claims: List[Claim], reference: str) -> List[Dict]:
        """
        ä½¿ç”¨NLIæ£€æµ‹æ¯ä¸ªå£°æ˜
        """
        results = []
        for claim in claims:
            if not claim.verifiable:
                results.append({
                    "claim": claim.text,
                    "verifiable": False,
                    "nli_result": None,
                    "is_hallucination": False
                })
                continue
            
            nli = self.nli_model.predict(reference, claim.text)
            
            # åˆ¤æ–­å¹»è§‰ï¼šçŸ›ç›¾ > 0.5 æˆ– (ä¸­ç«‹ > 0.7 ä¸”æ— æ³•éªŒè¯)
            is_hallucination = nli["contradiction"] > 0.5 or \
                             (nli["neutral"] > 0.7 and nli["entailment"] < 0.3)
            
            # ç¡®å®šNLIåˆ†ç±»
            max_label = max(nli, key=nli.get)
            nli_class = NLIResult.ENTAILMENT if max_label == "entailment" else \
                       NLIResult.CONTRADICTION if max_label == "contradiction" else \
                       NLIResult.NEUTRAL
            
            results.append({
                "claim": claim.text,
                "verifiable": True,
                "entities": claim.entities,
                "nli_result": nli,
                "nli_class": nli_class.value,
                "is_hallucination": is_hallucination,
                "hallucination_type": self._classify_hallucination_type(nli, claim)
            })
        
        return results
    
    def _classify_hallucination_type(self, nli: Dict, claim: Claim) -> Optional[HallucinationType]:
        """åˆ†ç±»å¹»è§‰ç±»å‹"""
        if nli["contradiction"] > 0.5:
            if any(e in claim.text for e in ["å¥–", "å† å†›", "ç¬¬ä¸€"]):
                return HallucinationType.FACTUAL_HALLUCINATION
            return HallucinationType.LOGICAL_HALLUCINATION
        elif nli["neutral"] > 0.7:
            if "æ ¹æ®" in claim.text or "ç ”ç©¶" in claim.text:
                return HallucinationType.CITATION_HALLUCINATION
        return None
    
    def calculate_metrics(self, nli_results: List[Dict]) -> Dict:
        """è®¡ç®—å¹»è§‰æ£€æµ‹æŒ‡æ ‡"""
        verifiable = [r for r in nli_results if r.get("verifiable")]
        
        if not verifiable:
            return {
                "hallucination_rate": 0.0,
                "fact_accuracy": 1.0,
                "verifiable_claims": 0
            }
        
        hallucinated = sum(1 for r in verifiable if r["is_hallucination"])
        
        return {
            "hallucination_rate": hallucinated / len(verifiable),
            "fact_accuracy": 1 - (hallucinated / len(verifiable)),
            "verifiable_claims": len(verifiable),
            "hallucinated_claims": hallucinated
        }
    
    def detect(self, answer: str, reference: str, test_id: str = "") -> HallucinationReport:
        """
        æ‰§è¡Œå®Œæ•´å¹»è§‰æ£€æµ‹æµç¨‹
        """
        # 1. æŠ½å–å£°æ˜
        claims = self.extract_claims(answer)
        
        # 2. NLIæ£€æµ‹
        nli_results = self.detect_nli(claims, reference)
        
        # 3. è®¡ç®—æŒ‡æ ‡
        metrics = self.calculate_metrics(nli_results)
        
        # 4. ç¡®å®šé£é™©ç­‰çº§
        risk_level = self._assess_risk(metrics["hallucination_rate"])
        
        # 5. æ”¶é›†æ£€æµ‹åˆ°çš„å¹»è§‰ç±»å‹
        detected_types = list(set(
            r["hallucination_type"] for r in nli_results 
            if r.get("hallucination_type")
        ))
        
        report = HallucinationReport(
            test_id=test_id,
            answer=answer,
            reference=reference,
            claims=[asdict(c) for c in claims],
            nli_results=nli_results,
            hallucination_ratio=metrics["hallucination_rate"],
            risk_level=risk_level,
            detected_types=detected_types
        )
        
        self.detection_history.append(report)
        return report
    
    def _assess_risk(self, hallucination_rate: float) -> RiskLevel:
        """è¯„ä¼°é£é™©ç­‰çº§"""
        if hallucination_rate >= 0.3:
            return RiskLevel.CRITICAL
        elif hallucination_rate >= 0.15:
            return RiskLevel.HIGH
        elif hallucination_rate >= 0.05:
            return RiskLevel.MEDIUM
        elif hallucination_rate > 0:
            return RiskLevel.LOW
        return RiskLevel.PASS


class ConsistencyChecker:
    """ä¸€è‡´æ€§æ£€æŸ¥å™¨ - å¤šé‡‡æ ·è‡ªæ´½æ€§éªŒè¯"""
    
    def __init__(self, llm: Optional[MockLLM] = None):
        self.llm = llm or MockLLM()
    
    def semantic_similarity(self, text1: str, text2: str) -> float:
        """
        è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆï¼šåŸºäºå…³é”®è¯é‡å ï¼‰
        å®é™…åº”ç”¨åº”ä½¿ç”¨Embeddingæ¨¡å‹
        """
        # æå–å…³é”®è¯ï¼ˆç®€å•è§„åˆ™ï¼‰
        def extract_keywords(text: str) -> set:
            # å»é™¤æ ‡ç‚¹ï¼Œæå–ä¸­æ–‡å­—ç¬¦å’Œæ•°å­—
            words = re.findall(r'[\u4e00-\u9fa5]+|\d+', text)
            return set(words)
        
        keywords1 = extract_keywords(text1)
        keywords2 = extract_keywords(text2)
        
        if not keywords1 or not keywords2:
            return 0.0
        
        # Jaccardç›¸ä¼¼åº¦
        intersection = len(keywords1 & keywords2)
        union = len(keywords1 | keywords2)
        
        return intersection / union if union > 0 else 0.0
    
    def check_self_consistency(self, prompt: str, n_samples: int = 5, 
                               temperature: float = 0.8) -> Dict:
        """
        è‡ªæ´½æ€§æ£€æŸ¥ï¼šå¤šæ¬¡é‡‡æ ·è®¡ç®—ä¸€è‡´æ€§
        """
        # å¤šæ¬¡é‡‡æ ·
        responses = self.llm.generate(prompt, temperature=temperature, n=n_samples)
        
        # è®¡ç®—ä¸¤ä¸¤ç›¸ä¼¼åº¦
        similarities = []
        for i in range(len(responses)):
            for j in range(i + 1, len(responses)):
                sim = self.semantic_similarity(responses[i], responses[j])
                similarities.append(sim)
        
        # ç»Ÿè®¡æŒ‡æ ‡
        consistency_score = statistics.mean(similarities) if similarities else 0.0
        min_similarity = min(similarities) if similarities else 0.0
        max_similarity = max(similarities) if similarities else 0.0
        
        # é£é™©è¯„çº§
        if consistency_score >= 0.9:
            risk_level = RiskLevel.PASS
        elif consistency_score >= 0.8:
            risk_level = RiskLevel.LOW
        elif consistency_score >= 0.6:
            risk_level = RiskLevel.MEDIUM
        else:
            risk_level = RiskLevel.HIGH
        
        return {
            "prompt": prompt,
            "responses": responses,
            "consistency_score": round(consistency_score, 4),
            "min_similarity": round(min_similarity, 4),
            "max_similarity": round(max_similarity, 4),
            "risk_level": risk_level.value,
            "risk_assessment": self._consistency_risk_assessment(consistency_score)
        }
    
    def _consistency_risk_assessment(self, score: float) -> str:
        """ä¸€è‡´æ€§é£é™©è¯„ä¼°è¯´æ˜"""
        if score >= 0.9:
            return "å›ç­”é«˜åº¦ä¸€è‡´ï¼Œå¹»è§‰é£é™©ä½"
        elif score >= 0.8:
            return "å›ç­”åŸºæœ¬ä¸€è‡´ï¼Œå¶æœ‰ä¸ä¸€è‡´"
        elif score >= 0.6:
            return "å›ç­”å­˜åœ¨åˆ†æ­§ï¼Œéœ€äººå·¥å®¡æ ¸"
        else:
            return "å›ç­”é«˜åº¦ä¸ä¸€è‡´ï¼Œé«˜å¹»è§‰é£é™©"


# ==================== æµ‹è¯•ç”¨ä¾‹ ====================

class TestHallucinationDetection:
    """å¹»è§‰æ£€æµ‹æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def detector(self):
        return HallucinationDetector()
    
    @pytest.fixture
    def consistency_checker(self):
        return ConsistencyChecker()
    
    def test_claim_extraction(self, detector):
        """æµ‹è¯•å£°æ˜æŠ½å–åŠŸèƒ½"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•1ã€‘å£°æ˜æŠ½å–åŠŸèƒ½éªŒè¯")
        print("="*60)
        
        text = "çˆ±å› æ–¯å¦äº1921å¹´è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ã€‚ä»–æå‡ºäº†ç›¸å¯¹è®ºã€‚"
        claims = detector.extract_claims(text)
        
        print(f"è¾“å…¥æ–‡æœ¬: {text}")
        print(f"æŠ½å–å£°æ˜æ•°: {len(claims)}")
        
        for i, claim in enumerate(claims, 1):
            print(f"\nå£°æ˜{i}:")
            print(f"  æ–‡æœ¬: {claim.text}")
            print(f"  å®ä½“: {claim.entities}")
            print(f"  å¯éªŒè¯: {claim.verifiable}")
        
        assert len(claims) >= 1, "åº”è‡³å°‘æŠ½å–åˆ°ä¸€ä¸ªå£°æ˜"
        assert any("çˆ±å› æ–¯å¦" in c.text for c in claims), "åº”åŒ…å«çˆ±å› æ–¯å¦"
        
        print("\nâœ… å£°æ˜æŠ½å–æµ‹è¯•é€šè¿‡")
    
    def test_nli_detection_entailment(self, detector):
        """æµ‹è¯•NLIè•´å«æ£€æµ‹"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•2ã€‘NLIè•´å«æ£€æµ‹éªŒè¯")
        print("="*60)
        
        # ä½¿ç”¨æ›´æ˜ç¡®çš„è•´å«å…³ç³»æµ‹è¯•
        reference = "çˆ±å› æ–¯å¦è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ï¼Œè·å¥–å¹´ä»½æ˜¯1921å¹´ï¼Œè·å¥–åŸå› æ˜¯å…‰ç”µæ•ˆåº”ç ”ç©¶ã€‚"
        answer = "1921å¹´çˆ±å› æ–¯å¦è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ã€‚"
        
        claims = detector.extract_claims(answer)
        results = detector.detect_nli(claims, reference)
        
        print(f"å‚è€ƒæ–‡æœ¬: {reference}")
        print(f"å›ç­”æ–‡æœ¬: {answer}")
        print(f"\nNLIæ£€æµ‹ç»“æœ:")
        
        for r in results:
            if r["verifiable"]:
                print(f"  å£°æ˜: {r['claim']}")
                print(f"  NLIåˆ†ç±»: {r['nli_class']}")
                print(f"  è•´å«åˆ†æ•°: {r['nli_result']['entailment']:.2f}")
                print(f"  æ˜¯å¦å¹»è§‰: {r['is_hallucination']}")
        
        # éªŒè¯ä¸åº”è¢«åˆ¤ä¸ºå¹»è§‰ï¼ˆå³ä½¿NLIåˆ†ç±»å¯èƒ½ä¸å®Œç¾ï¼‰
        entailment_result = [r for r in results if r["verifiable"]][0]
        # å…³é”®éªŒè¯ï¼šæ­£ç¡®äº‹å®ä¸åº”è¢«åˆ¤ä¸ºå¹»è§‰
        assert not entailment_result["is_hallucination"], "æ­£ç¡®äº‹å®ä¸åº”è¢«åˆ¤ä¸ºå¹»è§‰"
        
        print("\nâœ… NLIè•´å«æ£€æµ‹æµ‹è¯•é€šè¿‡")
    
    def test_nli_detection_contradiction(self, detector):
        """æµ‹è¯•NLIçŸ›ç›¾æ£€æµ‹ï¼ˆäº‹å®å¹»è§‰ï¼‰"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•3ã€‘NLIçŸ›ç›¾æ£€æµ‹éªŒè¯ï¼ˆäº‹å®å¹»è§‰ï¼‰")
        print("="*60)
        
        reference = "çˆ±å› æ–¯å¦äº1921å¹´è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ã€‚"
        answer = "çˆ±å› æ–¯å¦äº1921å¹´è·å¾—è¯ºè´å°”æ–‡å­¦å¥–ã€‚"  # äº‹å®é”™è¯¯
        
        claims = detector.extract_claims(answer)
        results = detector.detect_nli(claims, reference)
        
        print(f"å‚è€ƒæ–‡æœ¬: {reference}")
        print(f"å›ç­”æ–‡æœ¬: {answer}")
        print(f"\nNLIæ£€æµ‹ç»“æœ:")
        
        for r in results:
            if r["verifiable"]:
                print(f"  å£°æ˜: {r['claim']}")
                print(f"  NLIåˆ†ç±»: {r['nli_class']}")
                print(f"  çŸ›ç›¾åˆ†æ•°: {r['nli_result']['contradiction']:.2f}")
                print(f"  æ˜¯å¦å¹»è§‰: {r['is_hallucination']}")
                if r["hallucination_type"]:
                    print(f"  å¹»è§‰ç±»å‹: {r['hallucination_type'].value}")
        
        # éªŒè¯åº”æ£€æµ‹åˆ°çŸ›ç›¾
        contradiction_result = [r for r in results if r["verifiable"]][0]
        assert contradiction_result["nli_class"] == "çŸ›ç›¾", "é”™è¯¯äº‹å®åº”ä¸ºçŸ›ç›¾å…³ç³»"
        assert contradiction_result["is_hallucination"], "é”™è¯¯äº‹å®åº”è¢«åˆ¤ä¸ºå¹»è§‰"
        
        print("\nâœ… NLIçŸ›ç›¾æ£€æµ‹æµ‹è¯•é€šè¿‡")
    
    def test_self_consistency_check(self, consistency_checker):
        """æµ‹è¯•è‡ªæ´½æ€§æ£€æŸ¥"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•4ã€‘å¤šé‡‡æ ·è‡ªæ´½æ€§éªŒè¯")
        print("="*60)
        
        prompt = "è¯·ç®€è¿°çˆ±å› æ–¯å¦è·å¾—è¯ºè´å°”å¥–çš„æƒ…å†µ"
        
        result = consistency_checker.check_self_consistency(
            prompt, n_samples=3, temperature=0.7
        )
        
        print(f"æµ‹è¯•é—®é¢˜: {prompt}")
        print(f"é‡‡æ ·æ¬¡æ•°: 3")
        print(f"\né‡‡æ ·å›ç­”:")
        for i, resp in enumerate(result["responses"], 1):
            print(f"  {i}. {resp}")
        
        print(f"\nä¸€è‡´æ€§åˆ†æ:")
        print(f"  ä¸€è‡´æ€§åˆ†æ•°: {result['consistency_score']}")
        print(f"  æœ€å°ç›¸ä¼¼åº¦: {result['min_similarity']}")
        print(f"  æœ€å¤§ç›¸ä¼¼åº¦: {result['max_similarity']}")
        print(f"  é£é™©ç­‰çº§: {result['risk_level']}")
        print(f"  è¯„ä¼°è¯´æ˜: {result['risk_assessment']}")
        
        assert result["consistency_score"] >= 0, "ä¸€è‡´æ€§åˆ†æ•°åº”éè´Ÿ"
        assert result["risk_level"] is not None, "åº”æœ‰é£é™©è¯„çº§"
        
        print("\nâœ… è‡ªæ´½æ€§æ£€æŸ¥æµ‹è¯•é€šè¿‡")
    
    def test_hallucination_metrics(self, detector):
        """æµ‹è¯•å¹»è§‰æ£€æµ‹æŒ‡æ ‡è®¡ç®—"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•5ã€‘å¹»è§‰æ£€æµ‹æŒ‡æ ‡è®¡ç®—")
        print("="*60)
        
        # æ¨¡æ‹ŸNLIç»“æœ
        nli_results = [
            {"verifiable": True, "is_hallucination": False},
            {"verifiable": True, "is_hallucination": False},
            {"verifiable": True, "is_hallucination": True},  # 1ä¸ªå¹»è§‰
            {"verifiable": False},  # ä¸å¯éªŒè¯
        ]
        
        metrics = detector.calculate_metrics(nli_results)
        
        print(f"æµ‹è¯•æ ·æœ¬: 4ä¸ªå£°æ˜")
        print(f"  - å¯éªŒè¯: 3ä¸ª")
        print(f"  - ä¸å¯éªŒè¯: 1ä¸ª")
        print(f"  - å¹»è§‰: 1ä¸ª")
        print(f"\nè®¡ç®—æŒ‡æ ‡:")
        print(f"  å¹»è§‰ç‡: {metrics['hallucination_rate']:.2%}")
        print(f"  äº‹å®å‡†ç¡®ç‡: {metrics['fact_accuracy']:.2%}")
        print(f"  å¯éªŒè¯å£°æ˜æ•°: {metrics['verifiable_claims']}")
        print(f"  å¹»è§‰å£°æ˜æ•°: {metrics['hallucinated_claims']}")
        
        expected_rate = 1/3  # 3ä¸ªå¯éªŒè¯ä¸­æœ‰1ä¸ªå¹»è§‰
        assert abs(metrics["hallucination_rate"] - expected_rate) < 0.01, "å¹»è§‰ç‡è®¡ç®—é”™è¯¯"
        assert metrics["verifiable_claims"] == 3, "å¯éªŒè¯å£°æ˜æ•°é”™è¯¯"
        
        print("\nâœ… å¹»è§‰æŒ‡æ ‡è®¡ç®—æµ‹è¯•é€šè¿‡")
    
    def test_full_detection_pipeline(self, detector):
        """æµ‹è¯•å®Œæ•´æ£€æµ‹æµç¨‹"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•6ã€‘å®Œæ•´å¹»è§‰æ£€æµ‹æµç¨‹")
        print("="*60)
        
        reference = "çˆ±å› æ–¯å¦äº1921å¹´è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ï¼Œè·å¥–åŸå› æ˜¯å‘ç°å…‰ç”µæ•ˆåº”å®šå¾‹ã€‚"
        answer = "çˆ±å› æ–¯å¦äº1921å¹´è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ï¼Œä»–æå‡ºäº†ç›¸å¯¹è®ºå’Œè´¨èƒ½æ–¹ç¨‹E=mcÂ²ã€‚"
        
        report = detector.detect(answer, reference, test_id="TEST_001")
        
        print(f"å‚è€ƒæ–‡æœ¬: {reference}")
        print(f"å›ç­”æ–‡æœ¬: {answer}")
        print(f"\næ£€æµ‹æ‘˜è¦:")
        print(f"  æµ‹è¯•ID: {report.test_id}")
        print(f"  å£°æ˜æ€»æ•°: {len(report.claims)}")
        print(f"  å¹»è§‰æ¯”ä¾‹: {report.hallucination_ratio:.2%}")
        print(f"  é£é™©ç­‰çº§: {report.risk_level.value}")
        
        if report.detected_types:
            print(f"  æ£€æµ‹åˆ°çš„å¹»è§‰ç±»å‹:")
            for ht in report.detected_types:
                print(f"    - {ht.value}")
        
        print(f"\nè¯¦ç»†NLIç»“æœ:")
        for r in report.nli_results:
            if r.get("verifiable"):
                print(f"  å£°æ˜: {r['claim'][:40]}...")
                print(f"    NLI: {r['nli_class']}, å¹»è§‰: {r['is_hallucination']}")
        
        assert report.test_id == "TEST_001", "æµ‹è¯•IDåº”æ­£ç¡®"
        assert report.risk_level is not None, "åº”æœ‰é£é™©è¯„çº§"
        
        print("\nâœ… å®Œæ•´æ£€æµ‹æµç¨‹æµ‹è¯•é€šè¿‡")
    
    def test_risk_level_assessment(self, detector):
        """æµ‹è¯•é£é™©ç­‰çº§è¯„ä¼°"""
        print("\n" + "="*60)
        print("ã€æµ‹è¯•7ã€‘é£é™©ç­‰çº§è¯„ä¼°éªŒè¯")
        print("="*60)
        
        test_cases = [
            (0.0, RiskLevel.PASS, "æ— å¹»è§‰"),
            (0.03, RiskLevel.LOW, "ä½å¹»è§‰ç‡"),
            (0.08, RiskLevel.MEDIUM, "ä¸­ç­‰å¹»è§‰ç‡"),
            (0.20, RiskLevel.HIGH, "è¾ƒé«˜å¹»è§‰ç‡"),
            (0.35, RiskLevel.CRITICAL, "é«˜å¹»è§‰ç‡"),
        ]
        
        print("é£é™©ç­‰çº§é˜ˆå€¼æµ‹è¯•:")
        for rate, expected_level, desc in test_cases:
            level = detector._assess_risk(rate)
            status = "âœ…" if level == expected_level else "âŒ"
            print(f"  {status} å¹»è§‰ç‡{rate:.0%} -> {level.value} ({desc})")
            assert level == expected_level, f"{desc}çš„é£é™©ç­‰çº§è¯„ä¼°é”™è¯¯"
        
        print("\nâœ… é£é™©ç­‰çº§è¯„ä¼°æµ‹è¯•é€šè¿‡")


def print_summary():
    """æ‰“å°æµ‹è¯•æ€»ç»“"""
    print("\n" + "="*60)
    print("ã€Day 09 å¹»è§‰æ£€æµ‹æµ‹è¯•æ€»ç»“ã€‘")
    print("="*60)
    print("""
æ ¸å¿ƒæ£€æµ‹èƒ½åŠ›éªŒè¯:
âœ… å£°æ˜æŠ½å– - ä»æ–‡æœ¬ä¸­æå–å¯éªŒè¯çš„äº‹å®å£°æ˜
âœ… NLIæ£€æµ‹ - ä½¿ç”¨è‡ªç„¶è¯­è¨€æ¨ç†åˆ¤æ–­äº‹å®å…³ç³»
âœ… è‡ªæ´½æ€§æ£€æŸ¥ - å¤šé‡‡æ ·éªŒè¯å›ç­”ä¸€è‡´æ€§
âœ… æŒ‡æ ‡è®¡ç®— - å¹»è§‰ç‡ã€äº‹å®å‡†ç¡®ç‡ç­‰æ ¸å¿ƒæŒ‡æ ‡
âœ… é£é™©è¯„çº§ - åŸºäºå¹»è§‰ç‡çš„é£é™©ç­‰çº§è¯„ä¼°

å…³é”®é£é™©é˜ˆå€¼:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¹»è§‰ç‡       â”‚ é£é™©ç­‰çº§   â”‚ å»ºè®®æªæ–½        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0%           â”‚ âœ… PASS    â”‚ æ­£å¸¸ä¸Šçº¿        â”‚
â”‚ 0-5%         â”‚ ğŸŸ¢ LOW     â”‚ ç›‘æ§è§‚å¯Ÿ        â”‚
â”‚ 5-15%        â”‚ ğŸŸ¡ MEDIUM  â”‚ äººå·¥å®¡æ ¸        â”‚
â”‚ 15-30%       â”‚ ğŸŸ  HIGH    â”‚ ä¿®å¤åä¸Šçº¿      â”‚
â”‚ >30%         â”‚ ğŸ”´ CRITICALâ”‚ ç¦æ­¢ä¸Šçº¿        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ£€æµ‹ç­–ç•¥æœ‰æ•ˆæ€§:
1. NLI-basedæ£€æµ‹ - é€‚åˆæœ‰å‚è€ƒæ–‡æœ¬çš„åœºæ™¯ï¼ˆRAG/æ‘˜è¦ï¼‰
2. è‡ªæ´½æ€§æ£€æŸ¥ - é€‚åˆæ— å‚è€ƒæ–‡æœ¬çš„äº‹å®é—®ç­”
3. å¤–éƒ¨éªŒè¯ - é€‚åˆå…³é”®ä¸šåŠ¡åœºæ™¯ï¼ˆåŒ»ç–—/æ³•å¾‹/é‡‘èï¼‰

ç”Ÿäº§ç¯å¢ƒå»ºè®®:
- é«˜é£é™©åœºæ™¯ï¼ˆåŒ»ç–—/æ³•å¾‹ï¼‰: å¹»è§‰ç‡é˜ˆå€¼ < 1%
- ä¸­é£é™©åœºæ™¯ï¼ˆå®¢æœ/æœç´¢ï¼‰: å¹»è§‰ç‡é˜ˆå€¼ < 5%
- ä½é£é™©åœºæ™¯ï¼ˆåˆ›æ„/å¨±ä¹ï¼‰: å¹»è§‰ç‡é˜ˆå€¼ < 15%
    """)


if __name__ == "__main__":
    # å…è®¸ç›´æ¥è¿è¡Œ
    pytest.main([__file__, "-v", "-s"])
    print_summary()

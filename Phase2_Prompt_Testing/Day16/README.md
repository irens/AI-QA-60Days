# Day 16: CO-STAR框架应用与维度质量测试

## 🎯 1. 核心风险与测试目标 (20分钟)

> **测试工程师视角**：CO-STAR框架是Prompt工程的系统化方法，但每个维度的设计选择都会直接影响输出质量。如果不进行维度级测试，线上会出现：
> - Context缺失导致理解偏差，输出偏离用户真实意图
> - Objective模糊导致目标漂移，同样输入产生不同行为
> - Style不一致导致品牌认知混乱，用户体验割裂
> - Tone失控导致客户关系受损，极端情况下引发公关危机
> - Audience错配导致沟通失效，信息无法有效传达
> - Response格式不统一导致下游解析失败，数据管道断裂

### 1.1 业务风险点

| 风险等级 | 风险场景 | 业务影响 |
|---------|---------|---------|
| 🔴 L1 阻断性 | Response格式不统一，JSON解析频繁失败 | API接口错误，下游系统崩溃 |
| 🔴 L1 阻断性 | Objective模糊导致关键决策不一致 | 金融/医疗场景决策错误 |
| � L2 高优先级 | Context缺失导致理解偏差 | 回答偏离用户真实意图 |
| 🟡 L2 高优先级 | Tone失控（过于随意或过于生硬） | 客户满意度下降，品牌形象受损 |
| 🟡 L2 高优先级 | Style不一致导致品牌认知混乱 | 用户体验割裂，专业感缺失 |
| 🟢 L3 一般 | Audience错配导致沟通失效 | 信息传达效率降低 |

### 1.2 测试思路

**核心策略**：对CO-STAR六个维度进行系统化测试，验证每个设计选择对输出质量的影响

1. **Context完整性测试**：验证背景信息缺失/冗余/偏差时的输出变化
2. **Objective明确性测试**：验证目标定义清晰度对输出一致性的影响
3. **Style一致性测试**：验证风格约束的有效性和稳定性
4. **Tone适切性测试**：验证语气在不同场景下的适配性
5. **Audience适配性测试**：验证受众定位对表达方式的塑造
6. **Response契约测试**：验证输出格式承诺的兑现率

**测试输入设计原则**：
- 单维度扰动：每次只改变一个维度，隔离变量观察影响
- 极端值测试：维度缺失、过度指定、相互冲突
- 组合爆炸：关键维度的正交组合覆盖
- 边界探测：维度定义的边界和灰色地带

---

## 📚 2. 理论基础

### 2.1 CO-STAR框架详解

```
┌─────────────────────────────────────────────────────────────────┐
│                     CO-STAR 框架                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   C - Context    (背景)   → 提供任务执行的上下文信息             │
│   O - Objective  (目标)   → 明确要完成的任务                     │
│   S - Style      (风格)   → 定义输出风格（专业/ casual/学术等）  │
│   T - Tone       (语气)   → 设定情感态度（友好/严肃/幽默等）     │
│   A - Audience   (受众)   → 指定目标读者（专家/初学者/儿童等）   │
│   R - Response   (响应)   → 规定输出格式（JSON/列表/段落等）     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 维度-风险-测试映射表

| 维度 | 设计缺陷 | 质量风险 | 测试方法 |
|-----|---------|---------|---------|
| **Context** | 背景缺失/冗余/偏差 | 理解偏差、幻觉生成 | 上下文消融实验、噪声注入 |
| **Objective** | 目标模糊/多重/冲突 | 输出漂移、行为不一致 | 目标明确性评分、一致性测试 |
| **Style** | 风格未定义/不一致 | 品牌认知混乱 | 风格分类器验证、跨会话一致性 |
| **Tone** | 语气失控/不适配 | 客户关系受损 | 情感分析验证、场景适配测试 |
| **Audience** | 受众错配/未指定 | 沟通失效、理解门槛 | 可读性评分、专家验证 |
| **Response** | 格式未约束/不兼容 | 解析失败、下游错误 | Schema验证、契约测试 |

### 2.3 维度交互风险矩阵

```
                Context   Objective   Style    Tone    Audience   Response
               ┌─────────┬───────────┬────────┬────────┬──────────┬─────────┐
Context        │    -    │    高     │   中   │   低   │    高    │   低    │
Objective      │   高    │     -     │   中   │   中   │    高    │   高    │
Style          │   中    │    中     │   -    │   高   │    中    │   低    │
Tone           │   低    │    中     │   高   │   -    │    高    │   低    │
Audience       │   高    │    高     │   中   │   高   │    -     │   中    │
Response       │   低    │    高     │   低   │   低   │    中    │   -     │
               └─────────┴───────────┴────────┴────────┴──────────┴─────────┘

高 = 强交互风险：两个维度设计冲突时产生严重质量问题
中 = 中等交互风险：需要协调设计
低 = 弱交互风险：相对独立
```

### 2.4 可测试性设计原则

```
高质量CO-STAR Prompt特征：

✅ Context: 必要且充分，可量化（如"基于过去7天数据"而非"基于近期数据"）
✅ Objective: 单一明确，可验证成功标准（如"列出3个原因"而非"分析一下"）
✅ Style: 具体可识别，有参照样本（如"像《经济学人》风格"而非"专业风格"）
✅ Tone: 情感可度量，有边界定义（如"友好但不过于随意"）
✅ Audience: 特征可描述，知识水平可分级（如"有编程基础的初学者"）
✅ Response: 格式可解析，有Schema约束（如JSON Schema定义）
```

---

## 🧪 3. 实验验证任务

请运行本目录下的 `test_day16.py`，观察控制台输出的真实日志。

### 3.1 测试覆盖范围

```python
# 测试用例分类
├── Context维度测试（4个）
│   ├── 上下文缺失（1个）      # 无背景信息时的默认行为
│   ├── 上下文冗余（1个）      # 过多无关信息的影响
│   ├── 上下文偏差（1个）      # 误导性背景的影响
│   └── 上下文完整性（1个）    # 必要信息齐全时的表现
│
├── Objective维度测试（4个）
│   ├── 目标模糊（1个）        # 开放式指令的风险
│   ├── 目标明确（1个）        # 具体可验证的指令
│   ├── 多重目标（1个）        # 多任务冲突风险
│   └── 目标冲突（1个）        # 矛盾指令的处理
│
├── Style维度测试（3个）
│   ├── 风格一致性（1个）      # 跨调用风格稳定性
│   ├── 风格漂移（1个）        # 长对话中的风格保持
│   └── 风格冲突（1个）        # 矛盾风格指定
│
├── Tone维度测试（3个）
│   ├── 语气适切性（1个）      # 场景匹配度
│   ├── 语气极端化（1个）      # 过度情绪风险
│   └── 语气不一致（1个）      # 同一Prompt语气波动
│
├── Audience维度测试（3个）
│   ├── 受众适配（1个）        # 专家vs初学者
│   ├── 受众错配（1个）        # 内容难度不匹配
│   └── 受众未指定（1个）      # 默认受众假设
│
└── Response维度测试（4个）
    ├── 格式契约（1个）        # Schema合规性
    ├── 格式缺失（1个）        # 无约束时的输出
    ├── 格式冲突（1个）        # 矛盾格式要求
    └── 格式稳定性（1个）      # 多次调用一致性
```

### 3.2 运行测试

```bash
# 运行所有测试
python test_day16.py

# 预期输出
=== CO-STAR框架维度质量测试 ===

[Context维度测试]
✅ 上下文完整: 通过 (相关性: 0.95)
⚠️  上下文缺失: 风险 (相关性: 0.42, 低于阈值0.70)
❌ 上下文偏差: 失败 (检测到幻觉内容)

[Objective维度测试]
✅ 目标明确: 通过 (一致性: 0.98)
⚠️  目标模糊: 风险 (输出方差过高)
...

风险汇总:
- L1风险: 2个 (Response格式不稳定、Objective冲突)
- L2风险: 3个 (Context缺失、Tone极端化、Audience错配)
- L3风险: 1个 (Style轻微漂移)
```

---

## 📋 4. 测试用例设计模板

### 4.1 Context测试模板

```python
# 基线Prompt（完整Context）
BASELINE = """背景：用户是电商平台商家，经营服装类目3个月，月均销售额5万元。
目标：分析当前经营状况并提供改进建议。"""

# 测试变体
test_cases = [
    {"name": "上下文缺失", "context": "", "risk": "理解偏差"},
    {"name": "上下文冗余", "context": "+无关信息", "risk": "注意力分散"},
    {"name": "上下文偏差", "context": "错误背景", "risk": "幻觉生成"},
]
```

### 4.2 Objective测试模板

```python
# 模糊目标
VAGUE = "分析一下销售情况"

# 明确目标
SPECIFIC = """请完成以下任务：
1. 计算近30天销售额环比增长率
2. 列出Top 3畅销SKU
3. 给出3条可执行的改进建议"""
```

### 4.3 Response契约模板

```python
# JSON Schema约束
SCHEMA = {
    "type": "object",
    "required": ["analysis", "recommendations"],
    "properties": {
        "analysis": {"type": "string"},
        "recommendations": {
            "type": "array",
            "items": {"type": "string"},
            "minItems": 3,
            "maxItems": 3
        }
    }
}
```

---

## 🔍 5. 结果解读与行动建议

### 5.1 风险等级定义

| 等级 | 判定标准 | 行动要求 |
|-----|---------|---------|
| 🔴 L1 | 输出无法解析/严重偏离目标/产生幻觉 | 必须修复，阻断发布 |
| 🟡 L2 | 质量下降但可用/偶发不一致 | 建议修复，监控上线 |
| 🟢 L3 | 轻微偏差/可接受范围内 | 记录观察，后续优化 |

### 5.2 维度优化优先级

```
高优先级修复：
1. Response格式不稳定 → 添加JSON Schema约束
2. Objective模糊 → 使用SMART原则重新定义
3. Context缺失关键信息 → 补充必要背景

中优先级优化：
4. Tone场景不适配 → 增加场景-语气映射表
5. Audience错配 → 明确受众特征描述
6. Style不一致 → 提供参考样本
```

---

## 📝 6. 今日任务清单

- [ ] 阅读并理解CO-STAR六个维度的设计要点
- [ ] 运行 `test_day16.py` 观察各维度测试结果
- [ ] 分析失败的测试用例，定位维度设计缺陷
- [ ] 选择一个实际业务Prompt，应用CO-STAR框架重构
- [ ] 设计该Prompt的六维度测试用例
- [ ] 记录测试发现的风险点和修复方案

---

## 📚 参考资料

1. [CO-STAR Framework](https://aiadvisoryboards.wordpress.com/2024/01/29/co-star-framework/) - 结构化Prompt设计框架
2. [Prompt Engineering Guide](https://www.promptingguide.ai/) - Prompt工程最佳实践
3. [LLM Testing Handbook](https://www.lakera.ai/blog/llm-testing-guide) - LLM测试方法论
